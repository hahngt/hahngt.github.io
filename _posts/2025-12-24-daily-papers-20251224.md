---
layout: post
title: "Daily Papers — 2025-12-24"
date: 2025-12-24 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [SAM Audio: Segment Anything in Audio](https://arxiv.org/abs/2512.18099)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2512.18099)

## Introduction
- Goal: 본 연구는 텍스트, 시각, 시간 간격 프롬프트를 통합하여 다양한 오디오 신호 분리 문제를 다룰 수 있는 범용 오디오 분할 기초 모델인 SAM Audio를 제안하는 데 목적이 있다.  
- Motivation: 기존 오디오 분리 모델들은 특정 도메인이나 고정된 카테고리에 한정되거나 제어 가능성이 제한적이며, 단일 프롬프트 방식만 지원하는 문제점이 존재하였다.  
- Contribution: 본 논문에서는 다중 모달 프롬프트를 하나의 통합 프레임워크 내에서 처리하는 최초의 범용 오디오 분리 모델과 시간 영역 제어를 위한 새로운 스팬 프롬프트, 그리고 인간 평가와 높은 상관성을 갖는 참조 없는 평가 모델을 포함한 통합 벤치마크를 제안하였다.  

## Method  
SAM Audio는 DAC-VAE 기반 잠재 공간에서 플로우 매칭 학습을 수행하는 확산 트랜스포머 구조에 기반하며, 텍스트, 시각적 마스크, 시간 스팬 프롬프트를 독립적 또는 결합하여 입력받아 타깃 소스와 잔여 소스의 오디오를 동시에 생성한다.  
텍스트 프롬프트는 T5 인코더로, 시각 프롬프트는 영상 인코더 및 SAM2에서 생성한 마스크로, 시간 스팬은 프레임 단위 토큰 시퀀스로 변환되어 각각 모델 내에서 적절히 통합된다.  
훈련 중에는 실제 분리 스템이 존재하는 고품질 데이터 및 합성 혼합 데이터를 활용하며, 확산 과정에서 중첩 윈도우 기반 멀티 디퓨전으로 긴 오디오도 경계 없는 연속 분리가 가능하도록 설계되었다.  

## Results  
SAM Audio는 일반 음향, 음성, 음악 및 악기 분리 전반에 걸쳐 이전 일반용 및 특수용 모델 대비 현저히 우수한 최첨단 성능을 달성하였다.  

## Limitations  
텍스트 프롬프트만으로는 미세한 음향 효과나 다중 발생 이벤트 구분이 어려운 경우가 존재하며, 시각 프롬프트를 활용한 실세계 오디오 분리에 관한 연구는 아직 미진한 상태이다.  

## Conclusion  
SAM Audio는 다양한 프롬프트 방식을 융합하여 오디오 분리의 범용성과 제어성을 크게 향상시켰으며, 이를 뒷받침하는 통합 벤치마크와 평가 체계도 함께 제시되었다.

# 2. [Toxicity Ahead: Forecasting Conversational Derailment on GitHub](https://arxiv.org/abs/2512.15031)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2512.15031)

## Introduction
- Goal: 본 연구의 목적은 GitHub 오픈 소스 소프트웨어(OSS) 커뮤니티에서 대화가 독성으로 탈선하는 현상을 예측하는 것이다.  
- Motivation: OSS 커뮤니티 내 독성 상호작용은 참여도를 저하시켜 프로젝트 지속 가능성에 위협이 되나, 기존의 독성 탐지는 사후적이며 선제적 개입이 어려운 문제점을 가진다.  
- Contribution: 본 논문은 GitHub 토론 데이터를 수집‧분석하여 독성 대화 탈선의 패턴을 밝히고, 대형 언어 모델(LLM)을 활용한 선제적 예측 프레임워크를 제안하였다.  

## Method  
GitHub 토론에서 159개의 독성 탈선 쓰레드와 207개의 비독성 쓰레드를 수집‧주석하였으며, 대화 역학, 언어적 신호, 긴장 요인 등의 특성을 분석하였다.  
Least-to-Most(LtM) 프롬팅 기법을 사용해 단계별로 대화 요약(Summary of Conversation Dynamics, SCD)을 생성하고 이를 토대로 대화 탈선 가능성을 예측하는 LLM 프레임워크를 개발하였다.  
CRAFT 및 기존 LLM 방법과 비교 평가하였고, 외부 GitHub 데이터셋에 대한 일반화 가능성도 검증하였다.  

## Results  
Qwen과 Llama 모델에서 각각 F1 점수 0.901과 0.852를 기록하여 기존 벤치마크보다 성능이 뛰어났으며, 외부 데이터셋에서도 최대 0.797 F1 점수를 달성하여 높은 예측력을 보였다.  

## Limitations  
데이터셋 크기가 제한적이며, 주로 잠긴(issue locked) 대화에 기반하여 일반적인 GitHub 커뮤니케이션 특성을 완전히 대표하지 못할 가능성이 존재한다.  

## Conclusion  
본 연구는 LLM 기반의 구조화된 프롬팅을 통해 GitHub OSS 커뮤니티에서 대화 탈선을 조기에 발견하고, 설명 가능하며 선제적 조치를 가능케 하는 효과적인 모더레이션 도구를 제시하였다.

# 3. [Learning to Refocus with Video Diffusion Models](https://arxiv.org/abs/2512.19823)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2512.19823)

## Introduction
- Goal: 본 논문은 단일 흐림 이미지로부터 현실적인 초점 스택을 생성하여 사후 초점 조정을 가능하게 하는 방법을 제안한다.  
- Motivation: 현대 자동 초점 시스템의 한계와 사용자의 사후 초점 변경 요구를 해결하기 위해 영상 확산 모델을 활용한 새로운 기법이 필요하다.  
- Contribution: 본 연구는 스마트폰으로 촬영한 대규모 실세계 초점 스택 데이터셋을 구축하고, 영상 확산 모델의 분류기-자유 안내 방식을 개량하여 초점 스택을 단일 샷으로 생성하는 방법을 제안하였다.  

## Method  
단일 흐림 이미지를 입력으로 하여 해당 초점 위치를 조건부 입력으로 활용하고 위치 의존적 조건화 기법을 도입하여 영상 확산 모델을 통해 전체 초점 스택을 동시에 예측한다. 이 과정에서 변형된 분류기-자유 안내 메커니즘이 모델이 명확한 초점 위치와 일치하는 시퀀스를 생성하도록 돕는다. 사전 훈련된 잠재 공간 영상 확산 모델을 활용하여 계산 효율성과 결과의 현실성을 달성하였다.  

## Results  
제안 방법은 본 연구에서 구축한 1,637개의 실제 스마트폰 초점 스택 데이터셋을 이용한 실험에서 대조군 대비 기준 초점 위치 간 큰 차이가 있는 경우에도 지각적 품질과 견고성 면에서 우수한 성능을 보였다.  

## Limitations  
본 방법은 대형 조리개를 사용하는 DSLR 카메라에서 발생하는 극단적인 흐림이나 보케 효과에는 아직 제한적이며, 훈련 데이터의 한계로 인해 이에 효과적으로 대응하지 못한다.  

## Conclusion  
영상 확산 모델을 활용한 본 연구의 사후 초점 조정 방법은 대규모 실세계 데이터에 기반해 현저한 시각적 현실성을 달성하였으며, 다양한 카메라와 일상 환경에서도 활용 가능함을 입증하였다.
