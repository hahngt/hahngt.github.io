---
layout: distill
title: "[Paper Review] StarGAN"
description: 
date: 2023-04-30 14:45:11 +/-0000
categories: Paper
tags: [GAN, AI, generative]   
use_math: true  # TAG names should always be lowercase
typora-root-url: ../
toc:
  sidebar: right
---


[About Code](https://github.com/HahnGyuTak/Thesis-Review/blob/main/StarGAN/Code.md)

[English Ver](https://github.com/HahnGyuTak/Thesis-Review/blob/main/StarGAN/Review_EN.md)

## Abstract

* 최근 연구들은 2개의 도메인에서 이미지 변환에 효과적인 성능을 보였지만, 3개 이상의 도메인을 다루는 접근에서는 한계를 보였다.
* 이를 해결하기 위해하나의 모델을 사용하며 다중 도메인에 대한 이미지 변환을 수행하는 StarGAN을 제안한다.
* 하나의 네트워크에 있는 여러 도메인에, 여러 데이터셋(RaFD, CelebA)을 학습시킴
* 이로써 입력 이미지를 원하는 도메인으로의 유연한 변환을 수행


## Introduction


* 다른 두 도메인의 학습데이터로 a 에서 b로 변환하는 학습을 수행
* 이미지에서 여러 도메인 추출(머리색, 성별, 나이 등)
  * CelebA : 머리색, 성별, 나이 등을 추출
  * RaFD : 행복, 분노, 슬픔 등과 같은 감정 도메인 추출
* RaFD로 학습하여 CelebA 이미지에 표정을 바꾸기 위해 두 데이터셋을 함께 학습

![IMG_E790BB5F1968-1](https://user-images.githubusercontent.com/50629765/219863839-0c3d675b-a9dd-43a1-ae0c-8789f3025ac9.jpeg){: width="700"}

* 기존의 모델은 여러 도메인 간의 변환이 비효과적이며 비효율적이었다.
  * k개의 도메인이 존재할 경우 k(k-1)개의 generator를 학습시켜야 했기 때문
  * 각 generator는 전체 데이터셋을 모두 활용하지 못함
* StarGAN은 하나의 generatordp 여러 도메인 간의 매핑 즉, 연결 자체를 학습
  * 2개의 이미지와 도메인 정보를 입력하면 대응하는 도메인간의 변환을 학습
  * 필요없는 레이블은 무시, 데이터셋에서 추출한 특정 레이블만 학습

## Related Work

* GAN (Generative Adversarial Networks)
* Conditional GANs
* Img-to-Img Translation (CycleGAN)
  * 하나의 모델에 두 도메인 간의 관계만 학습

## Method

### 1. Muti-Domain Image-to-Image Translation

* 다중 도메인 간 매핑을 하나의 G(generator)에 학습시키는 것이 목표
* 입력 이미지 x, 출력 이미지 y, 목표 도메인 레이블 c : [G(x, c) -> y]
* c 를 랜덤으로 생성해서 G가 유연하게 이미지를 변환할 수 있음
* 하나의 D(discriminator)가 여러 도메인을 control할 수 있도록 보조적인 분류기가 존재
* D : x → {Dsrc(x), Dcls(x)}.
  


#### Adversarial Loss 

![IMG_57FC6DAEAC7A-1](https://user-images.githubusercontent.com/50629765/219863865-89884597-4d1c-4371-988f-08c97afbf0e9.jpeg){: width="300"}


* G는 loss 를 최소화하려하고, D는 이를 최대화하려고 한다.
  
#### Domain Classification Loss

* G(x,c)로 생성된 이미지가 c로 분류되도록 하기 위해, D 맨 위에 classifier 추가
* real Img의 도메인 분류 손실을 사용하여 D를 최적화

![IMG_DD09A5BA8DC8-1](https://user-images.githubusercontent.com/50629765/219863884-b591a08f-989c-460a-b5c0-6a2e04da097b.jpeg){: width="300"}

* real Img의 도메인 분류 손실을 사용하여 D를 최적화
* D cls(c′\|x)는 D가 계산한 도메인 레이블의 확률 분포
* D 는 이 loss 를 최소화함으로서 (real Img인 x, 레이블 c')을 분류하는것을 학습

![IMG_F4ECA0F27C1F-1](https://user-images.githubusercontent.com/50629765/219863889-f1be11ce-18cd-4b66-a968-66573beb0be1.jpeg){: width="300"}

* G는 생성한 이미지가 target 도메인인 c로 분류되게끔 하기 위해 이 loss를 최소화한다.

#### Reconstruction Loss

* 위 loss를 최소화 한다 해도, 입력된 이미지에서 변환된 도메인을 제외하고 보존하는 것에 어려움이 있음

![IMG_72F4C97DFD50-1](https://user-images.githubusercontent.com/50629765/219863895-5c768829-1131-4f4d-9a04-8c595500e1f9.jpeg){: width="300"}

* cycle consistency(순환 일관성) loss 적용
* G에 변환된 이미지 G(x, c)와 원본 도메인 c'을 입력 → 원본이미지 재구성
* 총 G를 2번 사용 (원본 → 변환된 이미지 → 원본 재구성)

#### Full Objective

* optimize Fuctions of G and D
  

![IMG_4F814845022B-1](https://user-images.githubusercontent.com/50629765/219863898-35a4e46b-de00-4192-b902-60bce54c374a.jpeg){: width="300"}

* λcls 와 λrec 는 분류, 재구성 손실에 영향을 주는 하이퍼 파라미터
* λcls 는 1, λrec 는 10 사용

### 2. Training with Multiple Datasets

* CelebA에는 머리색과 같은 속성이, RaFD에는 표정 속성이 있음
* 이와 같은 다중 데이터셋에서는 G(x, c)에서 재구성할 때 필요한 c'레이블이 필요하기 때문에 문제가 생김

#### Mask Vector

* make vector를 도입, 불특정한 레이블을 무시하고 명시된 레이블에 집중

![mask_vecotr](https://user-images.githubusercontent.com/50629765/219866136-663ceab6-d40f-4080-a6fe-cc7df648216e.jpeg){: width="300"}

* c는 i번째 dataset의 레이블 벡터를 의미

#### Training Strategy

* 다중 dataset을 학습할 때, domain 레이블은 mask vector로 정의하여 G에 입력
* G의 구조는 하나의 dataset으로 학습하는 것과 다를바 없음
* 모든 dataset의 확률분포를 만들기 위해 D의 보조 분류기를 확장
* D가 특정 레이블에 대한 classification error를 최소하하는 과정을 통해 학습
  * CelebA 이미지로 학습을 진행할 때, D는 CelebA에 존재하는 label의 classification loss를 최소화
* RaFD와 CelebA를 교대로 학습 진행 -> 모든 레이블 학습

## Implementation

### Imporve GAN Training

![image](https://user-images.githubusercontent.com/50629765/224294892-b999b941-b5e9-4999-9484-a957a639e620.png){: width="300"}

* 위 수식으로 정의된 gradient penalty를 사용하는 Wasserstein GAN 사용

### Network Acchitecture

* CycleGAN에서 채택된 StarGAN의 Generator 네트워크 구성
  * convolutional layer (stride size : 2) -> downsampling
  * Residual Block of 6
  * transposed convolutional layer (stride size : 2) -> upsampling
* G에만 표준화 적용

## Experiment

### 1. Baseline Models

* DIAT - image-to-image transform (2 domain)
  * 두 domain Img인 X, Y의 매핑을 학습
  * \|x - F(G(x))\| 로 매핑한 정규화를 통해 원본 Img의 특징 보존
* CycleGAN - image-to-image transform (2 domain)
  * G(x)를 다시 G에 입력하여, 원본 이미지와의 손실 측정
* IcGAN - cGAN에 기인
  * 매핑 G : {z, c} → x 에서 역매핑 Ez : x → z 및 Ec : x → c 역시 학습
  * 잠재 벡터를 보존하면서 조건 벡터만 변경하여 이미지를 합성

### 2. Datasets

* CelebA
  * 유명인사의 얼굴 데이터의 7가지 domain
  * 머리색 (black, blond, brown), 성별, 나이
* RaFD
  * 참여자들의 8가지 표정 데이터 수집

### 3. Training

* Optimizer : Adam
* batch size : 16
* CelebA
  * learning rate : (epoch) (0 ~ 10) 0.0001, (11 ~ ) 0까지 점차 감소
* RaFD
  * learning rate : (epoch) (0 ~ 100) 0.0001, (11 ~ ) 0까지 점차 감소
* GPU : NVIDIA Tesla M40

### 4. Experimental Results on CelebA

* DIAT, CycleGAN과 같은 교차 도메인 모델을 label의 모든 쌍을 학습시킴
* 평가
  * 고정된 변환을 학습 하는 대신, StarGAN은 target 도메인에 대한 label에 따라 유연하게 변환할 수 있도록 학습
  * 다른 r교차 도메인들 보다 성능 Good
  * IcGAN보다 얼굴의 정체성을 유지
    * 합성곱 layer에서 활성화된 맵을 latent representation 로 저장하기 때문
    * latent repesentation : 이미지에서 발견된 특징들을 나타내는 숫자 배열

![IMG_78CC5B591D7C-1](https://user-images.githubusercontent.com/50629765/224294980-cb4ed0b4-e434-4439-a4da-daeacbf76501.jpeg){: width="600"}
![IMG_ADAA2C15EAE7-1](https://user-images.githubusercontent.com/50629765/224295011-bb1cfb6f-a118-4d86-8450-319729932c8e.jpeg){: width="600"}

### 5. Experimental Results on RaFD

* 무표정을 입력으로 RaFD의 여러 표정들을 학습
* 각 도메인 당 약 500장의 데이터
* 평가
  * StarGAN 모델이 가장 자연스러운 표정 생성
  * DIAT와 CycleGAN은 입력 이미지의 정체성은 유지, 하지만 선명도가 저하
  * IcGAN은 정체성 유지조차 실패
  * Why?
    * 타 모델은 2 domain학습시 1000개의 데이터 학습
    * StarGAN은 모든 domain의 데이터 약 4000개 사용

![IMG_828603DA420E-1](https://user-images.githubusercontent.com/50629765/224295058-2a43d1ef-60eb-4af9-a95a-e8f3dbadc859.jpeg){: width="600"}


* RaFD로 분류기 학습 후, 생성된 이미지 분류 결과

![RaFD cls](https://user-images.githubusercontent.com/50629765/224295099-5e4b4a1d-7fa9-47b2-8089-9f2934bfc68f.jpeg){: width="600"}


* StarGAN이 classification error 가 가장 작음
* 학습에 필요한 parameter가 타 모델에 비해 현저히 작음
   * -> StarGAN은 단 한쌍의 (G, D)를 사용하기 때문


### 6. Experimental Results on CelebA + RaFD

![IMG_0D6FA5D07ACF-1](https://user-images.githubusercontent.com/50629765/224295184-4d2ad2c0-bd7f-4449-8965-c2edcc81b9f4.jpeg){: width="600"}

* CelebA 와 RaFD 데이터셋 둘 다 사용 (Multiple datasets) (with mask vector)
* JNT(jointly train), SNG(single train)
* joint training의 효과
  * JNT가 더 선명한 품질의 표정을 생성
  * SNG는 CelebA의 image translation을 학습 X 이기 때문
