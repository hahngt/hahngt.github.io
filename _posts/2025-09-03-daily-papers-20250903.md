---
layout: post
title: Daily Papers — 2025-09-03"
date: 2025-09-03 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [The Landscape of Agentic Reinforcement Learning for LLMs: A Survey](https://arxiv.org/abs/2509.02547)

## Introduction
- Goal: 본 논문은 대규모 언어모델(LLM)을 자율적 의사결정 에이전트로 전환하는 에이전틱 강화학습(Agentic RL)의 개념적 변화와 현황을 체계적으로 조사하는 데 목적이 있다.  
- Motivation: 기존의 단일 단계 강화학습 기반 LLM 최적화는 시퀀스 생성에 국한되어 실제 동적 환경에서의 장기적 의사결정 능력을 반영하지 못하는 한계가 존재한다.  
- Contribution: 본 연구는 전통적 LLM-RL과 달리 부분관측 마르코프 결정과정(POMDP)으로서 Agentic RL을 수학적으로 정식화하고, 핵심 에이전틱 역량과 다양한 적용 분야에 기반한 분류체계를 제안하며, 관련 오픈소스 환경과 평가체계를 통합하여 향후 연구를 지원한다.  

## Method  
Agentic RL은 LLM을 시퀀스 생성자가 아닌 계획, 도구 활용, 기억, 추론, 자기개선 및 지각 역량을 내재한 정책(policy)으로 모델링한다.  
이 과정은 기존 단일-스텝 MDP 기반 강화학습(PBRFT)과 대비되는 동적 환경에서의 POMDP 프레임워크를 활용한다.  
학습은 PPO, GRPO, DPO 등 다양한 강화학습 알고리즘을 적용하여 내부 계획 역량과 외부 도구 호출 행동을 동시에 최적화한다.  

## Results  
500편 이상의 최신 연구를 통합 분석하여 Agentic RL이 동적 환경 대응, 장기 계획 수행, 도구 통합 및 자가 개선 능력 측면에서 전통적 LLM-RL 대비 유의미한 발전을 이뤘음을 확인하였다.  

## Limitations  
Agentic RL 연구는 용어 및 평가 기준의 일관성 부족과 범용적 교차 도메인 일반화 어려움, 그리고 신뢰성 확보 및 대규모 학습 환경 구성의 난제에 직면해 있다.  

## Conclusion  
에이전틱 강화학습은 LLM의 자율적, 적응적 에이전트화에 핵심적인 역할을 하며, 확장성과 신뢰성을 담보한 차세대 범용 AI 에이전트 개발을 위한 중추적 연구 분야임을 제시하였다.

# 2. [UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn   Reinforcement Learning](https://arxiv.org/abs/2509.02544)

## Introduction
- Goal: 본 논문은 GUI 에이전트를 위한 대화형 강화학습 기반의 차세대 모델 UI-TARS-2를 개발하여 기존 한계를 극복하는 데 목적이 있다.  
- Motivation: 기존 GUI 에이전트는 데이터 부족, 다중 대화 강화학습의 불안정성, GUI 단독 운영의 한계, 환경의 안정성 문제 등 여러 난제를 안고 있었다.  
- Contribution: 본 연구는 데이터 플라이휠, 안정화된 다중 대화 강화학습, 하이브리드 GUI 환경, 대규모 롤아웃을 지원하는 워크플로우를 제안하여 이 난제들을 체계적으로 해결하였다.  

## Method  
UI-TARS-2는 GUI 조작과 시스템 도구 호출을 통합한 하이브리드 환경과 대규모 분산 가상머신 인프라를 활용한다. 데이터 플라이휠을 통해 지속적인 사전학습, 감독 미세조정, 강화학습을 순환하며 모델과 데이터 품질을 동시에 향상시킨다. 또한, 인간 참여 온라인 주석과 자동화된 과제 합성을 결합해 고품질의 인지적 사고과정을 반영한 데이터 수집 및 다중 대화 강화학습을 수행하였다.  

## Results  
UI-TARS-2는 Online-Mind2Web(88.2점), OSWorld(47.5점), WindowsAgentArena(50.6점), AndroidWorld(73.3점) 등 GUI 벤치마크에서 기존 모델 대비 우수한 성능을 보였으며, 15개 게임의 평균 정규화 점수 59.8로 인간 수준의 약 60% 성과를 달성하였다.  

## Limitations  
정보 부족.  

## Conclusion  
UI-TARS-2는 GUI 환경 내에서 안정적이고 확장 가능한 다중 대화 강화학습을 통해 다양한 현실적 작업에서 뛰어난 일반화 능력을 입증하는 차세대 GUI 에이전트임을 확인하였다.

# 3. [SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn   Tool-Integrated Reasoning](https://arxiv.org/abs/2509.02479)

## Introduction
- Goal: 본 연구는 강화학습 기반 다중 회차 도구 통합 추론(multi-turn Tool-Integrated Reasoning, TIR)에서 발생하는 훈련 불안정성을 해결하고 안정적인 학습을 실현하는 방법을 제안하는데 목적이 있다.  
- Motivation: 다중 회차 TIR에서 외부 도구 피드백으로 인한 분포 편이가 누적된 저확률 토큰 생성과 이로 인한 기울기 폭주 문제가 훈련 과정의 붕괴를 초래하는 한계가 존재한다.  
- Contribution: 본 연구에서는 void turn(코드 블록 또는 최종 정답을 생성하지 않는 회차)를 식별하고 이를 포함하는 경로를 필터링하여 기울기 폭주를 억제하고 안정적인 다중 회차 TIR 학습을 가능케 하는 SimpleTIR 알고리즘을 제안하였다.  

## Method  
SimpleTIR은 각 회차 응답이 완성된 코드 블록 또는 최종 정답을 포함하지 않는 void turn을 포함하는 전체 경로를 정책 업데이트에서 제외하는 방식으로 작동한다. 이는 고확률 토큰 생성만을 반영하여 불안정한 저확률 토큰에 의해 초래되는 고기울기 문제를 완화한다. 또한 정책 손실 계산 시 외부 도구 피드백 토큰은 마스킹하여 적절한 신용 배분을 보장한다.  

## Results  
SimpleTIR은 Qwen2.5-7B 모델 기반에서 다중 회차 TIR 수학 문제 해결 벤치마크 AIME24 점수를 22.1에서 50.5로 크게 향상시키며 Zero RL 환경에서 최첨단 성능을 달성하였다.  

## Limitations  
제안 기법은 void turn 기준이 다중 회차 TIR 외 다른 과제에 직접 적용 가능하지 않을 수 있으며, 현재 최대 10회차로 제한된 점과 고성능 코드 실행 샌드박스 의존성 등 실용적 제약이 존재한다.  

## Conclusion  
본 연구는 강화학습 다중 회차 TIR의 핵심 문제인 저확률 토큰에 의한 훈련 불안정을 void turn 기반 경로 필터링으로 해결하여 안정적 학습과 다양한 고급 추론 패턴 도출을 가능하게 함으로써 향후 대규모 언어모델 에이전트의 신뢰성 있는 멀티턴 추론 발전에 기여하였다.

# 4. [LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model](https://arxiv.org/abs/2509.00676)

## Introduction
- Goal: 본 연구는 비전-언어 모델에서 평가자(critic) 모델을 단순 평가를 넘어서 직접 정책(policy) 모델로 활용하는 방법을 제안하는 데 목적이 있다.  
- Motivation: 기존에는 정책 모델과 평가자 모델이 엄격히 분리되어 평가자가 직접 응답을 생성하는 용도로 사용되지 않았지만, 이 분리 관행을 재고할 필요성이 제기되었다.  
- Contribution: RL 기반 비평자 데이터 학습을 통해, 평가 능력과 응답 생성 능력을 동시에 향상시키는 단일 모델 LLaVA-Critic-R1 및 그 확장 모델을 개발하였다.  

## Method  
본 연구는 쌍별 선호(prefence) 라벨이 달린 평가 데이터셋을 강화학습용 신호로 재구성하고, 기본 생성 모델에 직접 강화학습을 수행하였다.  
평가자는 특정 포맷에 맞춰 응답 선호를 판단하며 체인오브씽킹(think-then-answer) 구조를 강화하여 자체적 추론능력을 키웠다.  
Group Relative Policy Optimization(GRPO) 알고리즘을 활용해 선호 보상과 출력 형식 보상을 함께 최적화하였다.  

## Results  
LLaVA-Critic-R1은 26개 광범위 비주얼 추론 및 이해 벤치마크에서 기본 모델 대비 평균 5.7% 성능 향상을 보였으며, 기존 인-도메인 데이터로 훈련된 전문화된 추론 VLM과 대등하거나 우수한 정책 성능을 입증하였다.  

## Limitations  
검증 결과, 테스트 시 자기비판(self-critique) 활용에도 불구하고 정답 선택 실패 사례가 존재하여 평가자 능력이 아직 최적화 단계에 이르지 못했다.  

## Conclusion  
평가자 데이터를 기반으로 한 강화학습 훈련은 평가 및 생성 능력을 동시에 강화하여 확장 가능하고자기개선이 가능한 다중 모달 비전-언어 모델 개발에 효과적인 접근법임을 제시하였다.

# 5. [ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long   Video Understanding](https://arxiv.org/abs/2508.21496)

## Introduction
- 본 연구의 목표는 장편 영상 이해 과정에서 발생하는 의미 집계 환각(Semantic Aggregation Hallucination, SAH)을 체계적으로 평가하고 분석하기 위한 벤치마크인 ELV-Halluc를 제안하는 것이다.  
- 기존 영상 멀티모달 대형언어모델들은 주로 단편 영상 위주의 환각을 다루었으나, 장편 영상에서 발생하는 복잡한 의미 집계 과정에서의 환각 문제는 충분히 탐구되지 않았다.  
- 이에 본 연구는 SAH 현상의 존재를 확인하고, 이를 완화하기 위한 위치 인코딩 및 직접 선호 최적화(DPO) 전략을 포함한 해결책을 제시하며, 8천 개의 적대적 데이터 쌍을 통한 성능 향상을 보였다.  

## Method  
ELV-Halluc는 여러 사건으로 구성된 장편 영상을 이벤트 단위로 구분하여 환각 현상을 평가하는 최초의 벤치마크로 설계되었다.  
모델이 동일 영상 내 이벤트 간 의미를 오인하여 발생하는 SAH를 구분하기 위해 인-비디오와 아웃-비디오 환각 질문 쌍을 사용하여 SAH 비율을 정의하였다.  
또한, Gemini-2.5 Flash를 활용한 반자동 캡셔닝과 GPT-4o를 통한 적대적 질문 생성 기법을 통해 348개의 고품질 이벤트별 영상 데이터셋을 구축하였다.  

## Results  
실험 결과, 14개의 공개 소스 모델과 2개의 폐쇄형 모델 모두 장편 영상에서 SAH가 확연히 존재하며, 의미 복잡성 증가 및 급변하는 시맨틱에서 SAH 비율이 상승함을 확인하였고, 위치 인코딩과 DPO 적용 시 SAH 비율이 최대 27.7%까지 감소하였다.  

## Limitations  
제안하는 데이터셋은 Gemini 기반 초기 캡션 생성에 따른 편향 가능성과 실제 장편 영상과의 차이, 그에 따른 데이터 규모 한계 등 제한점을 가진다.  

## Conclusion  
ELV-Halluc 벤치마크와 분석·완화 전략 제안은 장편 영상 이해의 환각 문제를 심층적으로 연구할 수 있는 토대를 마련하며, 신뢰성 높은 영상-멀티모달 대형모델 개발에 기여한다.

# 6. [VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use](https://arxiv.org/abs/2509.01055)

## Introduction
- Goal: 본 논문은 도구 사용을 포함하는 다중 턴 상호작용을 지원하는 통합적이고 모듈화된 에이전틱 강화학습(Agentic Reinforcement Learning with Tool use, ARLT) 프레임워크인 VERLTOOL을 제안하는 데 목적이 있다.  
- Motivation: 기존 강화학습과 도구통합 연구들은 단일 작업 맞춤형 코드베이스, 동기식 실행의 병목, 도구 다중 확장성의 부족 문제로 인해 확장성과 재현성에서 한계를 보였다.  
- Contribution: VERLTOOL은 VeRL과의 상위 호환성, 다양한 도구 통합을 위한 표준화 API, 비동기 롤아웃으로 2배 이상의 속도 향상, 그리고 6개 ARLT 도메인에서 경쟁력 있는 성능을 보여주는 모듈화 및 확장성 높은 학습 인프라를 제공한다.  

## Method  
ARLT를 다중 턴 행위와 다중 모달 관찰 토큰이 포함된 궤적으로 공식화하며, 각 행동이 도구 호출 여부를 판단하는 정지 토큰과 연결된다.  
VERLTOOL은 RL 학습과 도구 실행을 엄격히 분리한 비동기 파이프라인을 구축하여 도구 호출 대기 시간을 감소시키고, 도구 서버를 통한 병렬 실행 및 Ray 기반 분산 처리를 지원한다.  
도구는 Python 기반 경량 플러그인 구조로 구현되어 쉽게 통합 및 관리되며, 다중 모달(텍스트·코드·이미지 등) 도구 호출을 통합 API 하나로 제어한다.  

## Results  
VERLTOOL을 기반으로 한 학습 모델들은 수학 문제해결, 지식 질의응답, SQL 생성, 시각 추론, 웹 검색, 소프트웨어 공학 등 6개 도메인에서 선행 특화 시스템과 비슷하거나 우수한 성능을 보였다.  

## Limitations  
현재 연구에서는 ARLT 도메인 별 보상 설계 및 초기화 전략이 도구 사용 능력 습득에 필수적이며, 적절한 설계 없이는 효과적인 도구 활용이 어려운 한계가 존재한다.  

## Conclusion  
VERLTOOL은 ARLT 분야에서 포괄적이고 효율적인 통합 학습 인프라를 제공하여 LLM과 다양한 도구의 협력적 학습을 촉진하고, 향후 에이전틱 RL 연구 발전에 기여하는 기반을 마련한다.

# 7. [POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models   for Document Conversion](https://arxiv.org/abs/2509.01215)

## Introduction
- 본 연구의 목표는 문서 변환 작업에서 외부 모델의 지식 증류 없이도 다양하고 복잡한 문서 형식과 레이아웃을 처리할 수 있는 고품질 시각-언어 모델을 개발하는 것이다.  
- 기존 문서 변환 모델들은 고품질 라벨 데이터의 부족과 외부 교사 모델에 의존한 지식 증류 방법의 한계로 인해 실제 응용에서 성능 저하가 발생하는 문제가 있었다.  
- 이에 따라 본 연구는 대규모 합성 데이터 생성과 실세계 문서에 대한 반복적 자기 개선 단계를 포함하는 자동화된 증류 없는 학습 프레임워크를 제안하였다.  

## Method  
본 접근법은 첫째, 대형 언어 모델과 HTML 템플릿을 활용하여 통일된 출력 형식으로 다양한 문서 요소를 포함하는 대규모 합성 데이터셋을 생성하여 사전 학습하는 단계를 포함한다.  
둘째, 사전 학습된 모델을 이용해 실세계 문서에 대한 자동 주석을 생성하고, 고품질 필터링 전략을 적용하여 정제된 데이터로 모델을 반복 재학습시키는 자기 개선 단계를 수행한다.  
이러한 두 단계의 파이프라인은 데이터 품질과 모델 성능을 점진적으로 향상시키도록 설계되었다.  

## Results  
POINTS-Reader 모델은 여러 벤치마크에서 동급 혹은 그 이상의 성능을 보여주었으며, 특히 표 인식에서 기존 공개 모델과 전문 OCR 모델들을 능가하는 결과를 나타냈다.  

## Limitations  
본 연구에서 개발된 모델은 현 시점에서 영어 문서만 지원하며, 손글씨 인식 및 이미지 요소 추출 기능은 아직 구현되어 있지 않는다.  

## Conclusion  
본 논문은 증류 없이 합성 데이터와 반복 자기 개선을 통해 고품질 문서 변환 데이터를 구축하고, 이에 기반한 모델이 다양한 벤치마크에서 최첨단 성능을 달성함을 입증하였다.

# 8. [Baichuan-M2: Scaling Medical Capability with Large Verifier System](https://arxiv.org/abs/2509.02208)

## Introduction
- Goal: 본 논문은 의료 분야 대형 언어 모델의 실제 임상 적용성을 높이기 위해 동적 검증 시스템과 강화학습 기법을 제안하는 데 목적이 있다.  
- Motivation: 기존의 정적 벤치마크 시험은 실제 의료 상담의 동적이고 복잡한 특성을 반영하지 못해, 의료 AI의 실질적 활용에 한계가 존재하였다.  
- Contribution: 환자 시뮬레이터와 임상 루브릭 생성기를 포함하는 대규모 동적 강화학습 검증 시스템을 구축하고, 이를 기반으로 Baichuan-M2 모델을 개발하여 우수한 성능을 보였다.  

## Method  
본 연구는 환자 시뮬레이터를 통해 현실적인 다중 상호작용 임상 환경을 생성하고, 임상 루브릭 생성기가 다차원 평가 지표를 동적으로 생산한다. Baichuan-M2는 다단계 강화학습과 향상된 GRPO 알고리즘을 활용하여 의료 지식, 추론능력, 환자 대응 능력을 고루 강화하였다. 훈련 과정은 중간 단계의 도메인 적응, 감독 미세조정, 그리고 다중 단계 강화학습으로 구성된다.  

## Results  
Baichuan-M2는 HealthBench 평가에서 32B 파라미터임에도 불구하고 모든 공개 소스 모델과 대부분의 폐쇄형 모델을 능가하며, GPT-5만이 넘었던 HealthBench Hard 벤치마크에서 32점 이상의 성과를 기록하였다.  

## Limitations  
정보 부족  

## Conclusion  
본 연구는 의료 분야 LLM의 임상 적용을 위해 동적 검증 체계가 필수적임을 입증하고, 성능과 파라미터 효율성 측면에서 새로운 파레토 최적선을 제시하였다.

# 9. [Kwai Keye-VL 1.5 Technical Report](https://arxiv.org/abs/2509.01563)

## Introduction
- Goal: 본 논문은 동영상 이해에서의 근본적 한계를 극복하고 멀티모달 비디오 이해 성능을 향상시키기 위해 Keye-VL-1.5 모델을 제안하는 데 목적이 있다.  
- Motivation: 기존 멀티모달 대형 언어모델들은 정적인 이미지 이해에는 진전을 보였으나, 동영상의 동적이고 정보 밀도 높은 특성 때문에 시공간 해상도와 시간적 범위 간의 균형 문제를 해결하지 못하는 어려움을 겪었다.  
- Contribution: 본 연구는 동영상 특징에 기반한 Slow-Fast 인코딩 전략, 8K에서 128K까지 점진적 컨텍스트 확장 프리트레이닝, 그리고 체계적인 추론 능력 및 인간 선호도 정렬을 위한 후처리 학습 전략을 통해 혁신적인 멀티모달 비디오 이해 모델을 구현하였다.

## Method  
Keye-VL-1.5는 시각 변화를 반영해 고해상도 핵심 프레임과 저해상도 다수 프레임을 병렬 처리하는 Slow-Fast 동영상 인코딩 전략을 도입하였다. 프리트레이닝은 4단계로 진행되며, 점진적 컨텍스트 길이 확장을 통해 긴 영상과 복잡한 시각 정보를 안정적으로 학습하도록 하였다. 후처리 학습 과정에서는 체인 오브 사고(Chain-of-Thought) 데이터 생성, GSPO 기반 강화학습, 점진적 프롬프트 힌팅 및 정렬 강화학습을 포함하여 추론 능력과 인간 선호도 일치를 강화하였다.

## Results  
대규모 공개 및 내부 벤치마크 평가에서 Keye-VL-1.5는 동영상 이해 분야에서 기존 최첨단 모델 대비 월등한 성능을 달성하였으며, 일반적인 멀티모달 및 추론 태스크에서도 경쟁력 있는 결과를 보였다.

## Limitations  
정보 부족.

## Conclusion  
Keye-VL-1.5는 비디오 이해와 복합 추론에 특화된 차세대 멀티모달 대형 언어모델 구축을 위한 실용적이고 효과적인 접근법을 제시하였다.

# 10. [Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task   Arithmetic](https://arxiv.org/abs/2509.01363)

## Introduction
- Goal: 본 연구는 강화학습을 통해 습득된 복잡한 추론 능력을 모델 간에 전이 가능한 소형 작업 벡터(이하 reasoning vector)로 추출하고 이를 활용하는 방법을 제안하는 데 있다.  
- Motivation: 기존 대형 언어 모델의 고성능 추론능력 강화는 대량의 계산 리소스와 복잡한 튜닝을 요구하여 실용적 확산에 한계가 존재한다.  
- Contribution: 동일 초기화와 데이터 기반으로 SFT 및 GRPO 기법으로 훈련된 두 모델의 파라미터 차이를 reasoning vector로 정의하고, 이를 단순 덧셈 연산만으로 다양한 추론 벤치마크에서 성능을 일관되게 향상시킴을 보였다.  

## Method  
두 개의 QWEN2.5 모델(하나는 SFT, 다른 하나는 GRPO 최적화)을 이용해 reasoning vector = θGRPO − θSFT로 산출하였다. 이 벡터는 RL에 의해 부여된 추론 능력을 포착하며, 호환 가능한 instruction-tuned 모델에 더함으로써 추론 성능을 강화한다. 학습된 초기화 조건과 동일한 아키텍처 및 토크나이저를 가진 타깃 모델에 벡터를 단순하게 적용하는 절차로 구현된다.  

## Results  
1.5B 모델 기준 reasoning vector 추가 시 GSM8K(수학 문제) 정확도는 4.9%, HumanEval(코드 생성)은 4.3%, BigBenchHard(복잡 논리 문제)에서는 12.3% 성능 상승을 기록하였으며, 역벡터 적용 시 성능이 11.8% 하락하는 대칭적 효과를 확인하였다.  

## Limitations  
본 방법은 동일 초기화 기반의 아키텍처 및 토크나이저를 갖춘 호환 가능한 모델 간에만 적용 가능하며, 모델 가족 간 전송 가능성은 미확인으로 한계가 존재한다.  

## Conclusion  
추론 능력은 파라미터 공간에서 조작 가능한 모듈식 작업 벡터로 분리하고 재활용할 수 있음을 입증하여, 고비용 강화학습 없이도 기존 공개 모델 자원을 활용한 경량화된 추론 성능 향상 경로를 제시하였다.

# 11. [Implicit Actor Critic Coupling via a Supervised Learning Framework for   RLVR](https://arxiv.org/abs/2509.02522)

## Introduction
- 본 논문은 RLVR 환경에서 희소한 보상 신호와 불안정한 정책 경사 업데이트 문제를 해결하기 위해 감독학습 프레임워크를 활용한 암묵적 액터-크리틱 결합 방법인 PACS를 제안한다.  
- 기존 RLVR 방식은 보상 신호가 희박하여 크레딧 할당과 학습 안정성에 어려움이 존재한다는 점에서 동기를 부여받았다.  
- PACS는 결과 보상을 예측 가능한 레이블로 간주하여 정책 모델을 통해 크로스 엔트로피 손실로 직접 학습함으로써 정책 경사와 보상 추정을 암묵적으로 통합한다.  

## Method
- PACS는 결과 보상(R)과 출력(o)을 쌍으로 보고, 보상을 이진 분류 레이블로 하여 정책 모델의 점수 함수 ψ(q,o;θ)를 최적화한다.  
- 손실 함수는 크로스 엔트로피로 정의되며, 손실의 그래디언트 분석을 통해 기존 정책 경사 업데이트와 암묵적 액터-크리틱 역할 결합이 동시에 이뤄짐을 보였다.  
- 구체적으로 점수 함수는 REINFORCE Leave-One-Out(RLOO) 방식을 활용하여 그룹 내 상대적 우수성 평가를 반영한다.  

## Results
- MATH 500, AMC23, AIME 2024, AIME 2025 등 수학 추론 벤치마크에서 PACS는 PPO 및 GRPO 대비 최대 14.36포인트 이상의 pass@k 향상을 보이며 우수한 성능을 입증하였다.  

## Limitations
- 정보 부족.  

## Conclusion
- PACS는 RLVR 문제를 감독학습 문제로 재정의하여 희소 보상 문제와 불안정성을 극복하며, 높은 추론 성능과 안정적인 탐색-활용 균형을 달성하는 유망한 RLVR 학습 패러다임임이 확인되었다.

# 12. [Jointly Reinforcing Diversity and Quality in Language Model Generations](https://arxiv.org/abs/2509.02534)

## Introduction
- Goal: 본 연구는 언어 모델(LLM) 생성에서 응답의 품질과 의미적 다양성을 동시에 강화하기 위한 강화학습 기법을 제안하는 데 목적이 있다.  
- Motivation: 기존 LLM의 후처리 과정에서는 품질 향상에 주력하는 반면, 출력 분포가 좁아져 다양성이 감소하는 문제가 존재하였다.  
- Contribution: 의미적 유사도를 고려하는 분할 함수를 도입하여 다양성과 품질 보상을 결합하는 Darling 프레임워크를 개발하여 다양성 감소 문제를 극복하고자 하였다.  

## Method  
Darling은 시맨틱 분류기로 응답들을 의미적으로 동등한 군집으로 분할하며, 이를 바탕으로 다양성과 품질 보상을 곱하는 방식으로 온라인 강화학습 중 보상함수를 설계한다. 이로써 다양하고 동시에 높은 품질의 출력을 생성하도록 모델을 최적화한다. 기존 GRPO 알고리즘을 기반으로 하며 토큰 수준 손실 평균화와 정규화 방식의 변화를 도입하였다.  

## Results  
Darling은 다양한 크기와 계열의 모델에서 비검증적 창의적 작업과 수학 문제 등 검증 가능한 과제 모두에서 기존 방법 대비 품질과 다양성 지표 모두에서 우수한 성능을 나타냈다.  

## Limitations  
논문 내 제한점이나 한계점에 대한 구체적 기술은 부족하였다.  

## Conclusion  
Darling은 품질과 의미적 다양성을 동시에 증진시켜 언어 모델 후처리 시 발생하는 다양성 붕괴 문제를 효과적으로 해결함을 입증하였다.

# 13. [Gated Associative Memory: A Parallel O(N) Architecture for Efficient   Sequence Modeling](https://arxiv.org/abs/2509.00605)

## Introduction
- Goal: 본 논문은 시퀀스 모델링 효율성을 개선하기 위해 선형 시간 복잡도(O(N))를 가지면서 완전 병렬화가 가능한 Gated Associative Memory (GAM) 네트워크를 제안하는 것이다.  
- Motivation: 기존 Transformer의 자기-어텐션 메커니즘은 시퀀스 길이에 따라 계산량이 제곱(O(N²))으로 증가하여 긴 문맥 처리에 큰 병목 현상이 발생한다.  
- Contribution: GAM은 인과적 합성곱과 병렬 연관 기억 기전을 병렬로 결합하고 이를 게이팅 메커니즘으로 융합하여 기존 Transformer와 Mamba 대비 학습 속도와 성능 면에서 우수함을 실험적으로 증명했다.  

## Method  
GAM은 각 토큰에 대해 지역 문맥을 인과적 1D 합성곱으로, 전역 문맥은 학습된 기억 은행에서 병렬적으로 연관 기억 조회로 모델링한다. 두 경로는 학습 가능한 게이트를 통해 동적으로 결합되어 토큰별로 지역과 전역 정보를 조절한다. 이 구조는 순환 없이 완전 병렬화가 가능하여 선형 복잡도를 달성한다.  

## Results  
WikiText-2와 TinyStories 벤치마크에서 GAM은 Transformer 및 Mamba 대비 훈련 속도가 빠르고 최종 검증 perplexity가 더 우수하거나 경쟁력이 있음을 보였다.  

## Limitations  
정보 부족이다.  

## Conclusion  
GAM은 자기-어텐션을 대체하는 선형 시간, 완전 병렬 시퀀스 모델링 아키텍처로서 계산 효율성과 성능 측면에서 유망한 대안임이 확인되었다.

# 14. [DynaGuard: A Dynamic Guardrail Model With User-Defined Policies](https://arxiv.org/abs/2509.02563)

## Introduction
- Goal: 본 논문은 사용자 정의 정책에 따라 동적으로 작동하는 가디언 모델 DynaGuard를 제안하는 데 목적이 있다.  
- Motivation: 기존의 고정된 해악(category) 탐지 방식 가디언 모델은 실제 응용 분야의 다양성과 특수성을 충족하지 못하는 한계를 가진다.  
- Contribution: DynaGuard는 동적 정책 평가, 자연어 설명 제공, 빠른 추론 옵션을 지원하며, 사용자 정의 정책 위반 탐지에서 최첨단 성능을 입증하였다.  

## Method  
DynaGuard는 사용자 정의 규칙 집합으로 구성된 다양한 정책을 받아 채팅 대화를 평가하며, 규칙 위반 시 자연어 추론을 통해 위반 이유를 설명한다. 대규모의 DynaBench 데이터셋(40,000개 정책과 시뮬레이션 대화)을 활용하여 Qwen3 기반 모델을 지도학습과 강화학습으로 훈련하였다. 모델은 체인 오브 사고(Chain-of-Thought) 및 비사고 모드를 병행하여 신속한 추론과 해석 가능성을 동시에 제공한다.  

## Results  
DynaGuard-8B는 DynaBench 및 6개 안전성 벤치마크에서 기존 모델을 능가하며, 사용자 정의 정책에 대한 탐지 정확도와 추론 속도 모두 우수함을 보였다.  

## Limitations  
설명문을 활용한 다중 에이전트 복구 전략과 인간 신뢰성 향상에 관한 연구가 추가적으로 필요하다.  

## Conclusion  
DynaGuard는 유연하고 빠르며 해석 가능한 차세대 가디언 모델로, 다양한 실무 환경에 맞춤형 안전장치를 제공할 수 있는 가능성을 제시하였다.

# 15. [GenCompositor: Generative Video Compositing with Diffusion Transformer](https://arxiv.org/abs/2509.02460)

## Introduction
- 본 논문은 동적 전경 영상을 사용자가 지정한 위치, 크기, 경로에 따라 배경 영상에 자연스럽게 합성하는 새로운 영상 편집 과제인 생성적 영상 합성(generative video compositing)을 제안한다.  
- 기존 영상 합성 작업은 고도의 숙련자 협업과 다수의 작업 단계를 필요로 하여 제작 기간이 길고 비용이 높다는 문제점이 존재한다.  
- 따라서 본 연구는 확산 변환기(Diffusion Transformer) 기반의 GenCompositor라는 모델을 개발하여 자동으로 전경 영상의 정체성과 움직임을 유지하며 배경 영상과 일관성을 가진 합성을 가능하게 하였다.  

## Method  
- 제안한 방법은 배경 영상 유지용 경량 확산 변환기 분기, 전경 조건을 완전 자기 주의(full self-attention)로 융합하는 DiT 합성 블록, 그리고 전경과 배경 영상의 비정렬 레이아웃을 처리하는 확장 로터리 위치 임베딩(ERoPE)으로 구성된다.  
- 입력된 전경 마스크 동영상은 사용자가 지정한 크기와 경로에 따라 조정 및 위치 변경되며, 마스크 팽창과 조명 보강 기법을 통해 모델의 일반화 능력과 합성 현실감을 높였다.  
- 학습에는 6B 크기의 변환기와 고품질 데이터셋 VideoComp를 사용하였으며, VAE 기반의 잠재 공간에서 단계적 잡음 제거 방식을 통해 최종 합성 영상을 생성한다.  

## Results  
- 실험 결과, 제안한 GenCompositor는 영상 조화 및 궤적 제어 영상 생성 관련 최신 기법들을 비교 평가한 결과 모든 지표에서 우수한 성능을 보이며 사용자 지정 경로와 크기에 따른 전경 합성에서 일관성과 사실성을 크게 향상시켰다.  

## Limitations  
- 본 연구는 극단적 조명 조건과 복잡한 전경 폐색(occlusion) 변화에 대한 대응이 부족하며, 이러한 상황을 위한 심층 조명 보강 및 3D 정보 활용은 향후 연구 과제로 남아 있다.  

## Conclusion  
- 본 논문은 사용자 지정 조건을 충실히 반영하여 배경 영상과 조화로운 동적 전경 영상을 자동 합성하는 최초의 생성적 영상 합성 모델과 데이터셋을 제시하며, 이를 통해 영상 편집 및 효과 생성의 자동화 가능성을 입증하였다.

# 16. [DCPO: Dynamic Clipping Policy Optimization](https://arxiv.org/abs/2509.02333)

## Introduction
- Goal: 본 논문은 대형 언어 모델의 강화 학습에서 토큰 수준 탐색과 보상 활용의 효율을 개선하기 위해 동적 클리핑 정책 최적화(DCPO)를 제안하는 것을 목표로 한다.  
- Motivation: 기존의 GRPO 및 DAPO 방식은 고정된 클리핑 경계와 동일 보상 보정 기법으로 인해 제로 그래디언트 문제와 낮은 샘플 효율성을 보이며, 이로 인해 모델 탐색과 응답 데이터 활용에 한계가 존재한다.  
- Contribution: DCPO는 토큰별 사전 확률에 기반하여 클리핑 경계를 동적으로 조절하는 기법과 누적 훈련 단계 전반에 걸친 부드러운 보상 표준화 기법을 도입하여 토큰 및 응답 수준 탐색 및 효율성을 개선하였다.  

## Method  
DCPO는 (i) 토큰별 이전 확률 분포에 따라 클리핑 경계를 동적으로 적응시켜 저확률 토큰 탐색 공간을 넓히고, (ii) 누적 보상 분포를 활용하여 높은 엔트로피 샘플링에 의한 보상 변동성을 완화하는 부드러운 이점 표준화 방식을 적용하며, (iii) 응답 단위 내 토큰 평균 손실만 계산하여 같은 프롬프트의 응답 간 상대적 이점 관계를 보존하도록 설계되었다.  

## Results  
DCPO는 Qwen2.5 수학 모델 4종에 걸친 4개 수학 추론 벤치마크에서, AIME24-Avg@32 기준 7B 모델에서 38.8의 성능(기존 GRPO 32.1, DAPO 31.6 대비 우수)을 포함하여, 평균 28% 향상된 응답 이용률, 2배 향상된 훈련 효율, 그리고 10배 이상 감소한 토큰 클리핑 비율을 달성하였다.  

## Limitations  
본 연구는 DCPO의 적용 영역 및 다양한 언어 모델 외 확장 가능성에 대한 심층 평가가 미흡한 점을 보인다.  

## Conclusion  
DCPO는 고정 클리핑과 기존 표준화 한계로 인한 제약을 극복하여 대형 언어 모델 강화 학습에서 토큰 탐색성과 데이터 활용 효율을 크게 개선함으로써 수학 추론 능력 향상에 실질적인 기여를 하였다.

# 17. [OpenVision 2: A Family of Generative Pretrained Visual Encoders for   Multimodal Learning](https://arxiv.org/abs/2509.01644)

## Introduction
- 본 논문의 목적은 OpenVision의 아키텍처와 손실 함수를 단순화하여 멀티모달 학습에서의 학습 효율성을 향상시키는 것이다.  
- 기존 OpenVision은 텍스트 인코더와 대조 학습 손실을 포함해 학습 비용과 메모리 소모가 높아 확장성에 제약이 있었다.  
- OpenVision 2는 텍스트 인코더와 대조 손실을 제거하고 캡션 생성 손실만을 활용하는 경량화된 생성적 학습 방식을 제안한다.  

## Method  
OpenVision 2는 이미지 인코더와 텍스트 디코더 두 모듈로 구성되며, 이미지-텍스트 대조 학습을 제거하고 오로지 캡션 생성 손실만으로 학습된다.  
학습 중 이미지 토큰의 약 2/3를 무작위 마스킹하여 계산량을 줄이고, 텍스트 디코더의 부하를 감소시키는 전략을 도입하였다.  
기존 대비 더 높은 품질의 대규모 합성 캡션 데이터셋(ReCap-DataComp-1B v2)을 사용하여 생성적 학습을 최적화하였다.  

## Results  
OpenVision 2는 OpenVision과 유사하거나 더 우수한 멀티모달 벤치마크 성능을 유지하며, 학습 시간과 메모리 사용량에서 각각 약 1.5배에서 2배의 개선을 이루어 최대 10억 개 이상의 모델 파라미터까지 확장 가능함을 입증하였다.  

## Limitations  
학습 효율성과 성능 향상에 집중한 반면, 텍스트 인코더를 제거함에 따른 의미적 정합성이나 일부 태스크에서의 성능 저하 가능성에 대한 심층 분석은 부족하였다.  

## Conclusion  
OpenVision 2는 캡션 생성 손실만을 활용한 단순하고 효율적인 생성적 시각 인코더 학습 패러다임을 제시하며, 멀티모달 기초 모델의 확장성과 학습 자원 절약에 유용한 대안임을 입증하였다.

# 18. [Benchmarking Optimizers for Large Language Model Pretraining](https://arxiv.org/abs/2509.01440)

## Introduction
- Goal: 본 연구의 목표는 대규모 언어 모델(LLM) 사전 학습에서 다양한 최적화 기법을 표준화된 실험 환경 하에 체계적으로 벤치마킹하는 것이다.  
- Motivation: 최근 LLM의 발전과 함께 다양한 최적화 방법이 제안되었으나, 실험 프로토콜의 이질성으로 인해 직접적인 비교가 어렵다는 문제가 존재하였다.  
- Contribution: 본 연구는 11종 최적화 기법을 다양한 모델 크기, 배치 크기, 학습 기간에 따라 엄밀하게 비교 및 하이퍼파라미터를 조정하여 실용적 가이드라인과 향후 연구 방향을 제시한다.  

## Method  
- Llama 유사 트랜스포머 아키텍처 기반 124M~720M 규모 모델과 520M MoE 모델을 대상으로 최대 1000억 토큰 데이터셋 FineWeb을 사용하였다.  
- AdamW 기반 여러 비교 대상 옵티마이저와 배치 크기, 학습 토큰 수에 따른 다양한 조건에서 하이퍼파라미터를 체계적으로 탐색하였다.  
- 주요 실험에는 학습률, 웜업 단계, 가중치 감쇠, 모멘텀 등 중요한 최적화 관련 하이퍼파라미터에 대한 포괄적인 어블레이션 연구가 포함되었다.  

## Results  
- AdEMAMix가 전반적으로 최고 성능을 보였으며, Signum, Lion, MARS 등 사인 기반 옵티마이저는 대규모 배치에서 AdamW 대비 우수한 성능을 나타내는 등 상황별 최적의 옵티마이저 선택이 가능하다.  

## Limitations  
- 대규모 GPU 자원을 요구하는 광범위한 탐색과 실험 설계로 인해 일부 매우 장기 학습이나 추가 아키텍처 변형에 대한 검증은 제한적이다.  

## Conclusion  
- 본 연구는 대규모 언어 모델 최적화 기법에 대한 일관된 벤치마크 기준과 실전 적용 가능성을 제공하며, 향후 LLM 최적화 연구 및 산업 응용의 토대를 마련한다.

# 19. [Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm   Simulators for Conditional Synthetic Data Generation](https://arxiv.org/abs/2509.02040)

## Introduction  
- Goal: 본 연구의 목표는 유전자 알고리즘과 대규모 언어 모델(LLMs)을 결합하여 조건부 합성 데이터를 효과적으로 생성하는 방법을 제안하는 것이다.  
- Motivation: 기존 LLM 기반 합성 데이터 생성은 데이터의 품질과 다양성을 보장하는 데 한계가 있어 자동으로 데이터 다양성을 높이고 생성기의 적응성을 개선할 필요가 존재한다.  
- Contribution: 본 논문은 텍스트의 의미적 속성을 유전자 시퀀스로 간주하고, LLM을 활용하여 교차 및 돌연변이 연산을 시뮬레이션하는 Genetic Prompt 프레임워크를 제안한다.  

## Method  
Genetic Prompt는 텍스트 속성을 유전자처럼 식별하고, 능동 학습 기반 부모 샘플 선택으로 탐색 공간을 확장하며, LLM을 통해 의미 수준에서 교차 및 돌연변이 연산을 수행하여 높은 품질과 다양성의 합성 데이터를 생성한다.  

## Results  
여러 NLP 데이터셋과 작업에서 Genetic Prompt는 최첨단 기법들과 비교하여 데이터의 의미적 다양성과 실제 데이터 분포 근접성을 향상시켰으며, 합성 데이터와 실제 데이터를 결합할 경우 클래스 불균형 문제에서도 다운스트림 모델 성능이 크게 증대되었다.  

## Limitations  
본 연구는 영어 텍스트 데이터에만 적용되었으며, 기타 언어 및 비텍스트 데이터에 적용 시 방법론의 수정 및 추가 검증이 필요하다.  

## Conclusion  
Genetic Prompt는 의미 기반 유전자 연산과 능동 학습 기반 부모 선정을 통해 다양한 고품질 합성 데이터를 생성하여 광범위한 NLP 응용 분야에서 효과적임을 입증하였다.

# 20. [FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in   Diverse Adventure Games](https://arxiv.org/abs/2509.01052)

## Introduction
- Goal: 본 연구의 목표는 다양한 어드벤처 게임에서 GUI 에이전트가 전체 스토리 아크를 완성할 수 있는 능력을 평가하는 벤치마크인 FlashAdventure를 제안하는 것이다.  
- Motivation: 기존 게임 벤치마크들은 게임 종류의 다양성 부족과 전체 스토리 아크 완성을 평가하지 못하는 한계를 지니고 있었다.  
- Contribution: 본 연구에서는 Flash 기반 어드벤처 게임 34종으로 구성된 벤치마크와 자동 평가 체계인 CUA-as-a-Judge 및 장기 단서 기억을 활용하는 COAST 에이전트 프레임워크를 제안하였다.  

## Method  
FlashAdventure는 부분 관측 마르코프 결정을 기반으로 하며, GUI 에이전트가 34개 게임에서 전체 스토리 아크 달성을 목표로 행동한다. CUA-as-a-Judge는 게임 내 성공 이정표 달성을 자동으로 평가하며, COAST는 단서 탐색, 단서-관찰 매핑, 문제 해결의 순환 과정을 통해 장기 기억을 관리하며 복잡한 문제를 해결한다. 

## Results  
실험 결과, 기존 GUI 에이전트들은 전체 스토리 아크 완성에 어려움을 겪었으나 COAST는 계획 능력과 단서 기억 관리를 통해 성공률과 마일스톤 달성률을 향상시켰음에도 인간과는 큰 성능 차이가 존재하였다.  

## Limitations  
본 연구는 수작업으로 정의된 이정표에 의존하며, CUA-as-a-Judge는 플래시 어드벤처 게임에 적합하지만 빠른 동작 기반 액션 게임 등에는 적용하기 어렵다.  

## Conclusion  
FlashAdventure와 COAST를 통해 GUI 에이전트의 복잡한 장기 목표 달성 능력을 평가하고 향상시킬 수 있음을 보였으나, 인간 수준과의 격차 해소를 위한 추가 연구가 필요하다.

# 21. [M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via   Self-Supervision](https://arxiv.org/abs/2509.01360)

## Introduction
- Goal: 본 연구는 다양한 의료 영상 모달리티를 통합하여 모달리티 특화 설계 없이 제로샷 다중모달 의료 영상 검색을 가능하게 하는 통합 자기지도학습 프레임워크 M3Ret를 제안하는 것이다.  
- Motivation: 기존 방법들은 2D, 3D, 비디오 형태의 의료 영상 데이터를 각각 별도의 아키텍처와 학습 전략으로 처리하여 확장성에 한계가 존재하며, 모달리티 간 통합 표현 학습이 어렵다.  
- Contribution: 본 연구에서는 867,653개의 대규모 혼합모달 의료 영상 데이터셋을 구축하고, MAE와 SimDINO 기반의 시각적 자기지도학습을 통해 모달리티 비특화 통합 인코더를 학습시켜 기존 강력한 벤치마크 대비 우수한 성능을 달성하였다.  

## Method  
M3Ret는 2D X-ray, 초음파, RGB 내시경 비디오, 3D CT를 포함한 다양한 의료 영상 모달리티를 4D 형태로 통합 패치화하여 단일 인코더로 처리한다. MAE 기반의 픽셀 복원과 SimDINO 기반의 대조학습 두 가지 자기지도학습 방식을 활용하여 모달리티 간 표현을 횡단학습하며, 텍스트 또는 모달리티 특유의 감독 없이 학습이 이루어진다. 모달리티별 데이터 차이나 구조 차이를 극복하면서도 전역 및 세밀한 병변 정보까지 포괄적으로 학습하는 데 초점을 두었다.  

## Results  
SimDINO 사전학습된 M3Ret는 ChestXray14, Fetal Planes, Hyper Kvasir, CT-RATE 등 다양한 데이터셋에서 제로샷 이미지 간 검색 성능이 기존 언어 감독 기반 BMC-CLIP과 도메인 특화 SSL 모델 UniMiSS+를 능가하고, 심지어 MRI와 같이 사전학습에 포함하지 않은 미관측 모달리티까지도 효과적으로 일반화하였다.  

## Limitations  
다양한 의료 영상 모달리티 간 통합 학습의 가능성을 보였으나, MRI 같은 완전 미관측 모달리티에 대한 성능 향상을 위한 더 방대한 데이터와 후속 연구가 필요하다.  

## Conclusion  
본 연구는 모달리티 특화 설계 없이 대규모 혼합 의료 영상 데이터와 시각 자기지도학습을 통해 통합 표현 학습이 가능함을 입증하여, 범용 의료 영상 이해를 위한 기초 모델 개발에 중요한 초석을 제공하였다.

# 22. [The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in   LLMs with Camlang](https://arxiv.org/abs/2509.00425)

## Introduction
- Goal: 본 연구의 목표는 대형 언어 모델(LLMs)이 명시적인 문법 규칙과 어휘만으로 미지의 언어를 학습하고 사용할 수 있는지를 평가하는 것이다.  
- Motivation: LLM들이 높은 벤치마크 점수를 달성함에도 불구하고, 이러한 성과가 진정한 추론인지 단순한 패턴 매칭인지 명확하지 않기 때문에 새로운 평가 패러다임이 필요하다.  
- Contribution: Camlang이라는 자연스러우면서도 미출현 특성 조합을 지닌 인공 언어를 설계하고, 이를 통해 인간과 모델의 메타언어적 추론 능력을 비교 평가할 수 있는 인지 기반의 평가체계를 제공하였다.  

## Method  
Camlang은 문법서와 이중언어 사전이라는 두 가지 명시적 학습 자원으로 구성된 인공 언어이며, 영어 기반 CommonsenseQA 문제를 Camlang으로 번역하여 Camlang-CSQA-v0 벤치마크를 구축하였다. 이를 통해 문법 규칙과 어휘 매핑 적용 능력을 평가하며, 인간 실험으로 Camlang의 학습 가능성을 검증하였다. 여러 최신 LLM들과 인간 수행자 간 성능을 비교하고, 모델 성공 사례의 메타언어적 추론 여부를 인간이 직접 검증하였다.  

## Results  
GPT-5는 영어 CommonsenseQA에서 98% 정확도를 달성하였으나, Camlang-CSQA-v0에서는 47%에 그쳐 인간의 87% 성능에 미치지 못하였으며, 대부분의 LLM은 단순 어휘 정렬에 의존하였고 GPT-5만 부분적이지만 체계적인 문법 이해와 메타언어적 인식 능력을 일부 보여주었다.  

## Limitations  
본 연구는 초기 단계의 작업으로, Camlang과 벤치마크가 지속적으로 개선되고 확장될 예정이며, 현재 결과는 예비적이며 추가 실험과 분석이 필요하다.  

## Conclusion  
Camlang은 LLM과 인간의 메타언어적 추론력 차이를 드러내는 인지적 근거가 있는 새로운 평가 도구로서, LLM들의 진정한 언어 이해 및 추론 능력 한계를 밝히는 데 기여한다.

# 23. [Fantastic Pretraining Optimizers and Where to Find Them](https://arxiv.org/abs/2509.02046)

## Introduction
- Goal: 본 연구는 대규모 언어 모델 사전학습에서 여러 최적화 기법들의 성능을 엄격한 하이퍼파라미터 튜닝과 다양한 스케일 조건 하에서 체계적으로 비교하는 것이다.  
- Motivation: 기존 연구들은 하이퍼파라미터 최적화 불균형과 제한된 평가 환경으로 인해 실제 최적화 기법 간 성능 비교가 불공정하고 도입 실효성이 떨어졌다.  
- Contribution: 총 열한 가지 최적화 기법을 네 가지 모델 규모와 다양한 데이터 대비 모델 비율에서 다단계 하이퍼파라미터 조정 및 훈련 종료 시점 평가를 통해 객관적 속도 향상과 설계 원리를 도출하였다.  

## Method  
본 연구는 Llama 2 아키텍처 기반 0.1B~1.2B 파라미터 모델과 1~8배 Chinchilla 데이터 대비 모델 비율을 사용하였다. 하이퍼파라미터는 좌표 하강법을 활용한 세 단계에 걸친 정밀 튜닝 절차로 최적화를 수행하였으며, 주요 평가지표로는 C4-EN 언어모델링 손실과 다수의 다운스트림 벤치마크 정확도를 사용하였다. 구현은 JAX 기반 TPU v5 하드웨어에서 이루어졌으며, 스칼라 기반과 행렬 기반 최적화 기법을 포함한 11개 알고리즘을 비교하였다.  

## Results  
모든 실험 규모에서 행렬 기반 최적화 기법이 스칼라 기반보다 일관되게 우수한 성능을 보였으며, 최적 속도 향상은 최대 1.4배에 불과하고 모델 규모가 커질수록 이 값이 감소해 1.2B 파라미터에서는 약 1.1배에 머물렀다.  

## Limitations  
큰 모델 규모와 고데이터 대비 모델 비율 구간에서 기존에 주장된 2배 이상의 가속 효과는 검증되지 않았으며, 속도 향상은 제한적으로 나타났다.  

## Conclusion  
본 연구는 대규모 언어 모델 사전학습에 적합한 최적화 기법 선정 시 엄격한 하이퍼파라미터 튜닝과 다양한 스케일 환경에서의 평가가 필수적임을 실증하여 최적화 분야의 공정한 비교 및 향후 연구 방향성을 제시하였다.

# 24. [Universal Deep Research: Bring Your Own Model and Strategy](https://arxiv.org/abs/2509.00244)

## Introduction
- Goal: 본 논문은 사용자가 자유롭게 자신만의 딥 리서치 전략과 모델을 직접 정의하고 수정할 수 있는 범용 딥 리서치 시스템인 Universal Deep Research(UDR)를 제안하는 것이다.  
- Motivation: 기존 딥 리서치 툴들은 고정된 전략과 특정 모델에만 의존하여 사용자 맞춤화와 모델 교체가 어렵다는 문제점이 존재한다.  
- Contribution: UDR은 추가 학습 없이 어떠한 언어 모델에도 적용 가능하며, 사용자 정의 전략을 코드 변환하여 실행함으로써 연구 과정 전반에 사용자가 완전한 통제권을 갖도록 한다.  

## Method  
UDR는 연구 전략과 연구 요청을 입력받아 전략에 따라 단계별로 실행 가능한 코드로 변환하고, 이 코드를 격리된 환경에서 실행하여 중간 상태를 변수로 저장하며 도구 호출을 동기적으로 수행한다.  
언어 모델은 전체 연구 과정을 주도하지 않고 요약, 랭킹 등 국소적 추론에만 사용되며, 진행 상황은 사용자 정의 알림 형태로 실시간 전송된다.  
전략 구현의 일관성과 신뢰성을 위해 각 코드 부분마다 주석을 삽입하여 전략 단계와 일치하도록 하였고, 코드 실행 환경은 보안이 강화된 샌드박스로 구성된다.  

## Results  
UDR는 사용자가 완전히 맞춤화한 다양한 연구 전략(최소, 확장, 집중 전략)을 예시로 제공하며, 언어 모델과 전략 간 자유로운 조합이 가능함을 실증하였다.  

## Limitations  
UDR의 신뢰도는 언어 모델의 코드 생성 품질에 크게 의존하며, 사용자가 작성한 전략이 논리적이고 안전하다는 전제가 필수적이고 실행 중 동적 상호작용은 제한된다.  

## Conclusion  
UDR은 거의 모든 범용 생성형 언어 모델 위에 딥 리서치 도구를 적용할 수 있음을 보여주며, 사용자가 자연어로 연구 전략을 직접 프로그램할 수 있는 가능성을 제시한다.

# 25. [Discrete Noise Inversion for Next-scale Autoregressive Text-based Image   Editing](https://arxiv.org/abs/2509.01984)

## Introduction
- Goal: 본 논문은 시각적 자기회귀 모델(VAR)을 위한 최초의 노이즈 역변환 기반 텍스트-기반 이미지 편집 기법인 VARIN을 제안하는 것을 목표로 한다.  
- Motivation: 기존의 자기회귀 기반 이미지 생성 모델은 확산 모델에 필적하는 성능을 보이나, 추가 훈련 없이 프롬프트 안내 이미지 편집이 가능한 기술이 필요하였다.  
- Contribution: 논문은 argmax 샘플링의 의사역함수인 Location-aware Argmax Inversion(LAI)을 도입하여 원본 이미지의 세밀한 복원과 목표 텍스트에 부합하는 정밀한 편집을 가능하게 하였다.  

## Method  
VARIN은 VAR에서의 불연속적 argmax 연산 문제를 극복하기 위해 LAI를 통한 역감벨 노이즈 추출 방식을 도입하고, 이를 기반으로 원본 이미지를 정확히 재구성할 수 있는 편집 가능한 노이즈 집합을 생성한다. 편집 단계에서는 원본 노이즈와 새로운 감벨 노이즈를 적절히 보간하여 텍스트 지시에 따른 세밀한 이미지 변형을 수행한다. 이러한 방법은 별도의 재학습 없이도 효과적인 텍스트 유도 이미지 편집을 실현한다.  

## Results  
제안한 VARIN은 700개 이미지 편집 시나리오의 PIE-Bench 벤치마크에서 기존의 DICE, EditAR 등 모델과 비교하여 빠른 인퍼런스 속도와 함께 텍스트-이미지 정합도 및 배경 보존 성능에서 우수한 결과를 나타내었다.  

## Limitations  
HART 모델 기반 VARIN은 Paelia 대비 복원 성능이 다소 떨어져 세밀한 재현 측면에서 제한적이다.  

## Conclusion  
VARIN은 훈련 없이도 시각적 자기회귀 모델에서 텍스트 기반 이미지 편집을 효과적으로 수행하며, 향후 다른 자기회귀 모델 및 주의(attention) 제어 기법과의 통합을 통한 개선 가능성을 제시한다.

# 26. [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)

## Introduction
- Goal: 본 연구는 임베딩 기반 정보 검색 모델이 가질 수 있는 이론적 한계를 규명하는 것이다.  
- Motivation: 임베딩 모델이 다양한 복잡한 쿼리와 관련성 정의를 처리하도록 요구받는 상황에서, 기존 연구가 현실적 쿼리에서는 한계가 극복 가능하다고 가정한 점에 대해 의문을 제기하였다.  
- Contribution: 임베딩 차원과 문서 집합의 조합 가능한 top-k 관련성 표현 간의 이론적 관계를 증명하고, 이를 검증하는 실제 데이터셋 LIMIT을 제안하였다.  

## Method  
본 연구는 통신 복잡도 이론과 기하학적 대수 이론을 활용하여, 임베딩 공간 차원이 top-k 관련 문서 조합을 표현하는 데 갖는 하한선을 수학적으로 증명하였다. 최적화가 자유로운 임베딩을 실험적으로 학습시켜 이론적 한계가 실제로 존재함을 입증하였다. 아울러, 간단한 자연어 기반 쿼리와 문서로 구성된 LIMIT 데이터셋을 설계하여 여러 최첨단 임베딩 모델에서 성능 저하를 관찰하였다.  

## Results  
LIMIT 데이터셋 평가 결과, 임베딩 차원이 증가해도 최신 임베딩 모델들은 매우 단순한 쿼리임에도 불구하고 top-k 관련 문서 조합 문제에서 20% 미만의 recall@100 성능에 머물렀으며, BM25와 멀티벡터 모델만이 상대적으로 우수한 성능을 보였다.  

## Limitations  
본 연구의 실험은 임베딩 차원에 따른 이론적 하한에 초점을 맞췄으나, 복잡한 자연어 임베딩과 현실 세계 전반에 걸친 범용성을 완전하게 입증하기에는 한계가 존재한다.  

## Conclusion  
임베딩 기반 단일 벡터 검색 모델은 임베딩 차원의 제약으로 인해 모든 top-k 문서 조합을 완벽히 표현할 수 없으며, 이를 극복하기 위해 교차 인코더나 다중 벡터 기반 모델 같은 대체 접근법 연구가 필요하다.

# 27. [AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with   Knowledge Augmentation for Robust Constitutional Alignment of Language Models](https://arxiv.org/abs/2509.02133)

## Introduction
- Goal: 본 연구의 목표는 인도 사회의 카스트 및 종교 편향을 제거하고 인도 헌법의 평등·차별금지 조항에 부합하는 공정하고 중립적인 대형 언어모델 출력을 구현하는 것이다.  
- Motivation: 기존 편향 완화 기법들은 주로 서구 중심이며 인도의 특수한 사회문화적 맥락을 반영하지 못하는 한계가 존재한다.  
- Contribution: 본 논문은 헌법적 원칙에 기반한 추론 시점의 공정성 보장 추론 기법인 AMBEDKAR 프레임워크를 제안하여, 모델 내부 파라미터 수정 없이 카스트 및 종교 편향을 실질적으로 감소시킨다.  

## Method  
AMBEDKAR는 인도 헌법 제14조부터 제17조를 기반으로 한 헌법 인지 디코딩 계층을 도입하며, 추론 단계에서 소규모 초안 모델이 생성한 후보 문장들에 대해 헌법적 원칙에 맞춰 대형 언어모델이 검증하여 편향 없는 출력을 선택한다.  이 과정에서 원 문장과 반사실(대조) 문장을 생성하여 분포 차이를 통해 편향 점수를 산출하고, 이 점수를 최소화하는 방향으로 토큰을 선택하는 공정성 제약 점수화 및 순위 매김 방식을 적용한다.  반사실 데이터는 인도 사회의 카스트와 종교 집단을 중심으로 구성된 대규모 뉴스 기반 코퍼스를 활용하여 생성하며, 학습된 검증 모델은 헌법 문답식 데이터셋으로 정교하게 정렬된다.  

## Results  
평가 결과 AMBEDKAR는 다양한 언어모델에서 카스트·종교적 편향을 최대 26.41% 절대 감소시키며, 특히 힌디어 등 저자원 언어에서도 효과적인 편향 저감 성능을 보였다.  

## Limitations  
검증 모델의 편향 가능성과 문맥 수준의 의미 왜곡, 하이퍼파라미터 민감성, 이중 모델 시스템의 실용성 제약과 같은 한계가 존재한다.  

## Conclusion  
AMBEDKAR는 추론 시점에서 헌법적 공정성을 강제하는 신뢰성 높고 확장성 있는 편향 완화 프레임워크로서, 인도 사회 특성을 반영한 법적·문화적 정렬을 성공적으로 실현하였다.

# 28. [ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association](https://arxiv.org/abs/2509.01584)

## Introduction
- Goal: 본 연구는 카메라 내부 파라미터 없이 동작하는 실시간 단안 비주얼 SLAM 시스템 ViSTA-SLAM을 제안하는 것이다.  
- Motivation: 기존 SLAM 기법들은 주로 카메라 캘리브레이션을 요구하거나 복잡한 모델 구조로 인해 실시간 운용에 제약이 있었다.  
- Contribution: 본 연구는 대칭적인 두 뷰 연관성 모델(STA)을 경량 프론트엔드로 설계하고, Sim(3) 자세 그래프 최적화와 루프 클로저를 결합하여 우수한 추적 및 3D 재구성 성능을 달성하였다.  

## Method  
ViSTA-SLAM은 두 RGB 이미지로부터 상대 자세 및 로컬 포인트맵을 대칭적으로 회귀하는 STA 모델을 프론트엔드로 사용한다.  
백엔드에서는 다중 노드로 표현된 각 뷰들을 Sim(3) 자세 그래프로 구성하고, 포즈와 스케일 간의 변환을 최적화하며 루프 클로저로 드리프트를 보정한다.  
이를 통해 모델 크기를 크게 줄이고, 각 뷰가 독립적으로 최적화되어 보다 유연하고 견고한 글로벌 포즈 추정이 가능하다.  

## Results  
ViSTA-SLAM은 7-Scenes 및 TUM-RGBD 데이터셋에서 최첨단 무보정 SLAM 기법들을 능가하는 카메라 궤적 추정 정확도와 조밀한 3D 재구성 품질을 실시간으로 달성하였다.  

## Limitations  
점군 최적화가 백엔드에서 생략되어 일부 뷰포인트맵 불일치에 따른 정렬 문제를 겪을 수 있다.  

## Conclusion  
경량의 대칭적 두 뷰 모델과 강건한 Sim(3) 자세 그래프 최적화를 결합한 ViSTA-SLAM은 고성능 실시간 단안 비주얼 SLAM을 구현함으로써 다양한 카메라 환경에 적용 가능함을 보였다.

# 29. [SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction](https://arxiv.org/abs/2509.00581)

## Introduction
- Goal: 자연어 질문을 SQL 쿼리로 변환하는 Text-to-SQL 시스템의 성능과 신뢰성을 향상시키는 다중 에이전트 프레임워크 SQL-of-Thought를 제안하는 것이다.  
- Motivation: 기존 시스템들은 실행 기반의 정적 오류 수정에만 의존하여 논리적으로 잘못된 SQL 쿼리를 효과적으로 교정하지 못하는 한계가 있었다.  
- Contribution: 본 연구는 스키마 연결, 하위 문제 식별, 쿼리 계획 생성, SQL 생성, 그리고 오류 분류 체계에 기반한 동적인 오류 수정 루프를 통합한 혁신적인 다중 에이전트 구조를 설계하였다.  

## Method  
SQL-of-Thought는 여러 특화 에이전트가 연쇄적으로 작동하여 자연어 질문을 적절한 스키마에 연결하고, 하위 문제로 분해한 후 체인 오브 쏘트(Chain-of-Thought) 추론 기반 쿼리 계획을 만든다. 이후 SQL 에이전트가 쿼리를 생성하고, 실행 실패 시 오류 분류를 활용한 오류 수정 계획을 생성하는 루프가 작동하여 반복적으로 쿼리를 개선한다. 오류 수정은 9개 범주와 31개 하위 오류 유형을 포함하는 체계화된 오류 분류법에 의해 안내된다.  

## Results  
SQL-of-Thought는 Spider 데이터셋 및 변형 데이터셋에서 91.59% (Spider), 90.16% (Spider-Realistic), 82.01% (Spider SYN)의 실행 정확도를 기록하며 기존 최첨단 방법들을 능가하였다.  

## Limitations  
본 연구는 Spider 데이터셋에 한정된 평가를 수행했으며, 다중 에이전트 구조 및 고성능 대형 언어 모델 사용으로 인한 높은 추론 비용과 일반화 가능성의 제한이 있다.  

## Conclusion  
SQL-of-Thought는 스키마 연결부터 오류 수정까지 단계별 체계적 추론과 동적 안내 오류 수정을 결합하여 Text-to-SQL 변환에서 실행 정확도를 크게 향상시키는 효과적인 다중 에이전트 프레임워크임을 입증하였다.

# 30. [MobiAgent: A Systematic Framework for Customizable Mobile Agents](https://arxiv.org/abs/2509.00531)

## Introduction
- Goal: 본 논문은 실세계 모바일 환경에서 성능을 향상시킬 수 있는 맞춤형 모바일 에이전트 시스템인 MobiAgent를 제안하는 것을 목표로 한다.  
- Motivation: 기존의 GUI 기반 모바일 에이전트들은 정확도 및 효율성 측면에서 한계가 있으며, 다양한 환경에서의 실무 적용에서 여전히 과제들이 존재한다.  
- Contribution: MobiAgent는 MobiMind-series 모델, AgentRR 가속 프레임워크, MobiFlow 벤치마크 및 AI 지원 데이터 수집 파이프라인을 포함한 종합적인 체계를 구축하였다.  

## Method  
MobiAgent는 다역할 구조의 MobiMind 시리즈 에이전트, 다단계 경험을 활용해 실행 속도를 높이는 AgentRR 기록-재생 가속 프레임워크, 그리고 DAG 구조 및 다중 검증 기법을 적용한 MobiFlow 벤치마크를 포함한다. AI 보조 방식으로 GUI 작업 궤적을 수집하고, VLM을 활용한 고수준 추론을 재구성하며, 커리큘럼 학습과 자기진화 기법으로 에이전트 모델을 효과적으로 학습시킨다. AgentRR는 유사 작업의 접두어 행동 재사용과 잠재 기억 모델을 적용해 작업 실행 지연을 줄이고, 실행 오류 검출 및 갱신 방안을 포함한다.  

## Results  
MobiFlow 벤치마크 평가에서 MobiMind-Decider-7B와 MobiMind-Grounder-3B 조합은 GPT-5, Gemini-2.5-pro, UI-TARS 등 기존 일반 및 특수 목적 에이전트 모델 대비 높은 작업 완료율과 우수한 명령 수행 및 예외 처리 능력을 보였다.  

## Limitations  
환경 변화 및 UI 동적 변화로 인한 경험의 무효화 문제와 일부 복잡한 작업에서의 비완료 문제 등 일부 한계가 남아 있다.  

## Conclusion  
MobiAgent는 통합적 설계와 혁신적 가속기법, 정교한 벤치마크 프레임워크를 통해 모바일 에이전트 분야에서 현존 최고 수준의 실세계 작업 수행 능력을 증명하였다.

# 31. [Metis: Training Large Language Models with Advanced Low-Bit Quantization](https://arxiv.org/abs/2509.00404)

## Introduction
- Goal: 본 연구는 대형 언어 모델(LLM)의 저비트 양자화 기반 학습에서 발생하는 이방성(anisotropy)에 기인한 수치 분포 문제를 해결하는 방법을 제안하는 데 목적이 있다.  
- Motivation: 기존 블록 단위 양자화는 고크기 값은 유지하지만 저크기 값을 희생하여 학습 불안정성과 성능 저하를 초래하는 구조적 편향이 존재한다.  
- Contribution: 본 논문에서는 스펙트럼 분해와 무작위 임베딩을 결합하여 넓은 분포를 협소 범위로 압축하고, 적응형 학습률 및 이중 범위 정규화를 통합한 Metis 프레임워크를 제안한다.  

## Method  
Metis는 (1) 무작위 투영을 이용한 효율적인 저차원 스펙트럼 분해를 통해 지배적 및 장기 꼬리 성분을 분리하고 (2) 스펙트럼 도메인에서 적응 학습률을 적용하여 저평가된 특성을 증폭시키며 (3) 수치 정밀도와 파라미터 분포를 동시에 제한하는 이중 범위 정규화를 수행하여 안정적인 저비트 학습을 실현한다.  

## Results  
Metis는 FP8에서 FP32와 동등하거나 그 이상의 성능을 달성하고, FP4에서도 FP32 수준에 근접한 정확도를 유지하여 고성능 저비트 학습의 실용성을 입증하였다.  

## Limitations  
현재 결과는 1억 파라미터 규모 모델 및 일부 공개 데이터셋에 한정되어 있으며, 더 큰 모델과 광범위한 데이터셋에 대한 검증은 추후 진행 중이다.  

## Conclusion  
Metis는 이방성으로 인한 수치 분포 문제를 효과적으로 완화하여 대형 언어 모델의 저비트 정밀도 훈련을 안정화하고 성능 저하를 극복하는 실질적 해법으로 제시되었다.

# 32. [Stairway to Fairness: Connecting Group and Individual Fairness](https://arxiv.org/abs/2508.21334)

## Introduction
- Goal: 본 연구는 추천 시스템에서 그룹 공정성과 개인 공정성 평가 척도 간의 관계를 실증적으로 분석하는 데 목적이 있다.  
- Motivation: 기존 연구들은 서로 다른 평가 척도와 공정성 목표를 사용하여 두 공정성 유형을 비교하는 데 한계가 있었다.  
- Contribution: 동일한 평가 척도를 사용하여 그룹 공정성과 개인 공정성을 비교하며, 두 공정성 유형이 실질적으로 상이할 수 있음을 최초로 실증적으로 증명하였다.  

## Method
- 세 개의 추천 시스템 데이터셋에 대해 여러 사용자 민감 속성 기준으로 집단을 구성하고, 동일한 평가 척도(예: 지니 계수)를 활용하여 그룹 및 개인 공정성을 측정하였다.  
- 대규모 언어 모델 기반 추천기들에 대해 민감 정보 포함 여부에 따라 성능과 공정성을 평가하였다.  
- 다양한 공정성 척도들을 상호 비교하고, 그룹 내·외 공정성 및 개인 공정성의 상관관계를 분석하였다.  

## Results
- 그룹 공정성이 높은 추천 결과가 개인 단위에서는 매우 불공정할 수 있으며, 그룹 공정성 평가가 개인별 불공정을 은폐하는 경우가 많았다.  

## Limitations
- 본 연구는 주로 사용자 공정성에 초점을 두었으며, 아이템(제공자) 공정성에 관한 경험적 분석은 포함하지 않았다.  

## Conclusion
- 추천 시스템 공정성 평가는 그룹 공정성뿐만 아니라 개인 공정성 및 그룹 내 공정성까지 병행하여 측정해야 하며, 두 공정성 간 단순 대체는 불가능하다는 점을 명확히 하였다.

# 33. [Flavors of Moonshine: Tiny Specialized ASR Models for Edge Devices](https://arxiv.org/abs/2509.02523)

## Introduction
- Goal: 본 연구는 다양한 소수 언어를 지원하는 27M 매개변수 크기의 경량 단일언어 자동 음성 인식(ASR) 모델인 Moonshine Tiny를 개발하는 것이다.  
- Motivation: 기존 다국어 ASR 모델이 비영어권 언어에서 성능이 낮아 on-device 환경에서 효과적인 소형 모델 개발의 필요성이 대두되었다.  
- Contribution: Moonshine Tiny 모델은 고품질 인간 라벨, 의사 라벨, 합성 데이터를 활용하여 Whisper Tiny 대비 평균 오류율을 48% 감소시키고, 크기 대비 9배 이상의 Whisper Small 및 대다수 28배 크기의 Whisper Medium보다 동등하거나 우수한 성능을 달성하였다.  

## Method  
Moonshine Tiny는 로터리 위치 임베딩을 적용한 인코더-디코더 구조로, 입력 음성 길이에 비례한 효율적 계산방식을 사용하여 빠른 추론 속도를 가진다.  
데이터는 공개 데이터셋 집계, 공개 음성 데이터의 의사 라벨링, 텍스트-투-스피치를 이용한 합성 음성 생성의 세 단계로 수집 및 보강하였다.  
모델은 8개의 고성능 GPU에서 일정한 학습률과 AdamW 옵티마이저를 활용해 8에폭 동안 학습하였다.  

## Results  
Moonshine Tiny는 모든 평가에서 Whisper Tiny를 크게 앞서고, Whisper Small(9배 크기)보다 우수하며 대부분 언어에서 Whisper Medium(28배 크기)과 동등하거나 더 나은 성능을 보였다.  

## Limitations  
저자들은 저자원 언어 및 하위 저자원 언어에 대해 데이터 부족 문제를 해결하기 위해 더 많은 합성 음성 및 데이터 증강 기법 적용이 필요하다고 제시하였다.  

## Conclusion  
Moonshine Tiny는 소형 단일언어 ASR 모델이 다국어 대비 우수한 정확도 및 낮은 지연시간으로 on-device 음성 인식을 가능케 하며, 저자원이었던 6개 언어에 대해 공개 라이선스로 가중치를 배포하였다.

# 34. [MedDINOv3: How to adapt vision foundation models for medical image   segmentation?](https://arxiv.org/abs/2509.02379)

## Introduction  
- Goal: 본 연구는 비전 파운데이션 모델을 의료 이미지 분할에 효과적으로 적응시키는 방법을 제안하는 데 목적이 있다.  
- Motivation: 기존 딥러닝 기반 분할 모델은 주로 특정 과제에 최적화되어 있어 다양한 영상 모달리티와 기관 간 일반화가 어려우며, 자연 이미지에 사전학습된 대규모 파운데이션 모델 활용의 어려움이 존재한다.  
- Contribution: 본 연구는 비전 트랜스포머 기반 DINOv3을 의료 영역에 맞게 다룰 수 있도록 단순하지만 효과적인 다중 스케일 토큰 집계 아키텍처를 설계하고, 대규모 CT-3M 데이터셋을 활용한 도메인 적응 사전학습을 수행하여 여러 공개 벤치마크에서 최첨단 성능을 달성하였다.  

## Method  
본 연구는 평범한 비전 트랜스포머(ViT)의 구조를 재설계하여 중간 토큰을 다중 스케일로 병합하는 계층적 표현을 도입하고 이를 통해 공간적 맥락 정보를 강화하였다. 또한 DINOv3의 3단계 자기지도 사전학습 방식을 CT-3M 대규모 축면 CT 영상 데이터에 적용하여 의료 영상 도메인에 특화된 견고한 밀집 특징을 학습시켰다. 마지막으로, 고해상도 입력을 사용하는 학습 단계를 포함하여 세밀한 구조 보존과 특성 전이를 극대화하였다.  

## Results  
MedDINOv3는 AMOS22, BTCV, KiTS23, LiTS 등 4개 공개 CT/MRI 벤치마크에서 기존 강력한 CNN 기반 nnU-Net을 포함한 여러 경쟁 기법을 능가하거나 맞먹는 우수한 분할 성능을 보였다.  

## Limitations  
Gram anchoring 단계는 본 실험 환경에서 분할 성능 향상에 미미한 효과만을 나타내어 필수적이지 않으며, 전체 사전학습 과정 중 일부 단계는 재현성과 효율성 면에서 개선 여지가 존재한다.  

## Conclusion  
MedDINOv3는 간단한 아키텍처 개선과 도메인 적응형 사전학습을 결합하여 의료 영상 분할을 위한 비전 파운데이션 모델의 효용성을 입증하였으며, 이는 전문 CNN 기법과 경쟁 가능한 통합적 백본 솔루션을 제공함을 시사한다.

# 35. [Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs](https://arxiv.org/abs/2509.01790)

## Introduction
- Goal: 본 연구의 목표는 LLM 평가에서 보고된 높은 프롬프트 민감도가 모델 고유의 약점인지 평가 과정의 인위적 산물인지를 재고하는 것이다.  
- Motivation: 기존 연구들은 프롬프트 문구 변경에 따른 LLM 성능 변화가 심각하다고 여겼으나, 이는 모델의 다양하고 올바른 답변 표현을 평가 방법이 제대로 반영하지 못하기 때문일 수 있다.  
- Contribution: 7개의 LLM과 6개 벤치마크, 12가지 다양한 프롬프트 템플릿을 활용하여 전통적 휴리스틱 평가 방법과 LLM 자체를 평가자로 사용하는 방법을 비교분석하였다.  

## Method  
다양한 프롬프트 템플릿을 자동 생성하여 LLM의 프롬프트 민감도를 측정하였다. 전통적인 로그 가능도 기반 휴리스틱 평가와 달리, LLM을 평가자로 활용하여 의미적 동등성을 기반으로 답변을 판단하였다. 프롬프트 민감도는 성능 변동폭과 모델 순위 일관성으로 정량화하였다.  

## Results  
휴리스틱 평가에 비해 LLM-평가자 방식을 사용할 경우, 여러 벤치마크에서 모델의 프롬프트별 성능 변동과 순위 불안정성이 대폭 감소하였으며, 인간 평가자와도 높은 일치도를 보였다.  

## Limitations  
계산 자원 한계로 인해 각 벤치마크별 최대 12개의 프롬프트 템플릿만 평가에 사용되었으나, 제한된 수임에도 분석 결과가 안정적이었다.  

## Conclusion  
LLM 평가에서 드러난 프롬프트 민감도는 모델의 본질적 한계가 아니라 휴리스틱 평가 방식의 한계에서 기인하는 평가산물임을 규명하였다.

# 36. [Improving Large Vision and Language Models by Learning from a Panel of   Peers](https://arxiv.org/abs/2509.01610)

## Introduction
- Goal: 본 논문은 여러 대형 비전-언어 모델(LVLM) 간의 상호 평가와 피드백을 통해 성능을 향상시키는 Panel-of-Peers(PoP) 학습 프레임워크를 제안하는 데 목적이 있다.  
- Motivation: 기존의 LVLM 정렬 방법은 고비용의 인간 선호 데이터나 질이 제한적인 기계 생성 데이터에 의존하며, 자기지도 학습에서는 환각 문제 등이 발생하는 한계가 존재하였다.  
- Contribution: 본 연구는 동료 모델들이 서로 평가하고 학습하는 자가 개선 반복 과정을 통해 대규모 인간 레이블 데이터 없이도 성능을 향상시키는 새로운 패러다임을 제시하였다.

## Method  
PoP는 동일한 훈련 데이터로 학습된 동급 모델들로 패널을 구성하여, 각 모델이 주어진 이미지-질문 쌍에 대해 답변을 생성하고 서로의 답변을 5개 평가 축(도움됨, 정확성, 다변성, 일관성, 복잡성)을 기준으로 평가하여 보상 점수를 산출한다. 이 점수를 기반으로 우수 및 열등 답변 쌍을 선정하여 선호 데이터셋을 구축하고, 이 데이터를 활용하여 패널 내 모든 모델을 반복적으로 선호 기반 미세조정한다. 각 iteration마다 후보 답변 생성과 평가, 미세조정 과정을 반복하여 모델 성능을 점진적으로 개선한다.

## Results  
PoP는 15개 다양한 벤치마크에서 평균 정확도를 기존 48%에서 57%로 크게 향상시키며, 단일 모델 대비 향상된 앙상블 평가 및 자기 개선 효과를 입증하였다.

## Limitations  
본 방법은 패널에 포함된 모델 간 초기 성능이 유사해야 하며, 평가 및 학습 과정에서 상당한 연산 자원이 요구된다.

## Conclusion  
Panel-of-Peers 학습은 상호 평가와 반복 학습을 통해 LVLM의 성능과 정렬을 효과적으로 개선할 수 있는 확장 가능하고 실용적인 자기개선 프레임워크임이 확인되었다.

# 37. [Towards More Diverse and Challenging Pre-training for Point Cloud   Learning: Self-Supervised Cross Reconstruction with Decoupled Views](https://arxiv.org/abs/2509.01250)

## Introduction
- Goal: 본 연구의 목표는 두 개의 분리된 시점(뷰)을 생성하고 상호 재구성을 수행하는 새로운 자기지도 학습 방식인 Point-PQAE를 제안하여 3D 점군 학습의 사전학습을 더욱 다양하고 도전적으로 만드는 것이다.  
- Motivation: 기존 점군 자기지도 생성학습은 단일 뷰 내 가려진 점을 복원하는 데 집중하여 도전성과 정보량이 제한적이므로, 두 개의 뷰를 활용한 교차 재구성을 통해 보다 풍부한 표현 학습이 가능하다는 점에 주목하였다.  
- Contribution: 본 연구는 최초로 점군 데이터에 적합한 랜덤 크롭 메커니즘과 3D 상대 위치를 인코딩하는 뷰 상대 위치 임베딩(VRPE), 그리고 이를 활용한 위치 인식 쿼리 모듈을 제안하여 교차 재구성 기반 사전학습 프레임워크를 구성하였다.  

## Method  
랜덤으로 선택된 중심점을 기준으로 점군을 크롭하여 두 개의 분리된 뷰를 생성하고, 각 뷰에 무작위 회전을 적용하여 좌표계 분리를 유도한다.  
두 뷰의 상대 위치 정보를 뷰 상대 위치 임베딩(VRPE)으로 고정 표현하며, 이를 쿼리로 하여 한 뷰의 잠재 표현에서 다른 뷰를 재구성하는 위치 인식 쿼리 블록을 도입하였다.  
인코더-디코더 구조의 트랜스포머 기반 네트워크를 활용해 뷰 간 교차 재구성을 수행하며 Chamfer 거리 기반 손실함수로 학습한다.  

## Results  
제안한 Point-PQAE는 ScanObjectNN의 세 가지 평가 프로토콜에서 Point-MAE 대비 최대 약 6.7%p 향상된 분류 성능을 기록하며 다른 다수의 자기지도 및 교차모달 방법과 비교해 뛰어난 성능을 입증하였다.  

## Limitations  
제안 방법은 뷰 생성 시 크롭 비율 및 회전과 같은 하이퍼파라미터 설정에 민감하며, 복잡한 장면이나 밀집된 점군에 대해 성능 검증이 제한적이다.  

## Conclusion  
본 연구는 두 분리된 뷰 간 교차 재구성이라는 새로운 자기지도 학습 틀을 제안하여 점군 표현 학습의 도전성을 높임으로써 기존 단일 뷰 자기재구성 대비 우수한 표현력을 확보하였다.

# 38. [C-DiffDet+: Fusing Global Scene Context with Generative Denoising for   High-Fidelity Object Detection](https://arxiv.org/abs/2509.00578)

## Introduction
- 본 논문의 목표는 차량 손상 평가와 같은 미세한 객체 탐지 문제에서 전역 장면 문맥을 통합하여 고해상도 객체 탐지 성능을 향상시키는 것이다.  
- 기존 확산 기반 탐지기들은 국소 특징에만 의존해 문맥 의존적 상황에서 한계가 있으며, 이를 극복하기 위해 전역 장면 문맥 결합이 필요하다.  
- 기여로는 전역 장면 인코더를 통한 전역 문맥 추출 및 컨텍스트 인지 융합 메커니즘 도입, 그리고 최첨단 수준의 CarDD 벤치마크 성능 달성이 있다.  

## Method  
제안하는 C-DiffDet+는 DiffusionDet 아키텍처를 기반으로 Adaptive Channel Enhancement(ACE) 블록과 전역 문맥 인코더(Global Context Encoder, GCE)를 활용하여 다중 스케일 특징과 전역 장면 정보를 융합하는 Context-Aware Fusion(CAF) 모듈을 통해 객체 제안의 문맥 인지를 강화한다. 또한 글로벌 문맥 임베딩을 포함한 향상된 다중모달 융합(MMF) 구조를 사용해 시간, 위치 및 문맥 정보를 통합한다. 이로써 확산 기반 복원 과정 속에서 각 객체 제안이 전역 장면 정보를 참조하여 점진적이고 정밀한 위치 보정을 수행한다.  

## Results  
CarDD 데이터셋에서 C-DiffDet+는 평균 정밀도(AP) 64.8%를 달성하여 이전 최고 기록 대비 1.4% 향상시켰으며, 특히 작은 객체 탐지(AP_S 45.5%)와 고정밀 객체 위치(AP_75 67.9%)에서 두드러진 성능 개선을 보였다.  

## Limitations  
중간 크기 객체 탐지에서는 DCN+ 대비 성능이 8.8% 낮아 일부 복잡한 지오메트리 손상 탐지에서는 추가적인 지역적 특징 처리 방식이 요구된다.  

## Conclusion  
본 연구는 전역 장면 문맥과 확산 기반 객체 탐지의 반복적 정제 과정을 융합함으로써 미세한 시각 영역에서의 문맥 인지 성능 한계를 극복하고, 차량 손상 평가와 같은 도메인에서 견고한 최첨단 객체 탐지를 구현하였다.

# 39. [FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable   Diffusion Models](https://arxiv.org/abs/2508.20586)

## Introduction
- Goal: 본 연구의 목표는 다중 참조 이미지를 활용하는 가상 착용(Multi-Reference Virtual Try-On) 기술의 처리 효율과 품질을 동시에 향상하는 고속 프레임워크 FastFit을 제안하는 것이다.  
- Motivation: 기존 가상 착용 기법은 다중 의상 및 액세서리 조합 지원의 부재와 반복적인 참조 피처 재계산으로 인한 처리 비효율성이라는 두 가지 주요 한계에 직면해 있다.  
- Contribution: FastFit은 참조 이미지 인코딩을 디노이징 과정에서 분리하는 캐쉬 가능한 확산 모델 아키텍처를 도입하여 평균 3.5배의 가속을 달성하고, 다중 참조 가상 착용을 위한 대규모 DressCode-MR 데이터셋을 구축하였다.  

## Method  
FastFit은 클래스 임베딩과 세미-어텐션 메커니즘을 통해 참조 아이템 특징 인코딩을 시간 단계 의존성에서 분리하여, 참조 피처를 한번만 계산하고 모든 디노이징 단계에서 재사용하도록 설계되었다. 이를 통해 참조 피처의 중복 계산을 제거하고 캐쉬 기반 병렬 처리로 속도 향상을 이루었다. 더불어, 의상과 액세서리 5개 카테고리를 아우르는 멀티 참조 가상 착용을 위해 DressCode-MR 데이터셋을 제안하였다.  

## Results  
FastFit은 VITON-HD, DressCode, DressCode-MR 데이터셋에서 기존 최첨단 방법에 비해 이미지 재현 품질과 빠른 추론 속도(평균 3.5배 향상)를 동시에 달성하였다.  

## Limitations  
복잡한 의상 물리적 상호작용 및 레이어링 모델링과 실시간 대화형 응용을 위한 추가적인 효율 개선이 향후 연구로 남아 있다.  

## Conclusion  
FastFit은 캐쉬 가능한 확산 모델 구조를 통해 다중 참조 가상 착용의 효율성과 사실성을 동시에 개선하며, 전자상거래 및 지능형 스타일 시각화 분야에서의 실용적 적용 가능성을 크게 확장하였다.
