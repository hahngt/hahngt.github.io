---
layout: post
title: Daily Papers — 2025-09-06"
date: 2025-09-06 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth](https://arxiv.org/abs/2509.03867)

## Introduction
- Goal: 본 연구는 Drivelology라 명명된 “깊이를 지닌 무의미한 언어 현상”의 해석 능력을 평가하여 대형 언어 모델(LLM)의 의미론적 및 화용론적 이해 한계를 규명하는 것을 목표로 한다.  
- Motivation: LLM이 언어적 유창성과 많은 과제에서 뛰어난 성과를 보이나, 표면적으로는 비문법적이지 않으면서도 함의적 의미와 문화적 맥락을 요구하는 복합적인 표현인 Drivelology를 제대로 이해하지 못하는 문제의식에서 출발하였다.  
- Contribution: 다양한 언어(영어, 만다린, 스페인어, 프랑스어, 일본어, 한국어)를 포함하는 1,200여 개의 엄밀히 검증된 Drivelology 사례로 구성된 DRIVELHUB 데이터셋과 4가지 평가 과제를 제안하여, 다수의 최신 LLM을 다면적으로 평가하였다.  

## Method  
Drivelology 샘플 수집은 인터넷 내 젊은 층 위주의 SNS 플랫폼 자료에서 이루어졌으며, 엄격한 전문가 다단계 검토와 합의 과정을 통해 레이블링 및 내재된 의미 서술이 완성되었다.  
본 연구에서는 Drivelology 탐지, 태깅, 함의적 내러티브 생성, 선택 등 4가지 과제를 설계하여 각 모델의 다층적 의미 해석 능력을 검증하였다.  
주요 평가 대상 모델로는 GPT-4, Claude-3, Qwen3 및 Llama3 등 상용 및 공개형 LLM이 포함되었으며, 다양한 언어적 프롬프트 효과도 분석되었다.  

## Results  
Deepseek-v3 모델이 6개의 평가 지표 중 5개에서 최고 성능을 기록하였으며, 특히 복잡한 내러티브 논리 추론 과제에서 모델 크기 확장에 따른 실질적 성능 향상이 뚜렷하게 관찰되었다.  

## Limitations  
데이터셋 내 만다린어 표본의 과다 편중과 예산 및 계산 자원 제한으로 인해 보다 대형 혹은 신형 LLM에 대한 평가가 제한된 점이 존재한다.  

## Conclusion  
Drivelology 현상을 통해 LLM의 표면적 문법 이해를 넘어서는 심층적, 비선형적 의미와 사회문화적 맥락 인식의 어려움을 밝힘으로써, 향후 보다 창의적이고 맥락 민감한 AI 언어 모델 개발의 필요성을 제기하였다.

# 2. [From Editor to Dense Geometry Estimator](https://arxiv.org/abs/2509.04338)

## Introduction
- 본 연구의 목표는 이미지 편집 기반 모델을 밀도 기하학 추정에 적응시켜 단안 영상의 깊이 및 법선 정보를 효과적으로 예측하는 것이다.  
- 기존의 텍스트-이미지 생성 모델보다 이미지 편집 모델이 구조적 사전지식을 내포하여 밀도 기하학 예측에 더 적합하다는 점에 착안하였다.  
- 이에 본 연구에서는 Diffusion Transformer 기반 편집 모델 Step1X-Edit를 활용, 새로운 손실 함수와 로그 양자화 기법을 도입한 FE2E 프레임워크를 제안하였다.  

## Method  
이미지 편집 과제를 밀도 기하학 추정 문제로 재정의하고, 기존 flow matching 손실 함수를 일관된 속도 기반 손실로 개편하여 안정적인 수렴을 도모하였다.  
BFloat16 정밀도와 고정밀도 요구 간 충돌을 해결하기 위해 로그 깊이 양자화 방식을 채택하였으며, 깊이와 법선의 공동 추정을 하나의 순전파로 비용 없이 수행하는 기법을 개발하였다.  
훈련은 Step1X-Edit 모델에 LoRA를 적용하고, 하이퍼심 및 Virtual KITTI 데이터셋을 활용하여 제한된 데이터로 진행되었다.  

## Results  
FE2E는 7만장 미만의 데이터만으로 ETH3D에서 기존 최첨단 모델 대비 35% 이상의 절대 상대 오차 감소를 포함해 5개 벤치마크에서 두드러진 제로샷 성능 향상을 보였다.  

## Limitations  
제안된 방법은 불확실성 예측보다는 결정론적 추정에 초점을 맞추어, 다양한 불확실성을 반영하는 장면에서는 한계가 있을 수 있다.  

## Conclusion  
FE2E는 이미지 편집 모델의 내재된 구조적 사전지식을 효과적으로 활용하여, 데이터 효율적이고 안정적인 밀도 기하학 예측을 구현함으로써 ‘편집자에서 추정기로’의 새로운 패러다임을 제시하였다.

# 3. [Towards a Unified View of Large Language Model Post-Training](https://arxiv.org/abs/2509.04419)

## Introduction
- Goal: 본 논문은 대규모 언어 모델의 사후 학습(Post-Training) 과정에서 강화학습과 지도학습을 통합하는 통합 정책 기울기 추정기(Unified Policy Gradient Estimator)를 제안하는 데 목적이 있다.  
- Motivation: 기존 강화학습(RL)과 지도미세조정(SFT)이 서로 대립적인 방법처럼 인식되었으나, 두 기법이 본질적으로 단일 최적화 과정의 다양한 사례임을 밝힘으로써 효율적 통합법을 탐구하고자 한다.  
- Contribution: 다양한 사후 학습 기법을 하나의 통합 이론적 틀로 통합하고, 이 기반 위에서 성능 피드백을 활용해 RL과 SFT 손실을 동적으로 조절하는 혼합 사후 학습 알고리즘(Hybrid Post-Training, HPT)을 제안하였다.  

## Method  
본 연구는 SFT와 RL의 기울기 계산을 공통의 수학적 형태인 Unified Policy Gradient Estimator로 통합하였다. 이 추정기는 안정화 마스크, 기준 정책 분모, 이점 추정, 우도 기울기 네 가지 구성요소로 분해된다. 이를 토대로 성능 피드백을 활용해 RL 손실과 SFT 손실 비중을 상황에 맞게 동적으로 조정하는 HPT 알고리즘을 설계하였다.

## Results  
Qwen 및 LLaMA 모델을 대상으로 한 6개의 수학적 추론 벤치마크와 2개의 분포 외 평가에서 HPT는 기존 SFT, GRPO, SFT→GRPO, LUFFY 등의 강력한 기준선 대비 일관되게 우수한 성능을 보여주었다.

## Limitations  
동적 혼합 가중치 결정에서 단순한 임계값 기반 스위치 함수만을 사용하였으며, 보다 정교한 적응형 조절 방식에 대한 연구는 부족하다.

## Conclusion  
본 연구는 대규모 언어 모델의 사후 학습에서 RL과 SFT가 통합 가능한 단일 최적화 문제임을 수학적으로 규명하고, 이를 기반으로 성능 기대치를 반영하는 혼합 사후 학습 기법으로 학습 효율과 성능을 크게 향상시켰다.

# 4. [Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow   Real Instructions?](https://arxiv.org/abs/2509.04292)

## Introduction
- 본 연구의 목표는 큰 언어 모델(LLM)이 기존 학습 관습에 얽매이지 않고 실제 반직관적(inverse) 명령을 준수할 수 있는 능력인 ‘Counter-intuitive Ability’를 평가하는 벤치마크인 Inverse IFEval을 제안하는 것이다.  
- 기존 LLM들은 지도학습 및 인간 피드백을 통한 미세조정 과정에서 표준화된 패턴을 강하게 학습하여 비전형적 명령에 취약하며, 이로 인해 실제 사용자의 비일상적 요구를 충족하지 못하는 문제를 갖는다.  
- 본 논문은 비전형적 명령을 아우르는 여덟 가지 유형의 도전을 포함하는 Inverse IFEval을 구성하고, 이를 통해 LLM들의 인지 관성(cognitive inertia)을 진단 및 극복하는 방향을 제시한다.  

## Method  
Inverse IFEval은 표준화된 학습 패러다임을 의도적으로 전복하는 여덟 가지 반직관적 명령 유형을 체계적으로 설계하였다.  
도메인 전문가가 고품질 시드 질문을 수작업으로 작성하고, 대규모 LLM 기반 데이터 생성 및 자동 필터링, 인간 검증 과정을 거쳐 중국어·영어 통합 1,012문항의 다중 도메인 질문집을 구축하였다.  
평가에는 특정 명령 유형별 최적화된 LLM 심판 모델(LLM-as-a-Judge)을 도입하여 98%의 판정 정확도를 확보하였다.  

## Results  
여러 상위 LLM 평가 결과, 미세조정된 모델들은 Inverse IFEval에서 낮은 성능을 보였으며, 사고 메커니즘 적용 모델이 비사고 모델보다 우수한 성능을 나타내 인지 관성 해소의 난이도를 입증하였다.  

## Limitations  
Inverse IFEval에 포함된 반직관적 명령들은 실제 의미보다는 모델의 일반화 능력 평가에 중점을 둔 것이므로, 실제 응용에서의 실용성은 제한적일 수 있다.  

## Conclusion  
Inverse IFEval은 LLM들이 기존 학습에 고착된 규범을 벗어나 이상치 지시에 적응할 수 있는 정밀한 평가 틀을 제시하여, 미래 연구에서 인지 관성 극복과 명령 준수 신뢰성 향상을 위한 기반을 마련하였다.

# 5. [DeepResearch Arena: The First Exam of LLMs' Research Abilities via   Seminar-Grounded Tasks](https://arxiv.org/abs/2509.01396)

## Introduction
- Goal: 본 논문은 대규모 언어모델(LLM)의 심층 연구 역량을 평가하기 위한 DeepResearch Arena 벤치마크를 제안하는 것이다.  
- Motivation: 기존 연구 평가 기준은 정적 데이터에 의존하거나 전문가가 수작업으로 설계하여 실제 연구 현장의 동적이고 복합적인 문제 출현 양상을 반영하지 못하였다.  
- Contribution: 본 연구는 학술 세미나 기반의 실제 연구 담론을 활용하여 1만 개 이상의 고품질 연구 과제를 자동 생성하고, 다중 에이전트 계층적 과제 생성 시스템과 하이브리드 평가 프로토콜을 도입하였다.  

## Method  
DeepResearch Arena는 200여 개 학문 분야별 세미나 영상을 음성 인식으로 전사한 후, 영감을 추출하는 Inspira Agent와 연구 과제 생성 TaskWeaver Agent, 그리고 과제 품질 평가 RankEval Agent로 구성된 MAHTG(Multi-Agent Hierarchical Task Generation) 시스템으로 구축된다.  
추출된 영감은 한계, 방법론, 학제간 융합, 가설의 네 유형으로 분류되어 문헌 종합, 설계, 평가의 연구 단계별 개방형 문제로 전환된다.  
평가는 사실 기반 지표인 Keypoint-Aligned Evaluation(KAE)와 체크리스트 기반 적응형 평가인 ACE를 병합하여 연구 보고서의 정확성과 고차원 추론 능력을 정량화한다.  

## Results  
DeepResearch Arena는 다양한 최첨단 LLM들이 연구 과제 수행에 있어 명백한 성능 차이를 보이며, 특히 gpt-o4-mini-deepresearch와 gemini-2.5-flash가 높은 사실적 커버리지와 주관적 평가 점수를 달성하였다.  

## Limitations  
본 벤치마크와 평가 시스템은 세미나 전사 데이터의 한계와 일부 모델이 다언어 환경에서 성능 저하를 보이는 점 등에서 제약이 존재한다.  

## Conclusion  
DeepResearch Arena는 실제 연구 과정의 인지적 복잡성과 모호성을 반영하여 LLM 기반 심층 연구 에이전트를 전방위적으로 평가할 수 있는 이론적으로 견고하고 확장 가능한 기준을 제시한다.

# 6. [Transition Models: Rethinking the Generative Learning Objective](https://arxiv.org/abs/2509.04394)

## Introduction
- 본 논문은 생성 모델 학습 목표를 재고하여 임의의 시간 간격 상태 전이를 학습하는 전이 모델(Transition Models, TiM)을 제안하는 것을 목표로 한다.  
- 기존 확산 모델은 높은 품질을 얻지만 연산 비용이 크고, 빠른 단계 수의 대안은 품질 한계에 부딪히는 근본적인 딜레마가 존재한다.  
- TiM은 임의 단계 간 상태 전이를 정확히 정의하는 연속 시간 동역학 방정식을 도입하여, 적은 매개변수로도 최첨단 성능과 단계 수에 따른 단조로운 품질 향상을 달성한다.  

## Method  
TiM은 기존의 국소적 미분 기반 확산 모델 학습 대상과 달리 임의 시간 간격의 상태 전이 함수를 학습하는 학습 목표를 도입하였다. 이 목표는 상태 전이 정체(State Transition Identity)를 기반으로 하며 경로 일관성 및 시간 변화율 최소화를 통해 견고한 세분화 가능성을 보장한다. 또한, 효율적 미분 근사법인 차분 방정식(DDE)과 분리된 시간 및 구간 임베딩, 구간 인지 어텐션 등을 도입하여 대규모 학습과 안정성을 확보하였다.  

## Results  
TiM은 8억 6500만 개의 파라미터로 SD3.5(80억 파라미터) 및 FLUX.1(120억 파라미터)과 같은 대규모 모델을 상회하는 벤치마크 결과를 보였으며, 단계 수 증가에 따른 안정적이고 단조로운 품질 향상 및 최대 4096×4096 해상도에서도 우수한 성능을 입증하였다.  

## Limitations  
TiM은 세밀한 디테일 표현이나 텍스트, 손 등 특정 영역에서 품질 저하 및 고해상도 이미지에서 일부 아티팩트 발생 현상이 관찰되었으며, 내용 안전성 및 제어성 문제는 아직 해결 과제로 남아있다.  

## Conclusion  
본 연구는 임의 단계 상태 전이 학습을 통한 효율적이고 유연한 생성 패러다임을 제안하며, 적은 파라미터로도 다단계 세분화와 고품질 생성이 가능한 차세대 고성능 생성 모델 개발의 기초를 마련하였다.

# 7. [Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding](https://arxiv.org/abs/2508.20478)

## Introduction
- Goal: 본 논문은 장시간 영상 이해를 위해 반복적 다중 회차 추론을 수행하는 강화 학습 기반 프레임워크 Video-MTR을 제안한다.  
- Motivation: 기존 장시간 영상 이해 기법은 단일 회차 고정 프레임 샘플링이나 외부 시각-언어 모델 의존으로 복잡성과 최적화 한계가 존재하였다.  
- Contribution: 영상 구간 선택과 질문 이해를 동시에 최적화하는 게이트형 이중 레벨 보상 체계를 도입하여 다중 회차 추론을 통한 효율적이고 정확한 장영상 이해를 달성하였다.  

## Method  
Video-MTR은 MLLM으로 구성된 에이전트가 반복적으로 영상 구간을 선택하며 시퀀스별 상태를 갱신하는 다중 회차 추론 모델이다. 게이트형 이중 레벨 보상은 최종 답변 정확도 기반 궤적 보상과 구간-질문 연관도 기반 회차 보상으로 구성되어 중간 추론 과정을 효과적으로 지도한다. 강화 학습은 PPO 알고리즘을 사용하며, 데이터 부족 문제 극복을 위해 엄선된 시간적 근거 데이터셋과 탐색 부트스트래핑 전략을 적용한다.  

## Results  
Video-MTR은 VideoMME, MLVU, EgoSchema 장영상 벤치마크에서 GPT-4o를 포함한 기존 최첨단 모델과 비교하여 적은 프레임 입력에도 높은 정확도와 효율성을 보였다.  

## Limitations  
목표 지향 보상 설계로 보상 부정행위를 방지하였으나, 복잡한 장영상 및 추론 시나리오에 대해 여전히 데이터 부족과 학습 난이도 문제는 잔존한다.  

## Conclusion  
본 연구는 강화 학습과 다중 회차 추론을 결합한 최초의 장영상 이해 프레임워크 Video-MTR을 제안하여, 시간 확장성에서 우수한 성능을 입증하였으며 향후 더 긴 영상과 고난도 추론으로 확장 가능성을 시사한다.

# 8. [NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware   Embeddings](https://arxiv.org/abs/2509.04011)

## Introduction
- Goal: 본 연구는 사전 정의되지 않은 사용자 지정 타입 설명에 기반하여 특정 개체 유형을 검색하는 제로샷 명명된 개체 검색(ad-hoc Named Entity Retrieval) 프레임워크인 NER Retriever를 제안한다.  
- Motivation: 기존 NER 시스템은 고정된 개체 타입에 의존하고 대규모 라벨링 데이터가 필요하여 실제 다양한 도메인과 새로운 개체 타입에 적용이 제한된다.  
- Contribution: 본 연구에서는 대형 언어 모델(LLM)의 중간층 self-attention value 벡터를 활용한 타입 인지 임베딩과 대조학습 기반의 경량 프로젝션 네트워크를 통해 개체 및 타입 표현을 공통 공간에 임베딩하는 새로운 방법을 제안한다.  

## Method  
NER Retriever는 LLaMA 3.1 8B 모델의 17번째 트랜스포머 블록의 self-attention value 벡터에서 개체 임베딩을 추출하고, 이를 2층 MLP로 저차원 타입 인지 임베딩 공간으로 변환한다.  
유사도 기반 최근접 이웃 검색을 통해 사용자 정의 개체 타입 쿼리와 유사한 임베딩을 가진 문서들을 검색한다.  
학습은 같은 타입의 개체는 가깝게, 다른 타입은 멀리 위치하도록 트리플렛 대조 손실을 사용하여 수행된다.  

## Results  
NER Retriever는 Few-NERD, MultiCoNER 2, NERetrieve 세 개의 벤치마크에서 기존 BM25, E5-Mistral, NV-Embed v2 등 강력한 기법보다 평균 3배 이상의 성능 향상을 보이며 제로샷 세팅에서 우수한 검색 성능을 달성하였다.  

## Limitations  
LLM 내장 파라메트릭 지식에 의존하므로 법률, 의학, 금융 등 전문 도메인의 새로운 개체 타입에서 성능 저하가 발생할 수 있다.  

## Conclusion  
본 연구는 LLM 내부 표현을 효과적으로 활용하고 대조학습으로 추출한 타입 인지 임베딩을 통해 스키마 제한 없는 확장 가능한 제로샷 명명된 개체 검색을 가능하게 함을 증명하였다.

# 9. [Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers](https://arxiv.org/abs/2509.03059)

## Introduction
- Goal: 본 연구는 다양한 추론 중심 도메인에서 스케일 가능한 합성 데이터 생성과 검증을 통한 긴 사고 사슬(Chain-of-Thought) 합성을 목적으로 하였다.  
- Motivation: 수학 및 프로그래밍 분야에서는 자동 검증 가능한 정답이 존재하지만, 다른 추론 집약적 도메인에서는 고품질 검증 데이터의 부족과 인간 감독 비용의 문제로 성능 향상이 어려웠다.  
- Contribution: 12개 도메인의 8,729개 검증 데이터와 다양한 생성 전략을 지원하는 모듈식 환경을 포함하는 오픈소스 프레임워크인 Loong 프로젝트를 제안하였다.  

## Method  
Loong 프로젝트는 ① 코드 실행 및 정답 검증이 가능한 고품질 시드 데이터셋 LOONGBENCH와 ② 여러 prompting 기법을 통해 자동으로 합성QA쌍을 생성하는 LOONGENV 환경으로 구성된다.  
합성 데이터 생성 과정에서 질문과 코드 기반 답변을 생성하고, 이를 에이전트의 체인 오브 사고 결과와 비교하여 보상하는 에이전트-환경 루프를 운영한다.  
이 과정을 통해 인간 감독 최소화와 의미적 일치 보장을 통한 강화학습을 가능하게 하였다.  

## Results  
12개 도메인에서 GPT4.1-mini, o3-mini, DeepSeek-r1 등 최신 LLM을 벤치마킹한 결과, 수학 및 프로그래밍에서는 최고 100% 정확도를 나타내고, 금융, 보안, 수학적 최적화 분야 등에서는 상대적으로 낮은 성능을 보였다.  

## Limitations  
일부 도메인에서 생성된 합성 데이터는 실행 실패율과 의미적 불일치율이 높아 복잡한 prompting 전략 간 신뢰성 차이가 존재하였다.  

## Conclusion  
Loong 프로젝트는 다양한 추론 도메인에서 자동 검증 가능한 합성 데이터를 확장하여 LLM의 사고 사슬 생성 능력 향상과 대규모 강화학습 기반 추론 개선의 토대를 마련하였다.

# 10. [Few-step Flow for 3D Generation via Marginal-Data Transport Distillation](https://arxiv.org/abs/2509.04406)

## Introduction
- 목표는 사전 학습된 3D 플로우 모델을 소수의 샘플링 단계로 고속 생성 가능한 모델로 증류하는 것이다.  
- 3D 생성은 2D와 달리 고차원 희소 공간과 복잡한 기하학적 특성을 갖기에 적은 단계 내 가속화에 많은 어려움이 존재한다.  
- 본 논문에서는 주변 분포에서 데이터 분포로의 매핑을 직접 학습하는 새로운 증류 프레임워크 MDT-dist와 두 가지 최적화 목표인 Velocity Matching과 Velocity Distillation을 제안한다.  

## Method  
사전 학습된 3D 플로우 생성 모델의 속도 향상을 위해 주변 데이터 전달을 주요 목표로 설정하였고, 직접 평가가 불가능한 적분 항을 회피하기 위해 속도장 일치 및 확률 분포 증류 두 손실 함수를 도입하였다.  
Velocity Matching은 학생 모델과 교사 모델 간 속도장을 안정적으로 매칭하여 주된 목적을 간접 달성하며, Velocity Distillation은 확률 밀도 차이를 최적화하여 보다 정확한 증류를 가능하게 한다.  
이 두 목표를 결합하여 TRELLIS 모델에 적용, 기존 25단계 샘플링을 1~2단계로 줄이면서도 시각적 및 기하학적 품질을 유지하도록 학습하였다.  

## Results  
제안 방법은 TRELLIS에 적용 시 샘플링 단계를 25단계에서 1~2단계로 대폭 감소시키며, 9배 이상의 속도 향상과 함께 기존 consistency 모델 대비 우수한 시각 및 기하학적 품질을 달성하였다.  

## Limitations  
본 방법은 다량의 고품질 기하학적 데이터와 조건 이미지에 의존하여 증류 훈련이 비용과 시간이 많이 소요된다는 한계가 존재한다.  

## Conclusion  
MDT-dist는 주변-데이터 전달에 기반한 새로운 소수 단계 3D 플로우 증류 방법으로, 기존 일관성 모델들보다 안정적이고 효과적인 학습을 통해 실시간에 가까운 고품질 3D 생성 성능을 구현하였다.

# 11. [Durian: Dual Reference-guided Portrait Animation with Attribute Transfer](https://arxiv.org/abs/2509.04434)

## Introduction
- Goal: 본 논문은 참조 이미지로부터 얼굴 속성(attribute)을 전이하며 인물 초상 애니메이션을 제로샷 방식으로 생성하는 Durian 방법을 제안하였다.  
- Motivation: 기존의 얼굴 편집 및 애니메이션 기법들은 정적 이미지에 한정되거나, 다중 속성을 효율적으로 합성하지 못하며, 동영상 내 일관성을 보장하기 어렵다는 문제점이 존재하였다.  
- Contribution: Durian은 이중 참조 네트워크를 활용한 확산 모델 기반의 자기재구성(self-reconstruction) 학습과 속성 마스크 확장, 참조 이미지 증강 전략을 통해 다양한 얼굴 속성의 일관된 전이를 달성하고, 다중 속성 복합 합성을 단일 단계에서 지원한다.  

## Method  
본 방법은 속성 이미지와 초상 이미지로부터 마스크를 적용한 두 입력을 생성하고, 각기 Attribute ReferenceNet과 Portrait ReferenceNet에서 다중 해상도의 공간적 특징을 추출하여 Denoising U-Net에 주입한다.  
학습 시 동일 인물 동영상에서 두 프레임을 조합한 자기재구성 방식을 사용하며, 이를 통해 명시적 삼중 학습 데이터 없이도 속성 전이를 학습한다.  
추가로 속성의 공간적 범위 변화를 모사하는 마스크 확장과 참조 이미지 공간적·색상 변형 증강을 도입하여 실제 환경의 편차에 견고한 모델 성능을 확보하였다.  

## Results  
Durian은 다양한 얼굴 속성 전이 및 애니메이션 분야에서 기존 최첨단 방법들보다 복원 정확도, 지각 품질, 공간적 일관성 측면에서 우수한 성능을 보였다.  

## Limitations  
복합적인 속성 간 상호작용 처리, 극한 포즈에서의 속성 전이, 조명 차이로 인한 품질 저하, 얼굴 키포인트 추출 실패 시 발생하는 시간적 불안정성 등이 남은 한계로 지적되었다.  

## Conclusion  
Durian은 참조 이미지 쌍과 키포인트 시퀀스를 입력으로 하여 다양한 얼굴 속성의 자연스러운 애니메이션 영상을 제로샷 방식으로 생성하며, 다중 속성 복합 및 속성 보간 기능 또한 통합적으로 지원하는 혁신적 프레임워크임을 입증하였다.

# 12. [Delta Activations: A Representation for Finetuned Large Language Models](https://arxiv.org/abs/2509.04442)

## Introduction
- Goal: 본 연구는 기초 대형 언어 모델에 대해 미세조정된 모델들을 내적 활성화 변화로 벡터 임베딩하여 효율적으로 표현하는 방법을 제안하는 데 목적이 있다.  
- Motivation: 다수의 미세조정 모델들이 메타데이터 불일치와 비구조적 저장소로 인해 탐색 및 활용이 어렵다는 점이 문제로 대두되었다.  
- Contribution: Delta Activations라는 미세조정 모델의 내부 상태 변화를 측정하여 모델별 임베딩을 생성하고, 이 임베딩이 도메인 및 작업별 클러스터링 및 모델 선택과 병합에 활용 가능함을 보였다.  

## Method  
Delta Activations는 동일 입력에 대해 기준 모델과 미세조정 모델의 최종 층 토큰 활성화 차이를 계산하여 모델 표현 벡터를 생성한다.  
탐침 입력 세트를 이용하여 다수의 활성화 차이를 평균집계하며, 이 벡터는 미세조정 효과를 압축하여 내재적 행동 변화를 반영한다.  
Probe 데이터는 일반적 템플릿을 사용해 모델의 특화 행동을 유도하고, 확장하여 Delta Logits, Delta Meaning 등 다양한 내부 표현 기반 임베딩으로 발전 가능하다.  

## Results  
Delta Activations는 여러 백본 기반 모델 풀에서 도메인별 클러스터링 품질에서 기존 출력 임베딩이나 가중치 기반 방법을 능가하며, 미세조정 데이터셋 병합 효과에 대한 가법성도 확인되었다.  

## Limitations  
본 방법은 내부 활성화 접근이 가능해야 하며, 판권이 제한된 상용 모델에 적용이 어렵다는 한계가 존재한다.  

## Conclusion  
Delta Activations는 미세조정된 대형 언어 모델들의 구조적 이해와 탐색을 돕는 강력하고 확장 가능한 임베딩 기법으로서 미래의 모델 재활용 촉진에 기여할 것으로 기대된다.

# 13. [Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from   Vector Drawings](https://arxiv.org/abs/2508.18733)

## Introduction  
- Goal: 본 연구의 목표는 벡터 기반 2D 엔지니어링 도면으로부터 파라메트릭 CAD 모델을 자동으로 생성하는 시퀀스-투-시퀀스 학습 프레임워크를 제안하는 것이다.  
- Motivation: 기존 CAD 생성 연구들은 포인트 클라우드, 메시, 텍스트 등 다양한 입력을 사용하지만, 전통적 산업 설계 흐름의 출발점인 2D 벡터 도면을 활용한 자동화는 부족한 상태이다.  
- Contribution: 벡터 드로잉의 정확한 기하학적 정보 보존과 설계 의도 유지를 위해 네트워크 친화적 표현, 이중 디코더 구조, 소프트 타겟 분포 손실을 도입한 Drawing2CAD 프레임워크를 개발하였다.  

## Method  
Drawing2CAD는 SVG 형식의 벡터 엔지니어링 도면을 인코딩하여 CAD 명령어 타입과 파라미터를 각각 생성하는 이중 디코더 변형기(Transformer) 기반 구조로 설계되었다. 입력 도면은 정규화 및 순서 재정렬 작업을 거쳐 일관된 8차원 파라미터 벡터로 표현된다. 또한, CAD 파라미터의 유연성을 반영한 소프트 타겟 분포 손실 함수를 통해 모델의 일반화 성능을 향상시킨다.  

## Results  
벡터 형식 입력을 사용한 Drawing2CAD는 래스터 이미지 기반 모델 대비 명령어 정확도, 파라미터 정밀도 및 CAD 모델 유효성에서 일관되게 우수한 성능을 보였다.  

## Limitations  
복잡한 모델 처리 시 일부 FreeCAD 변환 도구의 제약으로 인해 도면 생성 실패 사례가 존재하며, 추후 개선이 필요한 상황이다.  

## Conclusion  
본 연구는 벡터 기반 2D 엔지니어링 도면으로부터 파라메트릭 CAD 모델을 성공적으로 생성하는 최초의 딥러닝 프레임워크를 제안하여 산업 설계 자동화에 새로운 가능성을 제시하였다.

# 14. [False Sense of Security: Why Probing-based Malicious Input Detection   Fails to Generalize](https://arxiv.org/abs/2509.03888)

## Introduction
- 본 논문은 대형 언어 모델(LLMs)의 내부 표현에서 악의적 입력을 탐지하는 프로빙 기반 방법의 일반화 실패 원인을 분석하는 것을 목표로 한다.  
- 프로빙 분류기가 분포 외 데이터에 취약하며, 악성 여부에 대한 의미적 이해보다는 피상적 패턴을 학습한다는 점에 착안하여 연구를 진행하였다.  
- 표면적 패턴 학습 문제를 확인하고, 이에 따른 재설계 방향을 제시하며 프로빙 기반 안전 탐지 방법의 한계를 체계적으로 규명하였다.  

## Method  
- LLMs의 마지막 토큰 마지막 층의 은닉 상태를 기반으로 SVM 등 간단한 분류기를 학습하여 악성 및 정상 입력을 구분하였다.  
- Naive Bayes 기반 n-그램 방법과 비교 및 의미적으로 정제된 데이터셋과 패러프레이징 실험을 통해 분류기의 의존 패턴을 분석하였다.  
- 여러 층의 은닉 상태 및 다양한 분류기 아키텍처로 실험을 반복하여 패턴 학습 현상의 일관성을 검증하였다.  

## Results  
- 프로빙 분류기는 분포 내 데이터에서는 98% 이상의 정확도를 달성하나, 분포 외 데이터에서는 최대 99%까지 성능이 급격히 하락하며, n-그램 방식과 유사한 수준의 표면적 패턴에 기반한 학습만 이루어짐을 입증하였다.  

## Limitations  
- 본 연구는 주로 영어 데이터셋과 디코더 기반 트랜스포머 모델에 국한되어 있어, 타 언어나 모델 구조에 대한 일반화 가능성은 추가 연구가 필요하다.  

## Conclusion  
- 프로빙 기반 악성 입력 탐지 방법은 의미론적 이해보다는 표면적 패턴에 과도하게 의존하여 실제 안전성 보장에는 실패하며, 이에 대한 근본적인 재검토와 더 견고한 평가 체계 마련이 필수적임을 밝혔다.
