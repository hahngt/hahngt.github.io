---
layout: post
title: "Daily Papers — 2025-09-26"
date: 2025-09-26 08:15:00
tags: [papers, hugginface]
categories: []
---

# 1. [CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling](https://arxiv.org/abs/2509.21114)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.21114)

## Introduction

- Goal: 본 논문은 3D 애니메 헤어스타일 모델링을 위한 새로운 파라메트릭 표현과 생성 프레임워크 CHARM을 제안하는 것이다.
- Motivation: 기존의 실사형 머리카락 모델링 기법은 애니메 고유의 스타일화되고 조각화된 기하학적 특성을 다루기 어렵고, 기존 작품들은 조작이 비효율적이며 확장 가능 학습에 부적합하다.
- Contribution: CHARM은 3D 위치, 너비, 두께의 5개 파라미터로 표현되는 가볍고 가역적인 컨트롤 포인트 기반 파라미터화를 도입하고, 이를 기반으로 이미지 또는 포인트 클라우드로부터 애니메 헤어를 고품질 생성하는 자기회귀 변환기 모델과 대규모 3만 7천 개 이상의 데이터셋을 구축하였다.

## Method

CHARM은 각 머리카락 카드를 컨트롤 포인트 시퀀스로 나타내며, 각 포인트는 3D 위치와 폭, 두께로 구성된다. 이러한 파라미터화는 수치 최적화 기법으로 폭 방향 벡터를 안정적으로 추정하여 가역적이고 압축된 표현을 가능하게 한다. 이를 바탕으로 조건부 자기회귀 트랜스포머 네트워크를 설계해 머리카락 카드를 순차적 “헤어 언어”로 간주하여 다양한 입력으로부터 헤어스타일을 효과적으로 생성한다.

## Results

벤치마크 실험에서 CHARM은 기존 최첨단 3D 메시 생성 기법들 대비 모든 측정 지표(Chamfer 거리, EMD, Hausdorff 거리, Voxel-IoU 등)와 CLIP 기반 지각적 유사도에서 우수한 성능을 보였다.

## Limitations

정보 부족이다.

## Conclusion

CHARM은 애니메 스타일의 독특한 3D 헤어 표현과 생성 문제에 특화된 가역적 파라미터화와 자기회귀 생성 모델을 통해 고품질, 스케일러블한 애니메 헤어스타일링 솔루션을 제공한다.

# 2. [Does FLUX Already Know How to Perform Physically Plausible Image Composition?](https://arxiv.org/abs/2509.21278)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.21278)

## Introduction

- Goal: 본 논문은 물리적으로 타당한 이미지 합성을 수행할 수 있는지 FLUX 기반 텍스트-투-이미지 모델의 능력을 평가하고, 이를 개선하기 위한 무학습 기반 이미지 합성 프레임워크 SHINE을 제안하는 것이다.
- Motivation: 기존의 이미지 합성 모델들은 복잡한 조명 조건과 다양한 해상도 입력에서 자연스러운 객체 삽입에 한계를 보이며, 특히 객체의 포즈 및 조명 반사 처리에 어려움이 존재한다.
- Contribution: SHINE은 사전학습된 커스터마이즈 어댑터를 활용하는 Manifold-Steered Anchor 손실과 저품질 출력을 억제하는 Degradation-Suppression Guidance, 그리고 마스크 경계의 이음새를 개선하는 Adaptive Background Blending 기법을 도입하여, 복잡한 환경에서도 고해상도, 고품질 합성을 가능하게 하는 무학습 기반 프레임워크를 제안한다.

## Method

SHINE은 사전학습된 커스터마이즈 어댑터를 이용한 Manifold-Steered Anchor 손실을 통해 참조 대상 객체를 충실히 표현하며 배경 구조를 유지한다. Degradation-Suppression Guidance는 텍스트 기반 부정적 프롬프트가 무효한 FLUX의 특성에 착안하여 이미지 쿼리 부분을 흐리게 처리해 저품질 영역으로의 경로를 차단한다. Adaptive Background Blending은 사용자가 제공한 마스크와 텍스트-이미지 교차어텐션으로부터 얻은 마스크를 상황에 따라 적응적으로 병합하여 경계부의 이음새를 최소화한다.

## Results

복잡한 조명과 다양한 해상도를 포함하는 새롭게 제안된 ComplexCompo 벤치마크와 기존 DreamEditBench에서 SHINE은 인간 평가 지표 및 표준 지표에서 최첨단 성능을 기록하였다.

## Limitations

SHINE은 부적절한 인페인팅 프롬프트에 의해 객체 색상이 잘못 지정되면 해당 오류를 보존하는 문제와 어댑터의 품질에 따른 객체 정체성 재현력 제한을 가진다.

## Conclusion

본 연구는 물리적으로 타당한 이미지 합성을 위한 무학습 기반 고품질 삽입 기법 SHINE을 제안하여, 다양한 난제 환경에서 기존 기법들을 능가하는 결과를 달성하였다.

# 3. [SD3.5-Flash: Distribution-Guided Distillation of Generative Flows](https://arxiv.org/abs/2509.21318)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.21318)

## Introduction

- Goal: 본 논문은 SD3.5-Flash라는 효율적인 소수 단계(distillation) 기반의 생성 모델을 제안하여 고품질 이미지 생성을 소비자용 기기에서도 구현하는 데 목적이 있다.
- Motivation: 기존 고품질 직류 흐름(rectified flow) 기반 이미지 생성 모델은 높은 계산 비용과 긴 생성 시간으로 인해 일반 소비자 기기에서 실행이 어렵다는 한계가 존재한다.
- Contribution: 본 연구에서는 시계열 공유(timestep sharing)와 분할 시계열 미세조정(split-timestep fine-tuning) 기법을 도입하고, 텍스트 인코더 구조 개편 및 특수량자화와 같은 파이프라인 최적화를 통해 소수 단계 생성에서 안정성과 성능을 크게 향상시켰다.

## Method

SD3.5-Flash는 소수 단계 흐름 생성 모델로, 시계열 공유를 통해 안정적인 그래디언트를 확보하며 분할 시계열 미세조정으로 프롬프트-이미지 정렬 문제를 완화한다. 분포 일치(disttribution matching) 목표를 재구성하여 학생 모델이 생성 경로에 적합한 샘플을 사용하도록 하여 노이즈 추가 없이 학습의 안정성을 높였다. 또한, 16비트에서 6비트까지 다양한 양자화 방식을 적용하고 T5-XXL 텍스트 인코더를 선택적으로 사용하여 다양한 하드웨어에 맞춰 효율적 배포가 가능하게 하였다.

## Results

광범위한 사용자 평가 및 비교 실험에서 SD3.5-Flash는 기존 소수 단계 생성 기법들을 일관되게 능가하며, 다양한 하드웨어 환경에서 고품질 이미지 생성을 실현함을 입증하였다.

## Limitations

텍스트 인코더 T5-XXL 제거 시 고난이도 복합 구성 구현이 어려워지고, 저단계(distillation) 모델의 특성상 생성 품질과 다양성에서 다소 제한이 존재하였다.

## Conclusion

SD3.5-Flash는 소수 단계 이미지 생성 속도를 18배까지 향상시키면서도 사용자 평가에서 대형 교사 모델을 능가하는 성능을 보여, 고성능 생성 AI의 소비자 기기 접근성을 크게 증대시키는 의의를 가진다.

# 4. [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.21106)

## Introduction

- Goal: 본 연구는 개인화된 정보 탐색을 위한 검색 보강 대형 언어 모델(LLM)의 성능을 평가하는 현실적이고 진단적인 벤치마크 BESPOKE를 제안하는 데 목적이 있다.
- Motivation: 기존 검색 보강 LLM은 사용자 이력 기반 개인화를 시도하지만, 이를 체계적으로 평가하고 진단하는 연구가 부족한 상황이다.
- Contribution: BESPOKE는 인간 사용자의 실제 대화 및 검색 이력을 수집하고, 세밀한 개인화 요구 사항과 함께 점수 및 피드백을 제공하는 평가 프레임워크를 구축하였다.

## Method

BESPOKE는 30명의 다양한 배경을 가진 인간 평가자들의 2,870회 세션의 대화 및 웹 검색 이력을 3주간 수집하였으며, 각 쿼리에 대해 상세한 정보 요구와 응답에 대한 점수 및 설명적 피드백을 취합하였다.  
평가 프레임워크는 GPT-5 기반 평가자를 활용하여 사실성(Recall)과 개인화 네 가지 기준(필요성 일치, 내용 깊이, 어조, 설명 스타일)을 점수화하고 진단적 피드백을 제공한다.  
사용자 이력은 쿼리 인지적 맥락에 맞게 선별 및 프로파일링하여 개인화 효과를 높이는 방법도 함께 연구되었다.

## Results

검색 보강 LLM들은 사용자 맥락을 활용할 때 개인화 점수가 유의미하게 향상되었으며, 특히 쿼리 인지적 맥락 구축과 이력 선별 및 구조화 프로파일 사용이 개인화 품질 향상에 효과적임이 확인되었다.

## Limitations

BESPOKE 실험 결과, 현실 환경에서 사용자 이력이 잡음과 암묵적 선호 정보를 포함하여 정확한 개인화 응답 생성에는 여전히 한계가 존재한다는 점이 드러났다.

## Conclusion

BESPOKE는 실제 사용자 이력 기반 개인화 검색 보강 LLM 성능을 체계적으로 평가할 수 있는 벤치마크이며, 개인화 개선을 위한 진단적 피드백을 제공하여 향후 관련 연구 발전에 기여할 수 있다.

# 5. [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.21042)

## Introduction

- Goal: 본 연구는 인과적 마스크(causal mask)가 어떻게 Transformer 디코더에서 위치 정보를 인코딩하는지 규명하는 것을 목표로 한다.
- Motivation: 기존 연구들은 RoPE와 같은 명시적 위치 인코딩이 위치 정보를 제공한다고 보았으나, 인과적 마스크도 위치 정보를 제공하는 중요한 역할을 하며 그 정확한 메커니즘은 불명확하다.
- Contribution: 인과적 마스크가 파라미터나 입력의 인과적 종속성 없이도 위치 의존적 어텐션 패턴을 유도함을 이론적으로 증명하고, RoPE와의 상호작용으로 인해 위치 정보 패턴이 왜곡됨을 실증적으로 보였다.

## Method

파라미터와 피드포워드 네트워크 없이 인과적 마스크를 적용한 Transformer 디코더를 이론적으로 분석하여, 입력 내 인과 구조가 없어도 위치 의존적 어텐션 내적값이 생성됨을 구체적으로 수학적으로 증명하였다. 이론적 모델을 시뮬레이션하고, 명시적 위치 인코딩 없이 Transformer를 학습한 실험을 통해 이론 결과가 실제 모델 동작과 일치함을 확인하였다. 또한, 로터리 위치 인코딩(RoPE)과 인과적 마스크의 결합이 RoPE의 상대적 어텐션 패턴을 비상대적 패턴으로 왜곡함을 시뮬레이션과 실제 대형 언어 모델들에서 조사하였다.

## Results

인과적 마스크는 명시적 위치 인코딩 없이도 위치 정보를 암묵적으로 인코딩하며, RoPE와 상호작용 시 위치 패턴이 왜곡되어 현대 대형 언어 모델에서도 이 현상이 명확히 관찰된다.

## Limitations

본 연구에서는 피드포워드 네트워크와 학습된 파라미터의 영향에 대한 분석이 제한적이며, RoPE와 인과적 마스크의 상호작용이 모델 성능 및 길이 일반화에 미치는 직접적 영향은 명확히 규명하지 못하였다.

## Conclusion

인과적 마스크는 RoPE와 같은 명시적 위치 인코딩과 함께 Transformer 디코더에서 중요한 위치 정보의 원천이며, 이들의 결합 효과를 고려하는 연구가 향후 대형 언어 모델의 성능 및 길이 일반화 개선에 기여할 것으로 기대된다.

# 6. [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.18293)

## Introduction

- Goal: 본 연구의 목표는 여덟 개의 공개된 대형 언어 모델(LLM)이 반유대주의 콘텐츠를 탐지하는 능력을 평가하는 것이다.
- Motivation: 반유대주의를 포함한 증오 발언의 탐지는 사회적·법적 맥락에 따라 복잡하고 민감한 문제이며, 자동화된 기계학습 도구의 지속적인 적응과 개선이 필요하다.
- Contribution: 본 연구는 IHRA 정의를 정책 지침으로 활용한 새로운 연쇄적 사고(Chain-of-Thought, CoT) 형태의 프롬프트 방식인 Guided-CoT를 제안하고, 이를 통해 모델 성능과 설명력 향상을 입증한 최초의 체계적인 평가를 수행하였다.

## Method

여덟 개 공개 LLM을 대상으로 Zero-Shot, Chain-of-Thought(CoT), 그리고 제안한 Guided-CoT 프롬프트 방식으로 반유대주의 탐지 성능을 비교하였다.  
평가에는 Twitter 기반 IHRA 정의에 따른 라벨링된 데이터셋을 사용하였으며, 모델별 응답의 적합성, 분류 정확도, 그리고 생성된 설명의 의미적 차이를 정량적으로 분석하였다.  
또한 Guided-CoT 내의 구성 요소별 중요도를 확인하는 제거 연구(ablation study)와 오류 유형에 대한 정성적 분석을 수행하였다.

## Results

Guided-CoT 프롬프트 기법이 모든 모델에서 일관되게 성능을 향상시켰으며, 특히 Llama 3.1 70B 모델은 미세조정된 GPT-3.5보다 높은 F1 점수를 기록하였다.

## Limitations

데이터셋은 영어권 Twitter 플랫폼에 한정되어 있어 다국어 및 다른 소셜미디어 환경에서의 일반화 가능성에 제약이 존재한다.

## Conclusion

본 연구는 다양한 LLM의 반유대주의 탐지 능력과 설명 가능성에서 나타나는 차이점을 상세히 분석하고 Guided-CoT 프롬프트가 이에 미치는 긍정적 영향을 입증함으로써, 민감한 사회적 분류 과제에 대한 모델 평가 및 신뢰성 확보에 기여하였다.
