---
layout: post
title: "Daily Papers — 2025-10-09"
date: 2025-10-09 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [Ming-UniVision: Joint Image Understanding and Generation with a Unified   Continuous Tokenizer](https://arxiv.org/abs/2510.06590)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.06590)

## Introduction
- 목표는 연속 잠재 공간을 갖는 통합 비주얼 토크나이저 MingTok을 도입하여 이미지 이해와 생성 작업을 하나의 자기회귀(autoregressive) 프레임워크에서 통합하는 것이다.  
- 시각적 이해와 생성은 본질적으로 서로 상충하는 표현 요구를 가지며, 기존의 이산 잠재 공간 기반 토크나이저는 양자화 오류로 인해 의미 표현성과 성능이 제한된다.  
- 본 연구는 MingTok을 기반으로 다양한 비전-언어 작업을 단일 자기회귀 예측으로 통합하는 Ming-UniVision 모델을 개발한 점에 그 기여가 있다.  

## Method  
MingTok은 저차원 연속 잠재 인코딩, 의미 확장, 이미지 재구성의 세 단계 구조를 가지며, 이를 통해 이해 작업과 생성 작업 간의 요구를 조화시킨다.  
Ming-UniVision은 단일 연속 표현 공간 내의 토큰 예측으로 이해와 생성을 모두 처리하며, 이를 통해 멀티라운드 인컨텍스트 작업과 편집을 지원한다.  
학습은 마스킹 이미지 모델링을 기반으로 잠재 공간과 의미 공간 모두에 감독 신호를 부여하여, 의미적 풍부함과 효율적 생성을 동시에 추구한다.  

## Results  
Ming-UniVision은 GenEval, MMbench 등 다중 벤치마크에서 최첨단 수준의 이미지 이해 및 생성 성능을 보였으며, 위치 제어 및 색상 속성 통제에서 특히 우수한 결과를 기록하였다.  

## Limitations  
OCRBench와 MMMU와 같은 세밀한 문자 인식 작업에서는 잠재 공간 압축과 인과 구조의 제약으로 인해 성능 격차가 존재한다.  

## Conclusion  
MingTok과 Ming-UniVision은 연속적이고 통합된 시각 표현을 통해 이미지 이해, 생성 및 편집 작업을 하나의 자기회귀 모델 내에서 효과적으로 수행할 수 있음을 입증하였다.

# 2. [SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models](https://arxiv.org/abs/2510.06917)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.06917)

## Introduction
- 본 논문은 화자 발화 중에도 실시간으로 사고 과정을 수행하여 응답 지연을 줄이는 음성 언어 모델(SLM)용 추론 프레임워크 SHANKS를 제안하는 것을 목표로 한다.  
- 기존 대형 언어 모델들은 사용자의 발화가 끝난 후에만 사고를 시작하여 실시간 상호작용에 적합하지 않은 문제를 해결하고자 하였다.  
- SHANKS는 고정 길이 음성 청크 단위로 입력을 처리하며, 각 청크 수신 시점에 이전 음성과 사고 내용을 바탕으로 비음성적 사고를 생성하는 방식을 도입하였다.  

## Method  
SHANKS는 사용자의 발화를 고정된 길이(tchunk) 단위로 나누어 수신하는 동시에 이전 음성 청크 및 사고 청크를 조건으로 비음성 chain-of-thought(사고) 토큰을 생성한다. 사고 토큰은 실제 음성 출력이 아니며, 이 사고 과정에서 사용자 중단 혹은 도구 호출 여부를 결정한다. 학습 시에는 이러한 사고 토큰과 사용자 음성 청크를 교차하는 시퀀스를 구성하여 모델이 청크별 사고를 학습하게 한다.  

## Results  
SHANKS는 수학 문제 풀이 중 사용자의 오류를 실시간으로 37.1% 더 정확하게 중단할 수 있으며, 대화 중 도구 호출을 사용자의 발화 종료 전 56.9%까지 완료하여 응답 지연을 효과적으로 감소시켰다.  

## Limitations  
SHANKS는 사고 토큰 생성 시간이 고정 청크 크기(tchunk)에 의존하여 사고가 사용자 발화보다 최소 tchunk 초만큼 지연된다는 제한점이 존재한다.  

## Conclusion  
SHANKS는 사용자의 발화가 완료되기 전에도 지속적으로 사고 과정을 수행함으로써 실시간 음성 대화 모델의 응답 성능과 상호작용 품질을 개선하는 중요한 진전을 이루었다.

# 3. [Why Low-Precision Transformer Training Fails: An Analysis on Flash   Attention](https://arxiv.org/abs/2510.04212)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.04212)

## Introduction
- Goal: 본 논문은 저정밀도 환경에서 flash attention을 사용한 트랜스포머 학습 실패의 근본 원인을 메커니즘적으로 규명하는 것이다.  
- Motivation: 효율적인 계산을 위해 저정밀도 수치 포맷을 도입한 트랜스포머 학습에서 잦은 불안정성과 손실 폭발 현상이 해결되지 않은 채 지속되어 왔다.  
- Contribution: 유사한 저랭크 표현과 BF16 형식의 편향된 반올림 오차가 학습 실패를 유발하는 두 가지 핵심 원인임을 최초로 분석하고, 이를 완화하는 간단한 flash attention 수정안을 제시하였다.  

## Method  
버그 재현을 위해 GPT-2 모델을 BF16 정밀도로 flash attention을 사용해 학습시켰고, 알고리즘 내부 연산과 수치 오차 원인을 좁혀가며 실패의 원천을 δ 계산과 특정 attention head의 출력 오차로 규명하였다.  
저랭크 행렬 간 구조적 유사성과 δ 차이의 편향이 누적되어 가중치 업데이트 오류를 증폭하는 과정을 수학적으로 분석하였으며, BF16 반올림 오차가 이 편향에 기여함을 실험적으로 입증하였다.  
특정 조건에서 softmax 정상화를 조정하여 ¯P 행렬 원소가 정확히 1이 되지 않도록 변경함으로써 편향된 반올림 오류 발생을 방지하는 수치적 안정화 방법을 구현하였다.  

## Results  
제안한 동적 softmax 수정 기법은 flash attention의 학습 불안정을 효과적으로 완화하여 손실 폭발 문제를 해결하고 전체 학습의 안정성을 제고하였다.  

## Limitations  
본 연구 결과는 GPT-2 아키텍처와 BF16 포맷에 국한되어 있으며, 다른 모델 구조나 저정밀도 포맷에 대한 일반화 가능성은 추가 연구가 필요하다.  

## Conclusion  
본 논문은 저정밀도 flash attention 학습 실패를 유발하는 저랭크 표현과 반올림 편향 간 상호작용을 규명하고, 이를 해결하는 실용적 방안을 제시하여 대규모 모델의 효율적 저정밀도 학습 연구에 기여하였다.

# 4. [Revisiting Long-context Modeling from Context Denoising Perspective](https://arxiv.org/abs/2510.05862)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.05862)

## Introduction
- 이 연구는 긴 문맥을 처리하는 대형 언어 모델에서 문맥 내 잡음(irrelevant tokens)을 효과적으로 탐지 및 제거하여 핵심 정보에 대한 주의를 강화하는 방법을 제안하는 것이다.  
- 긴 문맥 모델은 핵심 토큰을 찾는 과정에서 주변 잡음에 취약하여 성능 저하가 발생하는 문제점을 가지고 있다.  
- 본 논문은 통합 기울기(Integrated Gradient, IG) 점수를 이용한 잡음 검출 및 이를 기반으로 한 Context Denoising Training(CDT)이라는 새로운 학습 기법을 제안한다.  

## Method  
- 먼저 IG 점수를 통해 중요한 토큰과 불필요한 토큰을 정밀하게 구분하며, embedding gradient를 활용해 IG 점수를 효율적으로 근사한다.  
- 이후 잡음으로 판단된 토큰의 임베딩에 대해 기울기값을 빼는 방식으로 문맥 잡음을 억제하고, 이를 반영한 수정 임베딩으로 모델을 지속 학습시킨다.  
- 이 과정은 EM(Expectation Maximization)과 유사한 반복적 구조로 핵심 토큰에 대한 주의를 강화하며 모델 예측력을 향상시킨다.  

## Results  
- 제안된 CDT는 4가지 유형, 12개 실제 긴 문맥 태스크에서 기존 방법 대비 평균 약 2점 이상의 성능 향상을 보였으며, 오픈소스 8B 모델이 GPT-4o와 유사한 성능(50.92 vs. 51.00)을 달성하였다.  

## Limitations  
- IG 점수 계산에 큰 GPU 메모리와 계산 비용이 요구되어 최대 12K 토큰 길이로 제한되며, 이를 완화하기 위해 근사 방법을 사용해야 하는 한계가 존재한다.  

## Conclusion  
- 본 연구는 긴 문맥 내 잡음 제거를 통한 핵심 토큰 집중 강화가 긴 문맥 모델의 성능 향상에 효과적임을 입증하였으며, CDT는 실제 응용에서 우수한 성능과 효율성을 제공한다.

# 5. [Online Generic Event Boundary Detection](https://arxiv.org/abs/2510.06855)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.06855)

## Introduction
- Goal: 본 논문은 스트리밍 비디오 환경에서 실시간으로 일반적인 사건 경계를 감지하는 Online Generic Event Boundary Detection (On-GEBD) 과제를 정의하고 해결하는 것이다.  
- Motivation: 기존의 GEBD 방법은 전체 비디오 프레임을 필요로 하여 인간의 실시간 인지 방식과 다르고, 이와 달리 미래 프레임 없이 과거 정보만으로 즉각적 사건 경계 인지가 필요한 실시간 처리 과제에 대한 연구가 부족하였다.  
- Contribution: 본 연구는 인지과학의 Event Segmentation Theory(EST)에 기반하여 Consistent Event Anticipator(CEA)와 Online Boundary Discriminator(OBD)를 포함한 새로운 On-GEBD 프레임워크 ESTimator를 제안하였다.  

## Method  
ESTimator는 과거 프레임만을 활용하여 다음 프레임의 특징을 예측하면서 이벤트의 일관성을 학습하는 CEA와, 예측 오류의 통계적 분포를 활용해 동적으로 경계 임계값을 결정하는 OBD로 구성된다. 두 가지 손실 함수(EST 손실과 REST 손실)를 통해 경계 프레임에서 예측 오류를 극대화하고 일관된 이벤트 내부에서는 오류를 최소화하는 학습을 수행한다. OBD는 과거 오류를 기억하는 큐를 사용하여 실시간으로 변화하는 문맥에 적응하며 다양한 형태의 사건 전환을 감지한다.  

## Results  
제안한 ESTimator는 Kinetics-GEBD와 TAPOS 데이터셋에서 기존 온라인 비디오 이해 모델 기반의 베이스라인을 능가하며, 일부 기존 오프라인 GEBD 모델과도 유사한 수준의 성능을 보였다.  

## Limitations  
진행 중인 연구로서 미래 프레임 정보가 전혀 없는 환경에서 즉각적으로 사건 경계를 결정하는 과정에서 여전히 제한된 정보로 인한 오탐지 위험이 존재한다.  

## Conclusion  
본 연구는 인간 인지 과정을 모방한 실시간 일반 사건 경계 감지 과제와 이를 위한 ESTimator 프레임워크를 제안하여 온라인 환경에서 효과적인 사건 경계 인식 성능을 입증하였다.

# 6. [Heptapod: Language Modeling on Visual Signals](https://arxiv.org/abs/2510.06673)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.06673)

## Introduction
- Goal: 본 논문은 시각 신호에 대한 언어 모델링의 원칙에 입각한 이미지 자기회귀 모델인 Heptapod을 제안하는 것이다.  
- Motivation: 기존 시각 생성 모델은 Classifier-Free Guidance(CFG)나 의미 토크나이저에 의존하여 본질적인 모델 능력이 제한되는 문제점이 존재하였다.  
- Contribution: Heptapod은 인과적 Transformer와 재구성 중심 시각 토크나이저를 활용하여 2차원 공간 전체에 대한 차기 분포 예측 목표를 도입함으로써 시각 신호에서 통합적 의미 학습을 가능하게 하였다.  

## Method  
Heptapod은 1차원 인과적 Transformer를 그대로 유지하면서 입력된 비주얼 토큰의 2차원 공간 내 모든 후속 위치에 대한 토큰 분포를 병렬로 예측한다.  
예측 헤드는 전역 또는 지역 단위로 2차원 공간의 토큰 분포를 생성하는 양방향 Transformer 구조를 채택하며, 이를 통해 장거리 공간적 의존성 파악과 전체 이미지 의미론 이해를 촉진한다.  
학습 목표는 생성 모델링과 마스크 오토인코딩(Self-Supervised Learning)을 통합하였으며, 재구성에 집중된 토크나이저와 인과적 Transformer의 분리된 역할을 유지하도록 설계되었다.  

## Results  
Heptapod은 ImageNet 256×256 생성 벤치마크에서 2.70의 FID로 기존 인과적 자기회귀 모델 대비 크게 우수한 성능을 보였으며, CFG 없이도 의미가 내재된 시각 생성이 가능함을 입증하였다.  

## Limitations  
본 연구는 예측 헤드의 계산량 증가와 학습 효율성 개선을 위한 추가 연구가 필요한 한계가 존재한다.  

## Conclusion  
Heptapod은 재구성 중심 토크나이저와 인과적 Transformer를 활용한 전향적 2D 분포 예측 목표를 통해 의미가 내재된 시각 생성 모델링의 원칙을 수립하였다.

# 7. [NorMuon: Making Muon more efficient and scalable](https://arxiv.org/abs/2510.05491)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.05491)

## Introduction
- Goal: 본 논문은 Muon 옵티마이저의 직교화 특성을 신경망 뉴런별 적응 학습률과 결합하여 NorMuon이라는 효율적이고 확장 가능한 옵티마이저를 제안하는 데 목적이 있다.  
- Motivation: 기존 Muon 옵티마이저가 업데이트 방향 행렬의 상태수(condition number)는 크게 개선하였으나 뉴런별 업데이트 크기 불균형 문제를 해결하지 못해 최적화 효율 저하가 발생하였다.  
- Contribution: NorMuon은 Muon의 직교화 기법과 뉴런 단위의 두 번째 모멘텀 적응 학습률 정규화를 통합하고, FSDP2 프레임워크 기반으로 분산 구현하여 대규모 언어 모델 학습 효율을 획기적으로 개선하였다.  

## Method  
NorMuon은 Muon의 뉴턴-슐츠 반복을 이용한 모멘텀 행렬 직교화에 각 뉴런별 두 번째 모멘텀 통계치를 적용하여 업데이트 벡터를 행 단위로 정규화한다. 이러한 정규화는 뉴런 간 업데이트 크기 편차를 감소시키면서 Muon의 상태수 개선 효과를 유지한다. 또한 대규모 분산 학습 시 직교화 연산을 장치별로 균등 분산시켜 중복 계산과 통신 부담을 줄였다.  

## Results  
1.1B 규모 사전학습 실험에서 NorMuon은 Adam 대비 21.74%, Muon 대비 11.31% 향상된 학습 효율을 보이며, 5.4B 모델에서도 유의미한 개선을 보였다.  

## Limitations  
NorMuon의 분산 구현은 기존 Adam 대비 메모리 사용량을 약 50% 절감하는 반면 최대 33~50% 정도의 통신 오버헤드를 동반한다.  

## Conclusion  
NorMuon은 직교화와 뉴런별 적응 학습률을 효과적으로 결합하여 대규모 딥러닝 모델 학습의 최적화 성능과 계산 효율을 동시에 향상시킨다.

# 8. [Bridging Text and Video Generation: A Survey](https://arxiv.org/abs/2510.04999)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.04999)

## Introduction
- 본 논문은 자연어 명령어로부터 시각적으로 일관된 동영상 콘텐츠를 생성하는 텍스트-투-비디오(text-to-video, T2V) 생성 기술을 체계적으로 조사하는 것에 목표를 둔다.  
- T2V 기술은 교육, 마케팅, 엔터테인먼트, 시각 및 독해 장애 보조 기술 등 다양한 분야에 혁신적 변화를 가져올 가능성에도 불구하고, 텍스트와 영상 간 정렬, 장기간 일관성, 계산 효율성 등의 문제를 해결해야 한다.  
- 본 논문은 GAN, VAE, 확산모델 등 T2V 주요 모델들의 발전 과정, 학습 데이터셋과 평가 지표, 훈련 구성, 그리고 현재의 도전과 미래 연구 방향을 포괄적으로 정리하였다.  

## Method  
- GAN 기반 모델은 생성자와 판별자의 경쟁적 학습으로 영상 프레임 간 일관성 확보를 시도하였으나, 훈련 불안정성과 해상도 확장에 한계가 있었다.  
- VAE 기반 접근법은 잠재 공간 내 구조화된 표현 학습을 통해 제어 가능성을 높였으며, 복잡한 시공간 특징을 담은 자기회귀적 트랜스포머와 결합되었다.  
- 가장 최근 확산모델은 점진적 노이즈 제거 과정을 통해 고품질 및 시공간적 일관성을 개선하였으며, T2I 모델 재사용과 효율적 시간적 연산 기법을 활용한 다양한 아키텍처가 제안되었다.  

## Results  
- 최신 확산모델 기반 연구들은 텍스트-영상 정렬 및 시간적 일관성에서 기존 모델들을 능가하는 성능을 표준 벤치마크와 인간 평가에서 입증하였다.  

## Limitations  
- T2V 분야는 여전히 대규모 고품질 텍스트-비디오 데이터셋 부족과 높은 계산 비용, 복잡한 시공간 정렬 문제로 확장과 실용화에 제약을 받고 있다.  

## Conclusion  
- 본 논문은 T2V 모델 아키텍처, 데이터셋, 평가 방법론, 도전 과제를 체계적으로 분석하여 향후 연구자들이 본 분야를 심화하고 응용을 확장할 수 있는 견고한 토대를 제공한다.

# 9. [D^3QE: Learning Discrete Distribution Discrepancy-aware   Quantization Error for Autoregressive-Generated Image Detection](https://arxiv.org/abs/2510.05891)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.05891)

## Introduction
- 본 논문의 목표는 시각적 자기회귀(AR) 모델이 생성한 이미지를 효율적으로 탐지하는 새로운 기법을 제안하는 것이다.  
- 이는 기존 GAN 및 확산모델 기반 탐지법과 달리, AR 모델의 이산적 토큰 예측과 벡터 양자화 표현에서 나타나는 고유한 분포 차이를 활용하기 위함이다.  
- 기여점으로는 이산 분포 차이를 인지하는 양자화 오류(D3QE)를 학습하고, 코드북 빈도 통계 기반 변환기 구조를 도입해 AR 이미지 탐지 성능과 일반화를 크게 향상시킨 점이다.

## Method  
본 연구는 VQVAE를 이용해 이미지의 이산 코드북 표현과 양자화 잔차를 추출하고, 실제 및 생성 이미지 간 코드북 사용 빈도의 분포 차이를 동적 주의(attention) 메커니즘에 반영하는 D3AT 모듈을 설계하였다. 이어 CLIP으로부터 의미적 전역 특징을 추출해 양자화 오류 특징과 융합한 후 분류기를 통해 진위 판별을 수행하였다. 또한, AR 모델 다수를 포함하는 ARForensics 데이터셋을 구축하여 본 기법의 효용성을 평가하였다.

## Results  
제안한 D3QE는 7종의 대표적 자기회귀 모델로부터 생성된 이미지 탐지에서 기존 최첨단 기법 대비 평균 정확도와 정밀도를 각각 18.21%, 11.86% 이상 향상하였으며, GAN 및 확산모델에도 우수한 일반화와 강인성을 나타냈다.

## Limitations  
현재 연구는 이산 분포 특성에 기반해 AR 모델에 최적화되었으나, 더욱 다양한 생성 모델과 극한 변형 환경에 대한 대응력 증진은 추후 과제로 남는다.

## Conclusion  
D3QE는 자기회귀 기반 생성 이미지 탐지에 있어 이산 분포 차이를 효과적으로 활용하여 높은 정확도와 강인한 일반화 성능을 확보한 혁신적 기법임을 입증하였다.

# 10. [FinLFQA: Evaluating Attributed Text Generation of LLMs in Financial   Long-Form Question Answering](https://arxiv.org/abs/2510.06426)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.06426)

## Introduction
- Goal: 본 연구는 금융 분야의 장문 질문응답(Long-Form Question Answering, LFQA)에서 대형 언어모델(LLMs)의 신뢰성 있는 출처 표기와 정밀한 추론능력을 평가하기 위한 벤치마크인 FINLFQA를 제안하는 데 있다.  
- Motivation: LLM들이 장문 질문에 대해 사실과 다른 내용을 생성하는 환각(hallucination) 문제를 극복하기 위해 출처 제시가 요구되나, 기존 평가 기준은 단순한 근거문헌 검색에 집중하여 금융과 같은 전문 분야에서는 부족하다.  
- Contribution: FINLFQA는 금융 보고서에서 추출된 근거, 중간 수치 추론 과정, 전문 금융지식 세 가지 출처 표기 유형을 포함해 LLM의 답변 및 출처 생성 능력을 정밀하게 평가하는 자동화된 다차원 평가지표 체계를 설계하였다.  

## Method  
금융 회사 두 곳의 분기 재무보고서와 질문, 전문 금융지식 목록을 입력으로 활용하며, 전문가가 세분화한 답변 절(clause)별로 근거 문단, 수치 추론을 위한 실행 가능한 코드, 관련 금융 지식 출처를 함께 표기하도록 데이터셋을 구성하였다.  
평가를 위해 ROUGE나 BERTScore와 같은 표면적 텍스트 유사도 외에 LLM 평가자(GPT-4o)를 활용해 사실정확성, 수치정확성, 근거 적합성을 점수화하는 자동 평가 시스템을 개발하였다.  
LLM 출처 생성 방식으로 사후 생성(Post-hoc), 종단 간 생성(End-to-end), 반복 정제(Iterative refinement) 세 가지 방법론을 실험하였다.  

## Results  
GPT-4o가 전반적인 평가점수와 수치정확성에서 최고 성능을 보였으며, 사후 생성과 종단 간 생성은 성능 차이가 미미하고 반복 정제는 외부 피드백 부재 시 효과가 제한적임을 확인하였다.  

## Limitations  
현재 FINLFQA는 두 개 기업을 대상으로 제한된 금융 데이터를 활용하였으며, 수치 추론과 사실 근거화에서 LLM들의 어려움이 여전히 존재한다.  

## Conclusion  
FINLFQA는 금융 분야 LLM 장문 질문응답에서 정밀한 출처 표기와 신뢰성 있는 답변 생성을 평가할 수 있는 포괄적 벤치마크를 제공하며, 이를 통해 다양한 출처 생성 방법과 모델 성능을 객관적으로 비교할 수 있음을 입증하였다.
