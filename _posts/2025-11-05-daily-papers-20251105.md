---
layout: post
title: "Daily Papers — 2025-11-05"
date: 2025-11-05 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [Can Visual Input Be Compressed? A Visual Token Compression Benchmark for   Large Multimodal Models](https://arxiv.org/abs/2511.02650)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.02650)

## Introduction
- Goal: 본 연구는 대형 멀티모달 모델에서 시각 입력 토큰 압축 방식을 체계적으로 평가하는 통합 벤치마크 UniPruneBench를 제안하는 데 목적이 있다.  
- Motivation: 이미지 인코더가 생성하는 다수의 시각 토큰으로 인해 대형 멀티모달 모델의 추론 효율성이 크게 저하되는 문제를 해결할 필요가 존재한다.  
- Contribution: UniPruneBench는 여섯 가지 능력 차원과 열 개 데이터셋, 열 가지 압축 알고리즘, 세 가지 LMM 계열 모델에 대한 일관된 평가 프로토콜 및 시스템 지표를 제공한다.  

## Method  
본 벤치마크는 시각 토큰 압축 방법을 비전 인코더(Vis-only), 언어 모델(LLM-only), 혼합(Hybrid) 세 그룹으로 분류하여 평가한다.  
토큰 프루닝 위치를 고려한 이 접근법은 다양한 모델에 플러그 앤 플레이 형태로 통합 가능하며, 정확도와 실행 시간 등의 시스템 지표도 측정한다.  
실험에는 LLaVA-v1.5, Intern-VL3, Qwen2.5-VL 모델이 사용되었으며, 각기 다른 정밀도 저하율에서 성능 변화를 분석하였다.  

## Results  
랜덤 프루닝이 기존 설계된 방법들보다 경쟁력 있는 성능을 보였고, 특정 방법이 모든 시나리오에서 우수하지는 않았으며, OCR 작업은 프루닝에 민감한 반면 명령 수행 작업은 견고한 경향을 나타냈다.  

## Limitations  
단순한 단계별 토큰 프루닝 조합은 단일 단계 프루닝에 비해 일관된 성능 향상을 보장하지 못하였다.  

## Conclusion  
UniPruneBench는 대형 멀티모달 모델의 시각 토큰 압축을 공정하고 재현 가능하게 평가할 수 있는 기반을 제공하며, 효율적인 멀티모달 학습 및 배치 연구를 촉진할 것으로 기대된다.
