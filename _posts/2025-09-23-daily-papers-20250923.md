---
layout: post
title: "Daily Papers — 2025-09-23"
date: 2025-09-23 08:15:00
tags: [papers, hugginface]
categories: []
---

# 1. [Qwen3-Omni Technical Report](https://arxiv.org/abs/2509.17765)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.17765)

## Introduction

- Goal: 본 보고서는 텍스트, 이미지, 오디오, 비디오 등 다양한 모달리티에서 단일 모델로 최첨단 성능을 유지하는 멀티모달 언어 모델 Qwen3-Omni를 소개하고자 한다.
- Motivation: 기존 멀티모달 모델들은 하나의 모달리티 성능 향상이 다른 모달리티의 저하를 초래하는 한계를 가지고 있어 이를 극복하는 통합적 멀티모달 학습 방안이 요구된다.
- Contribution: Qwen3-Omni는 Thinker-Talker MoE 아키텍처를 활용해 모든 모달리티에서 단일 모달 대비 성능 저하 없이 최고 수준의 성능을 달성하고, 119개 언어 텍스트, 19개 언어 음성 이해 및 10개 언어 음성 생성이 가능한 모델을 공개하였다.

## Method

Qwen3-Omni는 텍스트 생성 담당 Thinker와 실시간 음성 생성을 담당하는 Talker 모듈로 구성되며, 양쪽 모두 Mixture-of-Experts 구조를 채택해 고성능과 고동시성 처리를 지원한다. 오디오 인코더로는 2천만 시간 이상의 감독 오디오로 학습한 Audio Transformer (AuT)를 사용하며, Talker는 다중 코드북을 통한 자가회귀 음성 생성 방식을 적용해 저지연 실시간 스트리밍을 가능케 하였다. 또한, TM-RoPE 위치 인코딩을 이용해 멀티모달 정보를 시간 축에 맞춰 정교하게 처리한다.

## Results

Qwen3-Omni는 36개 오디오 및 오디오비주얼 벤치마크에서 32개 오픈소스 최첨단 성능(SOTA)을 달성하고, Gemini-2.5-Pro, Seed-ASR, GPT-4o-Transcribe와 같은 강력한 폐쇄형 모델들을 능가하였다.

## Limitations

정보 부족.

## Conclusion

Qwen3-Omni는 모달리티 간 성능 저하 없이 통합된 멀티모달 이해·생성 능력을 제공하며, 연구 및 산업 환경에서 고품질의 멀티모달 상호작용을 위한 실용적 기반을 마련하였다.

# 2. [OnePiece: Bringing Context Engineering and Reasoning to Industrial Cascade Ranking System](https://arxiv.org/abs/2509.18091)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.18091)

## Introduction

- Goal: 본 연구는 대규모 언어 모델(LLM)의 문맥 엔지니어링 및 다단계 추론 메커니즘을 산업용 계단식 랭킹 시스템에 통합하는 통합 프레임워크 OnePiece를 제안하는 데 목적이 있다.
- Motivation: 기존 산업용 랭킹 시스템은 주로 Transformer 아키텍처 이식에 집중하여 개선 폭이 제한적이며, LLM의 핵심 성공 요인인 문맥 강화와 다단계 추론을 충분히 탐구하지 못하였다.
- Contribution: 본 논문은 구조화된 문맥 엔지니어링, 블록 단위 잠재 추론, 점진적 다중과제 훈련을 결합한 OnePiece를 제안하고, 이를 쇼피(Shopee) 개인화 검색에 적용하여 기존 대비 유의미한 성과 향상을 입증하였다.

## Method

OnePiece는 사용자 상호작용 이력, 선호 앵커, 상황 설명자, 후보 아이템 세트를 통합한 통합 토큰 시퀀스로 입력을 구성하고, 순수 Transformer 기반의 블록 단위 잠재 추론을 통해 표현을 다단계로 점진적으로 정제한다. 점진적 다중과제 학습 전략으로 클릭, 장바구니 담기, 주문 등 사용자 피드백 체인을 활용하여 각 추론 단계에 맞는 감독 신호를 제공한다. 조회 단계에서는 유저와 쿼리 토큰을 중심으로, 랭킹 단계에서는 무작위 그룹화된 후보 아이템 세트를 활용해 세밀한 비교 및 평가가 가능하도록 설계되었다.

## Results

광범위한 오프라인 실험과 쇼피에서의 대규모 온라인 A/B 테스트를 통해 OnePiece가 기존 DLRM 대비 로그 데이터가 더 적음에도 우수한 효율성과 지속적 성능 향상을 달성하며, GMV/UU 2% 이상 및 광고 수익률 2.90% 증가를 포함한 핵심 지표에서 일관된 비즈니스 이익을 확인하였다.

## Limitations

구체적인 한계점에 대한 기술은 본문에 명확히 제시되지 않아 정보 부족이다.

## Conclusion

OnePiece는 LLM의 문맥 강화 및 다단계 추론 기법을 산업용 계단식 랭킹 시스템에 성공적으로 이식하여 실환경에서 효과적인 성능 향상과 사업적 가치를 제공함을 검증하였다.

# 3. [EpiCache: Episodic KV Cache Management for Long Conversational Question Answering](https://arxiv.org/abs/2509.17396)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.17396)

## Introduction

- Goal: 본 논문은 장기 대화형 질문응답(LongConvQA)에서 제한된 메모리 환경 하에 효과적으로 동작하는 훈련 불필요한 키-값(Key-Value, KV) 캐시 관리 기법을 제안하는 데 목적이 있다.
- Motivation: 대화 길이에 따라 선형적으로 증가하는 KV 캐시 메모리 요구량은 엄격한 자원 제약 조건에서 대화 AI 시스템의 효율적 구현을 어렵게 한다.
- Contribution: EPICACHE라는 블록 단위 선입력(prefill)과 화제별 대화 분할(episodic clustering), 층별 민감도 기반 예산 할당을 결합한 KV 캐시 관리 프레임워크를 통해 기존 대비 최대 40% 향상된 정확도와 3.5배 메모리 절감, 2.4배 응답 지연 감소를 달성하였다.

## Method

EPICACHE는 대화 이력을 의미론적으로 분할하여 대표 대화 세그먼트를 선정한 후 이를 패치드 프롬프트로 활용해 블록 단위로 KV 캐시를 압축하고, 각 층별로 캐시 예산을 민감도에 따라 적응적으로 배분한다. 이로써 메모리 사용량을 고정하고 특정 주제 관련 정보를 효과적으로 보존한다. 최종적으로 사용자 쿼리를 클러스터링된 대화 에피소드에 매칭하여 해당 에피소드별 압축 캐시만 조회한다.

## Results

EPICACHE는 세 가지 LongConvQA 벤치마크에서 기존 방법 대비 약 20 점수 이상 높은 정확도를 기록하며, 4~6배 압축된 KV 캐시 상태에서도 거의 완전한 캐시 정확도를 유지하였다.

## Limitations

EPICACHE는 쿼리-에피소드 매칭 및 캐시 검색 과정에서 일부 연산 오버헤드가 발생하며, 다중 에피소드 전환 시 효율성이 다소 감소할 수 있다.

## Conclusion

본 연구는 제한된 메모리 자원 하에서도 주제 관련 문맥을 효과적으로 유지하며, 장기 대화 질문응답의 정확도와 효율성을 크게 개선하는 실용적인 KV 캐시 관리 전략을 제시하였다.

# 4. [VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models](https://arxiv.org/abs/2509.17985)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.17985)

## Introduction

- Goal: 본 논문은 거친 기하구조, 카메라 궤적, 참조 이미지를 입력으로 받아 고품질 3D 장면 영상을 합성하는 새로운 프레임워크 VideoFrom3D를 제안한다.
- Motivation: 기존 비디오 확산 모델은 복잡한 장면에서 시각 품질, 운동, 시간적 일관성을 동시에 모델링하는 데 어려움을 겪어 고해상도 3D 영상 생성에 한계가 존재한다.
- Contribution: 이미지 확산 모델과 비디오 확산 모델의 상호 보완적 강점을 활용하는 두 단계 모듈(Sparse Anchor-view Generation, Geometry-guided Generative Inbetweening)로 고품질, 스타일 일관성, 구조적 충실도를 달성하는 3D 장면 영상 합성 프레임워크를 개발하였다.

## Method

VideoFrom3D는 (1) 3D 메시 모델과 카메라 경로로부터 구조적 에지와 광학 흐름을 추출하고, (2) 이미지 확산 기반 SAG 모듈이 참조 스타일에 맞는 고품질 앵커 뷰를 생성하며, (3) 비디오 확산 기반 GGI 모듈이 앵커 뷰 사이의 중간 프레임을 시간적 일관성을 유지하며 보간하여 최종 영상 시퀀스를 합성한다. 이 과정에서 SAG 모듈은 Sparse Appearance-guided Sampling을 도입해 왜곡된 시점 간 외관 정보를 활용하여 앵커 뷰 간 일관성을 확보하며, GGI 모듈은 광학 흐름과 구조적 가이드를 함께 활용하여 정확한 카메라 궤적을 반영한다. 또한 학습에는 3D 모델과 자연 영상의 페어 데이터셋에 의존하지 않고 일반 영상 데이터셋 기반으로 GGI 모듈을 효과적으로 훈련하였다.

## Results

다양한 실험에서 제안 기법은 기존의 단일 비디오 확산 모델 및 최신 3D 재구성 방법 대비 시각적 충실도, 스타일 일관성, 구조적 정합성 등 대부분의 정량적 및 정성적 평가 지표에서 우수한 성능을 보였다.

## Limitations

본 프레임워크는 실시간 내비게이션을 지원하지 않으며, 픽셀 단위 뷰 간 완벽한 일치성을 보장하지 않는다.

## Conclusion

VideoFrom3D는 거친 기하구조와 최소한의 입력만으로도 빠르고 유연하게 고품질 3D 장면 비디오를 생성하는 혁신적인 접근법을 제시하였다.

# 5. [Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications](https://arxiv.org/abs/2509.17671)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.17671)

## Introduction

- Goal: 본 논문은 터키어 RAG(Retrieval-Augmented Generation) 응용을 위한 최초의 환각(hallucination) 탐지 모델인 Turk-LettuceDetect를 제안하는 것이다.
- Motivation: 대형 언어 모델(LLMs)은 신뢰성 문제인 환각 생성 경향으로 인해 실용적 적용에 한계가 존재하며, 특히 형태학적으로 복잡한 저자원 언어인 터키어에서는 환각 탐지 연구가 미흡한 상황이다.
- Contribution: LettuceDetect 프레임워크를 기반으로 터키어에 특화된 세 가지 인코더 구조(ModernBERT, TurkEmbed4STS, EuroBERT)를 활용하여 토큰 단위 환각 탐지 모델을 구현하고, 이에 맞춘 기계 번역된 RAGTruth 데이터셋으로 미세 조정한 결과를 제시한다.

## Method

RAGTruth 데이터셋의 기계 번역 버전을 사용하여 토큰별 이진 분류 문제로 환각 탐지 모델을 학습하였다. 세 가지 터키어 지원 인코더(ModernBERT-base-tr, TurkEmbed4STS, euroBERT)를 LettuceDetect 기법에 적용하여 환각 여부를 판별하도록 미세 조정하였다. 또한, 8,192 토큰까지 처리 가능한 현대적 인코더 아키텍처를 채택하여 긴 문맥 기반 환각 탐지에 적합하도록 설계하였다.

## Results

ModernBERT 기반 모델은 전체 테스트셋에서 F1-score 0.7266의 성능을 기록하였으며, 특히 구조화된 질의응답 및 데이터-텍스트 변환 과제에서 우수한 탐지 능력을 보였다.

## Limitations

추상적 요약 생성 과제에서 환각 탐지 성능이 다소 저조하여, 과제별 탐지 전략의 추가 연구가 요구된다.

## Conclusion

Turk-LettuceDetect는 터키어 RAG 환경에서 환각 탐지를 위한 기초를 마련하여 실시간 환경에서도 신뢰성 높고 계산 효율적인 모델 개발에 기여하였으며, 다국어 및 저자원 언어 환각 탐지 연구 발전에 중요한 이정표를 제공한다.

# 6. [QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models](https://arxiv.org/abs/2509.17428)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.17428)

## Introduction

- 본 연구의 목표는 대형 언어 모델(LLM)의 효율적인 양자화 인식 파라미터 효율적 미세 조정(Quantization-Aware PEFT)을 위한 새로운 어댑터 구조와 초기화 방식을 제안하는 것이다.
- LLM의 추론 비용 절감과 학습 오버헤드 감소를 위해 양자화와 파라미터 효율적 미세 조정 기술이 요구되며, 특히 미세 조정 전 양자화 오차 감소가 모델 정확도 향상에 중요하다.
- Walsh-Hadamard 변환(WHT) 기반 어댑터와 적응형 파라미터 할당 및 값 정제 기법을 결합한 QWHA를 제안하여 양자화 오차를 효과적으로 줄이고 계산 비용을 크게 절감하였다.

## Method

QWHA는 WHT를 변환 핵심으로 이용하는 FT 기반의 고표현력 어댑터(WHA)와, 채널별 양자화 오차에 따라 파라미터 위치를 할당하는 AdaAlloc, 선별된 값 정제를 포함하는 양자화 인식 초기화 체계를 포함한다.  
WHT는 ±1로만 구성되어 계산 효율성이 높으며, 단일 변환만을 적용하여 기존 FT 기반 어댑터 대비 연산 부담을 줄였다.  
초기화는 계층 출력 오차를 최소화하는 희소 행렬 근사 문제를 채널별 분할하여 근사하고, 값 정제를 통해 근사 성능을 높였다.

## Results

QWHA는 다양한 LLM과 벤치마크(예: CSQA, GSM8k)에서 2~4비트 저비트 양자화 환경에서 기존 LoRA 기반 및 FT 기반 어댑터를 능가하는 정확도 및 학습 속도 향상을 보였다.

## Limitations

본 연구는 FT 기반 어댑터 초기화 전략 탐색에 집중하였으나, 실제 배포 환경에서의 추가적인 메모리 절감 효과와 확장성에 관한 고찰은 부족하다.

## Conclusion

QWHA는 WHT 기반 어댑터와 양자화 인식 초기화 기술을 통해 저비트 양자화 환경에서 LLM의 미세 조정 정확도와 효율성을 동시에 향상시키는 효과적인 QA-PEFT 방법임이 입증되었다.

# 7. [Understanding Embedding Scaling in Collaborative Filtering](https://arxiv.org/abs/2509.15709)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.15709)

## Introduction

- Goal: 협업 필터링에서 임베딩 차원의 확장에 따른 성능 변화를 이해하는 것이다.
- Motivation: 임베딩 차원의 확장이 성능 저하를 유발한다는 기존 연구들의 관측에도 불구하고, 그 원인과 다양한 모델 및 데이터셋에서의 적용 가능성이 명확하지 않았기 때문이다.
- Contribution: 대규모 실험을 통해 임베딩 차원 확장 시 나타나는 이중 봉우리(double-peak)와 로그 곡선(logarithmic) 현상을 발견하고, 잡음에 의한 상호작용이 원인임을 해석하며, 주요 협업 필터링 모델의 잡음 내성에 대한 이론적 분석을 제시하였다.

## Method

10개의 데이터셋과 4가지 대표 협업 필터링 모델(BPR, NeuMF, LightGCN, SGL)을 대상으로 임베딩 차원을 확장하며 성능 변화를 관찰하였다.  
잡음 상호작용의 영향을 분석하기 위해 잡음 내성 및 잡음에 민감한 성능 변화를 수학적으로 정리하고, 잡음 완화 전략으로 샘플 드롭 방식을 도입하였다.  
또한, 그래프 기반 모델과 자기지도 학습을 도입한 모델의 잡음 저항 특성을 스펙트럼 및 정보 이론 관점에서 분석하였다.

## Results

임베딩 차원 확장에 따라 기존 알려진 단일 봉우리 현상 외에, 데이터셋과 모델에 따라 이중 봉우리와 로그 곡선 현상이 공존하며, 잡음 저항력이 높은 모델일수록 안정적인 로그 곡선 패턴을 보였다.

## Limitations

컴퓨팅 자원의 한계로 다양한 협업 필터링 모델에 대한 실험과 Top@K에서 K=20 외 다른 평가 지표 실험이 제한되었다.

## Conclusion

임베딩 차원 확장 시 나타나는 성능 변화 현상을 새롭게 규명하고, 잡음 상호작용이 이중 봉우리 현상의 주요 원인임을 밝히며, 잡음 내성 모델 설계가 확장성 향상에 핵심임을 이론적·실험적으로 증명하였다.

# 8. [Synthetic bootstrapped pretraining](https://arxiv.org/abs/2509.15248)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.15248)

## Introduction

- Goal: 본 논문은 기존 문서 내 토큰 간 인과관계 학습을 넘어 문서 간 상호의존성을 반영하는 신경망 언어 모델의 사전학습 방법인 Synthetic Bootstrapped Pretraining(SBP)을 제안하는 것을 목표로 한다.
- Motivation: 고품질의 웹 텍스트 데이터가 빠르게 고갈됨에 따라 기존 사전학습 데이터의 효과적 활용 방안 모색이 필요하다.
- Contribution: SBP는 문서 간 조건부 확률 모델을 학습하여 합성 데이터를 생성하고 이를 바탕으로 문서 간 상관관계를 포착함으로써 동일한 데이터 내에서 의미 있는 성능 향상을 경험하였다.

## Method

SBP는 세 단계로 진행된다. 우선 유사도가 높은 문서 쌍을 선별한 뒤, 첫 문서가 주어졌을 때 두 번째 문서를 생성하는 조건부 데이터 합성기를 학습한다. 마지막으로 학습된 합성기를 이용해 사전학습 데이터 내에서 방대한 합성 문서를 생성하여 원본과 합성 데이터를 병합해 공동 학습한다.

## Results

1조 토큰 규모의 사전학습에서 SBP는 데이터 반복 학습 기반 강력한 베이스라인을 일관되게 능가했으며, 20배 더 많은 고유 데이터에 접근 가능한 오라클 상한에 근접하는 상당한 성능 향상을 기록하였다.

## Limitations

본 연구는 대규모 데이터셋과 고성능 컴퓨팅 자원을 필요로 하여 자원 제약 환경에서의 적용 가능성에는 제약이 존재한다.

## Conclusion

SBP는 문서 간 잠재 개념을 베이지안 모델링 관점에서 추론하며, 기존 사전학습에서 누락된 문서 간 상호관계를 활용하여 언어 모델의 성능을 개선함을 규명하였다.

# 9. [Accurate and Efficient Low-Rank Model Merging in Core Space](https://arxiv.org/abs/2509.17786)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.17786)

## Introduction

- Goal: 본 논문은 대형 신경망의 저랭크 적응(LoRA) 모델들을 정확하고 효율적으로 병합하는 방법을 제안하는 것이다.
- Motivation: 기존 저랭크 적응 기반 파인튜닝은 효율적이나, 기존 병합 방법은 전체 가중치 행렬 병합으로 효율성이 저하되는 문제가 있었다.
- Contribution: 저랭크 적응의 효율성을 유지하면서 정확도를 향상시키는 공통 정렬 기저(Core Space)를 도입하고, 정보 손실 없는 투영 및 효율성을 수학적으로 증명하였다.

## Method

Core Space 병합 프레임워크는 여러 작업별 LoRA 행렬들을 공유하는 저차원 기저에 사영하여 병합 문제를 훨씬 적은 차원 공간에서 해결한다.  
각 작업의 저랭크 행렬에 대해 특이값 분해(SVD)를 적용하여 핵심 행렬을 추출하고, 공통 참조 기저에 맞춰 정렬한 뒤 병합하여 최종 모델을 복원한다.  
이 과정은 정보 손실이 없으며, 기존의 고차원 병합 방식보다 계산량이 크게 줄고 고성능을 달성한다.

## Results

비전과 자연어 추론 과제들에서 제안한 Core Space 병합 기법은 기존 기법 대비 최대 600배 이상의 병합 속도 향상과 함께 성능도 꾸준히 우수하여 최첨단 결과를 기록하였다.

## Limitations

정보 손실이 전혀 없음을 수학적으로 증명했으나, 저차원 차원 수(T×r)가 매우 커지는 경우 효율성 저하가 발생할 수 있다.

## Conclusion

Core Space는 다중 작업 설정에서 대형 모델의 LoRA 적응 모듈들을 효율적으로 병합하여 정확도를 향상시키는 실용적인 프레임워크로서, 대규모 모델 적응의 접근성과 효율성에 기여한다.

# 10. [CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects](https://arxiv.org/abs/2509.14856)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.14856)

## Introduction

- Goal: 본 연구는 실제 코드 리뷰의 맥락과 전 과정을 반영하는 종합적이고 저장소 수준의 자동 코드 리뷰 평가 벤치마크인 CodeFuse-CR-Bench를 제안하는 것이다.
- Motivation: 기존 자동 코드 리뷰 평가들은 단편적인 하위 작업과 문맥이 부족한 데이터를 사용하여 실제 리뷰 작업과의 괴리가 존재하는 문제를 해결하기 위함이다.
- Contribution: CodeFuse-CR-Bench는 70개 파이썬 프로젝트에서 601개의 고품질 인스턴스를 수집하고, 위치 및 문법 검증과 모델 기반 리뷰 품질 판단을 결합한 새로운 평가 프레임워크를 도입하였다.

## Method

CodeFuse-CR-Bench는 기본 정보, PR 관련 정보, 코드 리뷰 관련 정보, 저장소 수준의 문맥 정보를 포함하는 다면적 데이터로 구성되며, 유의미한 PR 커밋을 휴리스틱 규칙으로 선별한다.  
평가는 규칙 기반 위치 및 의미적 유사성 검사와 보상 모델 및 LLM-심사자 모델을 활용한 종합적 모델 기반 평가를 통합하여 수행한다.  
또한 PR 문제 영역, 난이도, 리뷰 노력 등 다양한 속성을 라벨링하고, 수작업 필터링과 주관적 평가를 통해 노이즈를 제거하였다.

## Results

CodeFuse-CR-Bench를 이용한 대규모 실험 결과, 어떤 단일 LLM도 코드 리뷰의 모든 측면을 지배하지 못하며 Gemini 2.5 Pro가 종합 성능 최고를 기록하였고 LLM별로 중복 문맥에 대한 강건성 차이가 드러났다.

## Limitations

본 벤치마크 및 평가 프레임워크는 파이썬 프로젝트에 한정되었으며, 다른 언어 및 도메인에 대한 확장성은 추가 연구가 필요하다.

## Conclusion

CodeFuse-CR-Bench는 현존하는 단편적 평가의 한계를 극복하고 실무에 가까운 코드 리뷰 성능 평가를 가능하게 하여 차세대 지능형 코드 리뷰 도구 발전의 기초를 마련하였다.

# 11. [From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem](https://arxiv.org/abs/2509.09873)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2509.09873)

## Introduction

- Goal: 본 논문은 오픈소스 AI 생태계 내에서 데이터셋, 모델, 그리고 소프트웨어 애플리케이션 간 라이선스 연속성을 추적하여 라이선스 충돌 발생 빈도와 원인, 영향을 받는 커뮤니티를 분석하는 것을 목표로 한다.
- Motivation: 오픈소스 AI 생태계에서 라이선스 충돌이 법적·윤리적 위험을 내포하지만, 이러한 문제의 전반적 규모와 경로에 대한 데이터 기반 연구가 부족하다는 점에 주목하였다.
- Contribution: 대규모 데이터셋·모델·깃허브 프로젝트를 아우르는 최초의 종합적인 라이선스 감사와 AI 특화 라이선스 충돌 탐지 및 해결을 위한 LicenseRec 규칙 엔진을 제안하였다.

## Method

Hugging Face에서 36만 개 데이터셋과 160만 개 모델, 14만 개 깃허브 저장소까지 전체 AI 공급망을 연결하는 의존성 그래프를 구축하였다.  
라이선스 범주화를 통해 라이선스 전파를 분석하고, Moreau et al.의 논리 기반 호환성 모델을 적용하여 라이선스 간 충돌을 자동 탐지하는 LicenseRec 엔진을 구현하였다.  
정적 코드 분석 및 GitHub 코드 검색을 활용해 모델의 실제 사용 여부를 검증한 후 라이선스 충돌 시 호환 가능한 라이선스 추천 기능을 제공하였다.

## Results

분석 결과 전체 모델-애플리케이션 전이의 35.5%에서 라이선스 충돌이 발생하며, LicenseRec는 86.4%의 충돌을 자동으로 교정 가능한 것으로 확인되었다.

## Limitations

LicenseRec의 정확도는 입력 데이터의 라이선스 태그 및 감지에 의존하며, 근본적인 라이선스 불일치는 도구로 해소 불가능하여 개발자 주의가 필수적이다.

## Conclusion

본 연구는 오픈소스 AI 생태계 내 라이선스 비준수의 전반적 규모와 문제 경로를 규명하고, 자동화된 AI 특화 규칙 엔진을 통해 다수 충돌을 해결할 수 있음을 보여주며, 법적 위험을 줄이기 위한 도구와 데이터를 함께 제공하여 책임 있는 AI 개발의 기반을 마련한다.
