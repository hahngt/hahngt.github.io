---
layout: post
title: "Daily Papers — 2025-10-29"
date: 2025-10-29 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [Uniform Discrete Diffusion with Metric Path for Video Generation](https://arxiv.org/abs/2510.24717)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.24717)

## Introduction
- Goal: 본 연구는 이산적 공간에서 영상 생성을 위한 확산 기반 모델인 URSA를 제안하여 연속적 접근법과의 성능 격차를 해소하고 확장 가능한 영상 생성을 실현하는 것을 목표로 한다.  
- Motivation: 기존 이산적 생성 모델은 오차 누적과 긴 시퀀스 내 일관성 유지의 한계로 연속적 확산 모델에 비해 성능이 뒤처지는 문제점이 존재하였다.  
- Contribution: URSA는 선형화된 거리 기반 경로와 해상도 의존적 시간 단계 조정 메커니즘, 비동기 시간 스케줄링 전략을 도입하여 다양한 영상 생성 작업을 하나의 모델로 효율적으로 수행할 수 있음을 증명하였다.  

## Method  
URSA는 범주형 노이즈에서 출발하여 이산 시공간 토큰을 전역적으로 반복 정제하는 방식을 채택하였다. 선형화된 거리 기반 확산 경로와 해상도에 따라 변화하는 시간 단계 변환을 통해 장기 시퀀스에 적합한 섬세한 분포 제어를 가능하게 하였다. 또한 각 프레임별로 독립적인 시간 단계를 무작위로 할당하는 비동기적 스케줄링을 도입하여 이미지-비디오 변환, 보간, 장기 영상 생성 등 다중 과제를 통합하였다.  

## Results  
URSA는 텍스트-비디오, 이미지-비디오 및 텍스트-이미지 생성 벤치마크에서 기존 이산적 모델을 일관되게 능가하고, 최고 수준의 연속 확산 모델과 견줄 만한 성능을 달성하였다.  

## Limitations  
현행 이산 비전 토크나이저의 표현 한계로 인해 생성물의 화질 개선에는 제약이 존재하였다.  

## Conclusion  
URSA는 이산 및 연속 확산 모델 간의 간극을 효과적으로 좁히며, 확장 가능하고 다목적으로 활용 가능한 영상 생성의 새로운 방향을 제시하였다.

# 2. [Routing Matters in MoE: Scaling Diffusion Transformers with Explicit   Routing Guidance](https://arxiv.org/abs/2510.24711)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.24711)

## Introduction
- 본 논문은 Diffusion Transformer(DiT) 모델에서 MoE(Mixture-of-Experts) 구조의 성능 향상을 목적으로 한다.  
- 기존 DiT에 MoE를 적용한 연구들은 언어 모델과 달리 시각 토큰의 중복성과 기능적 이질성으로 인해 전문가 특화가 어렵다는 문제점에서 착안하였다.  
- 이를 해결하기 위해 토큰의 기능적 역할과 의미적 내용을 기반으로 하는 명시적 라우팅 가이던스를 도입한 ProMoE 프레임워크를 제안하였다.

## Method
- ProMoE는 기능별 토큰 분할을 수행하는 조건부 라우팅과 의미적 특성을 반영하는 프로토타입 라우팅의 두 단계 라우터로 구성된다.  
- 프로토타입 라우팅은 각 전문가에 대응되는 학습 가능한 프로토타입과 토큰의 코사인 유사도를 이용해 라우팅 가중치를 산출하며, 이를 통해 전문가 간 내·외부 일관성과 다양성을 촉진한다.  
- 추가로 라우팅 대비학습(Routing Contrastive Loss)을 도입하여 의미적으로 유사한 토큰은 동일 전문가에, 다른 토큰은 상이 전문가에 배정되도록 명시적 가이던스를 강화한다.

## Results
- ImageNet 벤치마크에서 ProMoE는 동일 활성 파라미터 수 대비 기존 Dense DiT 및 최신 MoE 기법들을 크게 능가하며, 특히 Rectified Flow 학습에서 FID 점수를 최대 29.4%까지 감소시키고 Inception Score를 크게 향상시켰다.

## Limitations
- 평가 지표인 FID 및 IS가 세밀한 지각 품질이나 의미적 충실도를 완벽히 반영하지 못하며, 본 연구는 이미지 생성에 국한되어 다중 모달 확장 가능성에 대한 검증은 이루어지지 않았다.

## Conclusion
- ProMoE는 명확한 라우팅 가이던스를 활용하여 DiT 기반 비전 모델에서 MoE 전문가 특화를 성공적으로 달성하고, 기존 한계를 극복하여 우수한 성능과 효율성을 입증한 효과적인 확장 방법임을 보였다.

# 3. [ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining,   Finetuning, and Decoding the Curse of Multilinguality](https://arxiv.org/abs/2510.22037)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.22037)

## Introduction
- Goal: 본 연구는 다국어 사전학습, 미세조정, 그리고 다국어 모델 확장 과정에서의 적응형 전이 확장 법칙(ATLAS)을 제안하고, 다국어성의 저주를 해독하는 것을 목표로 한다.  
- Motivation: 기존 확장 법칙 연구가 대부분 영어에 집중되어 있으나, 주요 AI 모델은 수십억 다국어 사용자에게 서비스를 제공하므로 다국어 확장 법칙 연구가 필요하다.  
- Contribution: 774개의 다국어 학습 실험을 통해 ATLAS를 개발하고, 38개 언어 간 전이 행렬과 다국어 확장 시 모델 크기 및 데이터 최적 스케일링 법칙을 제시하였다.  

## Method  
본 연구에서는 10M에서 8B 파라미터 범위 모델과 400개 이상의 훈련 언어, 48개 평가 언어를 대상으로 MADLAD-400 데이터셋을 활용하여 다양한 다국어 및 단일 언어 사전학습과 미세조정 실험을 수행하였다.  
ATLAS는 언어별 데이터 반복성, 언어 간 전이 효과를 고려하여 단일 목표 언어 데이터, 전이 언어 데이터, 그 외 언어 데이터를 구분하고, 각 요소에 대한 포화 함수를 도입하여 효과적인 데이터 사용량을 계산한다.  
또한, 다국어성 저주 현상을 모델 크기, 데이터량, 언어 수로 정량화하고, 사전학습과 미세조정 간 효율적 전환 시점을 수학적으로 도출하였다.  

## Results  
ATLAS는 기존 다국어 확장 법칙과 비교하여 모델 크기, 데이터량, 컴퓨팅 자원, 훈련 언어 혼합에 대한 일반화 성능에서 평균 R² 0.9 이상의 우수한 적합도를 보여주었다.  

## Limitations  
본 연구는 훈련 언어 분포가 균일하다는 가정을 기반으로 하며, 미세조정과 사전학습의 교차점은 특정 다국어 체크포인트와 훈련 조건에 제한된다.  

## Conclusion  
ATLAS는 다국어 모델 확장과 전이 학습을 과학적으로 정량화하여 다국어 AI 모델의 효율적 확장과 실용적 설계에 기여하는 포괄적 확장 법칙을 제공한다.

# 4. [Batch Speculative Decoding Done Right](https://arxiv.org/abs/2510.22876)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.22876)

## Introduction
- Goal: 본 논문은 대규모 언어 모델 추론 가속을 위한 배치 투기적 디코딩(batch speculative decoding)에서 올바른 동기화와 효율적 스케줄링을 통해 출력 정합성을 유지하면서 성능을 극대화하는 방법을 제시하고자 한다.  
- Motivation: 기존 배치 투기적 디코딩 구현은 길이가 서로 다른 시퀀스들의 불규칙한 텐서(ragged tensor) 문제로 위치 아이디, 어텐션 마스크, KV-캐시 상태 동기화가 깨지며 출력이 손상되는 문제를 겪기 때문이다.  
- Contribution: 본 연구는 최소 동기화 불변량을 규정하고 유지하는 EQSPEC 알고리즘과, 동적 그룹핑을 통한 오버헤드 감소 기법 EXSPEC를 개발하여 95% 이상의 출력 정합성 보장과 배치 크기 8에서 최대 3배 처리량 향상을 달성하였다.

## Method
본 연구는 불규칙한 배치 내 시퀀스 길이 차이로 야기되는 텐서 정렬 문제를 전처리 과정에서 위치 아이디, 어텐션 마스크, KV-캐시 동기화를 엄격히 보장하는 EQSPEC으로 해결한다. 이어서 EXSPEC에서는 개별 시퀀스를 풀에 유지하며 동일 길이 시퀀스를 동적으로 그룹화하여 오버헤드를 줄이고 실시간 재정렬 비용을 최소화한다. 이를 통해 정확성을 유지하면서도 배치 기반 병렬처리가 가지는 속도 장점을 효과적으로 활용한다.

## Results
Vicuna-7B/68M, Qwen3-8B/0.6B, GLM-4-9B/0.6B 모델 쌍에 대한 SpecBench 평가에서 본 방법은 기존 연구 및 상용 시스템과 달리 95% 이상의 출력 정합성과 배치 크기 8 기준 최대 3배의 처리량 향상을 동시에 달성하였다.

## Limitations
배치 크기가 8을 초과할 경우 시퀀스 길이 다양성이 커져 그룹화 효율이 급감하며 재정렬 오버헤드가 증가하여 처리량 개선 효과가 감소한다.

## Conclusion
본 연구는 배치 투기적 디코딩의 출력 등가성 유지와 실용적 속도 향상 간의 근본적 긴장을 해소한 알고리즘과 스케줄링 방안을 제시하여 향후 대규모 언어 모델 서비스 시스템 설계에 중요한 기초를 제공한다.

# 5. [SAO-Instruct: Free-form Audio Editing using Natural Language   Instructions](https://arxiv.org/abs/2510.22795)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.22795)

## Introduction
- Goal: 본 연구의 목표는 자연어 기반의 자유 형식 음성 편집이 가능한 모델인 SAO-Instruct를 제안하는 것이다.  
- Motivation: 기존 음성 편집 기법은 완전한 목표 음성의 설명이나 사전 정의된 편집 명령에 의존하여 유연성이 부족하였다.  
- Contribution: SAO-Instruct는 Prompt-to-Prompt, DDPM inversion, 수작업 편집을 결합한 새로운 데이터셋 구축 방식을 통해 자연어 자유편집을 가능하게 하였으며, 실제 환경 음성에도 잘 일반화된다.  

## Method  
SAO-Instruct는 Stable Audio Open 모델을 기반으로 자유 형식의 편집 지시문과 입력 음성을 받아 편집된 출력을 생성한다. 데이터셋은 LLM 기반 편집 지시문 생성과 세 가지 방식(완전 합성, 반합성, 수동편집)을 사용하여 구축하였다. 파라미터 최적화에는 베이지안 최적화가 적용되며, 학습과 추론 시 입력 음성이 추가 조건으로 활용된다.  

## Results  
SAO-Instruct는 기존 영-샷 편집 기법과 비교해 최적화된 주관 평가에서 편집 적합도 및 원본 음성과의 일관성에서 최고 성능을 보였으며, 추론 시간도 가장 빠르다.  

## Limitations  
본 연구는 생성 데이터 구축 비용과 기반 모델의 제약으로 편집 실패 사례가 존재하며, 다중 단계 편집이나 비영어 지원에는 제한이 있다.  

## Conclusion  
SAO-Instruct는 완전 자유형 자연어 지시에 따른 고품질 음성 편집을 실현하여 창의적인 오디오 작업에 새로운 가능성을 열었으며, 연구 활성화를 위해 코드와 모델을 공개하였다.

# 6. [VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a   Unified Concept Set](https://arxiv.org/abs/2510.21323)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.21323)

## Introduction
- Goal: 본 연구는 시각-언어 표현 간 정렬 메커니즘을 통합된 개념 집합으로 해석하고 향상시키는 VL-SAE 모델을 제안하는 데 목적이 있다.  
- Motivation: 기존 시각-언어 모델에서 멀티모달 표현의 의미를 통일된 개념 집합으로 해석하는 데 어려움이 존재하며, 이는 정렬 메커니즘 이해와 왜곡 문제 해결을 저해한다.  
- Contribution: VL-SAE는 거리 기반 인코더와 모달리티별 디코더를 활용하여 의미적으로 유사한 시각-언어 표현을 일관된 뉴런 활성화로 매핑하고 이를 통해 정렬 메커니즘을 해석 및 강화한다.  

## Method  
VL-SAE는 시각 및 언어 표현을 명시적으로 정렬시키기 위해 보조 오토인코더를 도입하며, 유클리드 거리 기반 인코더를 통해 의미적으로 유사한 표현들이 유사한 활성화를 가지도록 설계된다. 모달리티별 디코더는 서로 다른 분포 특성을 가진 시각과 언어 표현을 각각 재구성하여 활성화 불일치를 방지한다. 자기지도 학습 방식으로 학습되어 개념 집합을 자동으로 형성한다.  

## Results  
VL-SAE는 다양한 시각-언어 모델(CVLM, LVLM) 상에서 통합 개념 집합의 일관성과 다양성 측면에서 기존 sparse autoencoder 기반 방법들을 능가하였으며, 이를 활용해 제로샷 이미지 분류 성능 향상 및 언어 모델의 환각 현상 감소에 성공하였다.  

## Limitations  
본 연구는 보조 오토인코더 학습 및 하이퍼파라미터 설정에 의존하며, 대규모 데이터셋 필요성과 일부 구성 요소의 복잡성으로 인한 학습 비용 증가 문제가 존재한다.  

## Conclusion  
VL-SAE는 시각-언어 표현의 정렬 메커니즘을 통합 개념 집합으로 효과적으로 해석하고 강화함으로써 다중 모달 모델의 성능과 신뢰성을 높이는 새로운 방향을 제시한다.

# 7. [Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural   Processing of Figurative Language](https://arxiv.org/abs/2510.23828)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.23828)

## Introduction
- Goal: 본 연구는 대형 언어 모델(LLMs)이 지역 지식과 문화적 뉘앙스를 내포한 비유적 표현을 이해하고 실제 사용에 적용하는 능력을 평가하는 것이다.  
- Motivation: 비유적 언어는 공유된 문화적 맥락과 세계지식을 요구하므로 LLM의 문화적 이해 및 실용적 언어 사용 능력을 진단하는 중요한 대상이다.  
- Contribution: 본 연구는 아랍어 방언 및 영어의 관용구·속담에 대한 해석, 문맥적 적절성, 감성 의미 추론을 포괄하는 평가 체계를 개발하고, 이집트 아랍어 관용구의 새로운 데이터셋 Kinayat를 공개하였다.  

## Method  
본 연구는 22개 공개 및 비공개 LLM을 대상으로 아랍어 관용구, 다문화 아랍어 속담, 영어 속담을 이용하여 이해, 문맥적 사용, 감성적 함축 의미 추론 등의 다차원 평가를 수행하였다.  
Kinayat 데이터셋을 활용해 문맥 내 적절한 관용구 사용 능력을 평가하는 새로운 실용 과제를 도입하였으며, 부정, 문맥추론, 설명 생성 등의 작업을 포함하였다.  
평가는 제로샷 방식으로 진행하였으며 정확도, BERTScore, LLM-판정자 평가 방식을 통해 모델 성능을 정량화하였다.  

## Results  
평가 결과 영어 속담에 비해 아랍어 속담의 정확도가 평균 4.29% 낮았고, 이집트 방언 관용구는 아랍어 속담 대비 10.28% 더 낮은 정확도를 보였으며, 특히 문맥적 실용 과제에서는 이해 과제 대비 평균 14.07%의 성능 저하가 관찰되어 LLM이 비유적 표현의 적절한 활용에 어려움을 겪음을 확인하였다.  

## Limitations  
본 연구는 이집트 아랍어 관용구에 국한되어 있으며, 비유적 언어 전체 범위를 포괄하지 못하고 자동 평가 지표의 한계와 감성 평가의 주관성 문제를 내포한다.  

## Conclusion  
비유적 언어를 통해 LLM의 문화적 추론 능력을 진단한 결과, 모델들이 비유적 의미를 해석하는 데는 대체로 성공하나 이를 상황에 맞게 활용하는 데는 여전히 큰 제약이 있음을 입증하였다.

# 8. [PatenTEB: A Comprehensive Benchmark and Model Family for Patent Text   Embedding](https://arxiv.org/abs/2510.22264)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.22264)

## Introduction
- Goal: 본 연구는 특허 텍스트 임베딩의 특수한 문제점을 포괄적으로 평가할 수 있는 벤치마크와 이를 지원하는 모델 패밀리를 개발하는 것이다.  
- Motivation: 기존 임베딩 벤치마크는 특허 텍스트의 길이, 비대칭 매칭, 도메인 간 의미 차이 등 특허 고유의 복잡성을 충분히 반영하지 못한다.  
- Contribution: 특허 전용 15개 과제의 대규모 평가 체계인 PatenTEB와, 멀티태스크 학습 기반의 patembed 모델 패밀리를 제안하였다.  

## Method  
PatenTEB는 검색, 분류, 유의어 판별, 군집화를 아우르는 15개 과제를 포함하며, 도메인 균형 분할과 하드 네거티브 마이닝으로 데이터 누수를 방지한다.  
patembed 모델은 BERT 기반의 특허 도메인 사전학습 초기화에서 출발해 13개 훈련 태스크를 멀티태스크 학습으로 최적화하고, 다양한 모델 크기와 문맥 길이를 지원한다.  
전체 손실은 4가지 손실 함수를 활용, 다양한 태스크를 균등 가중치로 결합해 학습하였으며, 지식 증류를 통해 경량 모델도 생성하였다.  

## Results  
patembed-base 모델은 MTEB의 BigPatentClustering.v2에서 V-measure 0.494로 이전 최고 성능 0.445를 능가하는 성과를 보였고, patembed-large는 DAPFAM 벤치마크에서 NDCG@100 0.377을 기록하였다.  

## Limitations  
크로스 도메인 특허 검색에서는 기술 분야가 완전히 상이할 경우 성능이 3~6배 저하되어 어휘 차이 극복에 한계가 존재한다.  

## Conclusion  
PatenTEB와 patembed 모델 패밀리는 특허 텍스트 임베딩 평가의 공백을 메우고 다양한 현실적 분석 작업에 적용 가능한 강건한 특허 임베딩 솔루션을 제공한다.
