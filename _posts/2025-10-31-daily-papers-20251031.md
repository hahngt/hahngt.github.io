---
layout: post
title: "Daily Papers — 2025-10-31"
date: 2025-10-31 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [The Quest for Generalizable Motion Generation: Data, Model, and   Evaluation](https://arxiv.org/abs/2510.26794)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.26794)

## Introduction
- Goal: 본 논문은 비디오 생성 모델에서 얻은 지식을 통합하여 3D 인간 모션 생성의 일반화 능력을 획기적으로 개선하는 것을 목표로 한다.  
- Motivation: 기존 3D 모션 생성 모델은 표준 벤치마크에서 발전을 이루었으나, 일반화 역량에서 근본적인 한계를 보이며, 인접 분야인 비디오 생성 모델이 뛰어난 인간 행동 일반화를 보여 차용 가능성을 제시하였다.  
- Contribution: 데이터, 모델, 평가의 세 축에 걸쳐 비디오 생성 모델로부터 지식을 체계적으로 이전하며, 대규모 다중 출처 모션 데이터셋 ViMoGen-228K, 게이티드 융합 확산 트랜스포머 기반 모델 ViMoGen과 경량화된 ViMoGen-light, 그리고 9개 평가 차원으로 구성된 MBench 벤치마크를 제안하였다.  

## Method  
ViMoGen은 고품질 모션 캡처 데이터와 비디오 기반 모션 간의 상이한 강점을 융합하는 게이트 기반 이중 분기 확산 트랜스포머를 사용하며, 문장-모션 및 문장-비디오-모션 데이터를 활용하여 효율적이고 일반화된 모션 생성을 수행한다. 경량화된 ViMoGen-light는 비디오 생성 과정 의존성을 제거하고 지식 증류를 통해 추론 효율성을 높였다. 또한, ViMoGen-228K는 광범위한 의미적 다양성과 고품질 모션을 제공하는 22만여 개의 클립으로 구성되었다.  

## Results  
MBench 평가에서 ViMoGen은 운동 조건 일관성과 일반화 능력에서 모든 최신 비교 모델을 능가하며, ViMoGen-light 또한 동등한 일반화 능력을 보임과 동시에 추론 비용을 크게 낮추었다.  

## Limitations  
복잡한 동작에서 비디오 생성 모델의 불안정성과 계산 비용 증가는 여전히 일부 제한점으로 남아 있다.  

## Conclusion  
본 연구는 데이터, 모델, 평가의 삼중 혁신을 통해 3D 인간 모션 생성의 일반화 난제를 극복하며, 풍부한 의미적 다양성과 높은 품질의 모션 생성을 동시에 실현하였다.

# 2. [OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal   Document Layout Generation](https://arxiv.org/abs/2510.26213)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.26213)

## Introduction
- Goal: 본 연구는 다양한 문서 유형에 대해 범용적인 문서 레이아웃 생성을 가능하게 하는 대형 언어 모델 기반의 조악-정밀(Coarse-to-Fine) 학습 방법을 제안하는 데 목적이 있다.  
- Motivation: 기존의 문서 레이아웃 생성 연구는 학술 논문 중심의 단순한 Manhattan 스타일 구조에 치중되어 있으며, 신문, 잡지 등 복잡하고 다양한 레이아웃 데이터가 부족해 일반화에 한계가 존재하였다.  
- Contribution: 본 연구에서는 최초로 백만 규모의 다양한 문서 레이아웃 데이터셋 OmniLayout-1M을 구축하고, 이를 활용한 0.5B 규모 OmniLayout-LLM을 조악-정밀 학습으로 훈련하여, 여러 도메인에서 최신 기법을 능가하는 성능을 입증하였다.  

## Method  
문서 레이아웃을 카테고리와 위치 정보가 포함된 일련의 토큰 시퀀스로 정의하고, 조악 단계에서 다양한 문서 유형과 조악-범주 레이블로 기본 레이아웃 원리를 학습하며, 정밀 단계에서 적은 수의 정밀 레이블을 사용해 특정 도메인에 맞게 세부 조정을 수행한다.  
학습은 문서 유형, 캔버스 크기, 유효 카테고리 등의 메타 정보를 포함한 통일된 프롬프트 체계로 조건부 시퀀스 생성 문제로 모델링하여 다섯 가지 조건부 생성 태스크를 다룬다.  
이를 통해 모델은 기본적인 공간 구성 능력을 기르고, 세부적이고 복잡한 요소 범주에 대한 적응력을 높인다.  

## Results  
OmniLayout-LLM은 M6Doc 데이터셋 내 다섯 개 도메인(교과서, 신문, 잡지, 시험지, 학술문서)에서 기존 확산 모델과 최신 범용 LLM 대비 모든 주요 평가 지표(FID, 정렬도, 중첩도, mIoU)에서 우수한 성능을 보였다.  

## Limitations  
본 연구에서는 일부 복잡한 도메인의 경우 데이터 편향 문제 및 미세 조정 단계에서의 한계가 존재할 수 있다.  

## Conclusion  
OmniLayout-1M 데이터셋과 조악-정밀 학습 체계를 활용한 OmniLayout-LLM은 복잡한 문서 유형에 대해 범용적이고 세밀한 레이아웃 생성 능력을 효과적으로 향상시키는 방법임이 확인되었다.

# 3. [POWSM: A Phonetic Open Whisper-Style Speech Foundation Model](https://arxiv.org/abs/2510.24992)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.24992)

## Introduction
- Goal: 본 논문은 음성, 문자(그래피), 음소 간의 변환을 통합하여 네 가지 음성 관련 작업을 수행할 수 있는 단일 모델 POWSM을 제안하는 데 목적이 있다.  
- Motivation: 음성 인식, 음소 인식, 그래피-음소 변환(G2P), 음소-그래피 변환(P2G) 등 음소 관련 작업이 개별적으로 연구되어 통합된 다목적 음성 처리 모델 부재 문제를 해결하고자 한다.  
- Contribution: POWSM은 멀티태스킹 구조로 훈련되어 기존 음소 인식 모델을 능가하거나 동등한 성능을 보이며, 70개 이상의 언어에서 ASR, G2P, P2G까지 수행 가능한 최초의 공개 음성 기초 모델을 제공한다.  

## Method  
POWSM은 IPAPack++ 데이터셋을 활용해 음소 인식, ASR, 오디오 기준 G2P 및 P2G의 네 가지 작업 형식으로 데이터를 재구성하여 학습시켰다.  
모델 구조는 Whisper와 유사한 주의(attention)-기반 인코더-디코더 아키텍처를 채택하여 유연한 출력 시퀀스 생성을 지원한다.  
훈련 시 CTC 및 어텐션 손실을 결합했고, 350M 매개변수를 갖는 모델을 4개의 GPU에서 2일간 학습하였다.  

## Results  
POWSM은 여러 벤치마크에서 기존 최첨단 모델보다 음소 인식 정확도가 우수하며, 저자원 언어의 ASR 성능 또한 웹 규모 다국어 모델과 비슷한 수준을 달성하였다.  

## Limitations  
본 모델은 완전한 음운적·음운론적 일관성을 갖추지 못하며, 고자원 언어 편향과 연산 속도 및 음조 모델링 제한 등의 한계가 존재한다.  

## Conclusion  
POWSM은 고자원 언어뿐만 아니라 미처 학습되지 않은 언어와 사회음성학적 변이까지 효과적으로 처리하는 다목적 음성 기초 모델로, 전 세계 음성 기술 발전에 기초가 될 수 있음이 입증되었다.
