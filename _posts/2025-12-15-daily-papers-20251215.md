---
layout: post
title: "Daily Papers — 2025-12-15"
date: 2025-12-15 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder](https://arxiv.org/abs/2512.11749)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2512.11749)

## Introduction
- Goal: 본 연구는 변분 오토인코더 없이 시각 기초 모델(Visual Foundation Model, VFM) 특징 공간에서 직접 대규모 텍스트-투-이미지 잠재 디퓨전 모델을 확장하는 것이다.  
- Motivation: 기존 잠재 디퓨전 모델들은 VAE 기반으로 낮은 차원 공간에서 작동하지만, VFM 특징 공간에서 고해상도, 고품질 텍스트-이미지 합성을 위한 연구는 부족하였다.  
- Contribution: 본 논문은 SVG 프레임워크를 확장하여 SVG-T2I를 제안하고, 완전한 학습·추론 파이프라인과 사전 학습 가중치를 공개하여 VFM 표현 기반 시각 생성 연구를 촉진하였다.  

## Method
SVG-T2I는 DINOv3-ViT-S/16+ 인코더가 생성한 고차원 VFM 특징 공간에서 흐름 매칭(flow matching) 손실을 이용한 디퓨전 트랜스포머(Unified Next-DiT)를 훈련한다. 두 가지 자동인코더 구성을 제공하며, 필요시 비전 트랜스포머 기반 잔차 인코더를 사용하여 고주파 정보와 색상 보정을 수행한다. 다단계 점진적 해상도 학습 전략과 다국어 및 다양한 길이 캡션 샘플링 방식을 통해 텍스트-이미지 정렬 및 고해상도 합성 능력을 확보한다.

## Results
SVG-T2I는 GenEval 0.75 점과 DPG-Bench 85.78 점을 달성하여, SD3-Medium, FLUX.1, HiDream-I1-Full 등 기존 최첨단 VAE 기반 텍스트-이미지 확산 모델과 경쟁력 있는 성능을 나타냈다.

## Limitations
본 모델은 복잡한 인물 얼굴의 세밀한 표현, 손가락 해부학적 정확성, 텍스트 렌더링 등에서 한계가 있으며, 이는 관련 데이터 부족과 고주파 패턴 학습의 높은 계산 비용에 기인한다.

## Conclusion
SVG-T2I는 VFM 표현 공간을 유효한 잠재 공간으로 활용하여 고해상도 텍스트-이미지 합성에 성공적으로 확장하였으며, 크로스 해상도 불변성을 위한 후속 연구 필요성을 제기하였다.

# 2. [V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties](https://arxiv.org/abs/2512.11799)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2512.11799)

## Introduction
- Goal: 본 논문은 영상에서 내재 속성(반사도, 법선, 재질, 조명 등)을 정확하게 조작할 수 있는 내재 속성 인지 영상 편집 프레임워크 V-RGBX를 제안하는데 목적이 있다.  
- Motivation: 기존 대규모 영상 생성 모델들은 사실적인 영상 합성에는 강점이 있으나 내재 속성을 분리하고 시간적으로 일관성 있게 편집을 전파하는 능력이 부족하였다.  
- Contribution: V-RGBX는 영상 역렌더링과 내재 속성 조건부 사실적 영상 생성, 그리고 편집 키프레임 기반 내재 속성 편집을 통합한 최초의 종단 간 내재 속성 영상 편집 시스템을 제안한다.  

## Method  
입력 RGB 영상을 반사도, 법선, 재질, 조명 채널 등 내재 속성으로 분해하는 역렌더링 모듈과, 편집된 키프레임 내재 속성과 랜덤 샘플링한 다른 프레임 내재 속성을 교차 삽입해 시간·공간적 일관성을 유지하는 내재 속성 조건부 샘플링 모듈, 그리고 이를 조건으로 사실적인 영상을 생성해 편집 내용을 전파하는 내재 인지 영상 생성 모델로 구성된다.  

## Results  
합성 및 실제 데이터셋에서 기존 내재 속성 분해 및 편집 영상 생성 기법들을 능가하는 정확도, 시간적 일관성 및 편집 전파 성능을 입증하였다.  

## Limitations  
실내 합성 데이터 위주로 학습되어 외부 환경 등 분포가 확장된 실제 환경에 대한 일반화가 제한적이며, 한 프레임당 하나의 내재 속성만 샘플링할 수 있어 복합 편집에는 제약이 있다.  

## Conclusion  
V-RGBX는 분해, 편집, 재합성을 아우르는 내재 속성 기반 영상 편집의 새로운 기준을 제시하며, 향후 확장된 영상 길이 및 실시간 편집 지원 방향으로 발전 가능성이 크다.

# 3. [MeshSplatting: Differentiable Rendering with Opaque Meshes](https://arxiv.org/abs/2512.06818)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2512.06818)

## Introduction
- Goal: MeshSplatting은 불투명 삼각형으로 구성된 연결된 메시를 통해 미분 가능 렌더링을 수행하고, 고품질의 새로운 시점 합성을 목표로 한다.  
- Motivation: 기존 3D 가우시안 스플랫팅은 실시간 렌더링에 뛰어나지만 다각형 메시 기반 파이프라인과 호환되지 않아 게임 엔진 등에서 활용하기 어렵다.  
- Contribution: MeshSplatting은 제한된 들로네 삼각분할을 활용해 연결된 메시를 생성하고, 불투명 삼각형을 최적화하여 기존 방식 대비 2배 빠른 학습과 2배 적은 메모리 사용을 달성하였다.  

## Method  
MeshSplatting은 초기에는 독립적인 삼각형 무리를 반투명 상태로 최적화한 뒤 제한된 들로네 삼각분할을 통해 메시를 생성한다. 이후 메시 연결 및 재정제를 통해 시각 품질과 기하학적 일관성을 높이고, 최종적으로 삼각형을 불투명하도록 최적화한다. 이 과정에서 공유 정점 기반 파라미터화와 학습 스케줄링을 적용하여 게임 엔진에 직접 호환되는 메시를 얻는다.  

## Results  
Mip-NeRF360 및 Tanks & Temples 데이터셋에서 MeshSplatting은 기존 최첨단 기법 대비 PSNR과 LPIPS 지표에서 우수하며, 더 적은 정점 수로 고품질의 색상 메시를 빠르게 학습할 수 있었다.  

## Limitations  
기하학적 정확도 향상을 위한 정규화 항들은 시각적 품질을 소폭 저하시킬 수 있으며, 표현력 높은 색상 모델이 필요하다.  

## Conclusion  
MeshSplatting은 미분 가능 렌더링과 전통적인 그래픽스 파이프라인 간 간극을 해소하며 실시간 인터랙티브 3D 애플리케이션을 위해 즉시 사용 가능한 불투명 메시를 효율적으로 생성하는 통합 프레임워크이다.

# 4. [Causal Judge Evaluation: Calibrated Surrogate Metrics for LLM Systems](https://arxiv.org/abs/2512.11150)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2512.11150)

## Introduction
- 본 연구의 목표는 대규모 언어 모델(LLM) 시스템 평가에 있어 편향된 판정자 점수 문제를 보정하고 신뢰구간의 타당성을 확보하는 보정된 대리 지표 프레임워크인 Causal Judge Evaluation(CJE)를 제안하는 것이다.  
- 기존 LLM 평가 방식은 보정되지 않은 점수 사용으로 선호 역전, 신뢰구간 커버리지 부족, 중요도 가중 추정치의 실패 등 통계적으로 신뢰할 수 없는 문제점을 갖는다.  
- 본 논문은 보상 보정, 가중치 안정화, 불확실성 인식을 통합한 CJE를 개발하고, 4,961개 챗봇 아레나 프롬프트 실험에서 기존 대비 14배 저렴한 비용으로 오라클 품질과 유사한 99% 쌍별 순위 정확도를 달성했다고 기여한다.  

## Method  
CJE는 (i) 평균 보존 등방성 회귀를 이용한 보상 보정(AutoCal-R), (ii) S-단조 후보 스태킹을 통한 중요도 가중치 안정화(SIMCal-W), (iii) 보정 불확실성을 반영하는 Oracle-Uncertainty-Aware(OUA) 추론으로 구성된다.  
이 방법들은 Design-by-Projection 원칙 하에 편의 없는 효율적 추정량을 달성하며, 정책별 평균 잔차를 통한 수송성 테스트로 대리 지표의 편향 가능성을 평가한다.  
추가로, CLE(Coverage-Limited Efficiency) 진단법을 도입하여 높아진 효과적 표본 크기에도 불구하고 로그 데이터의 커버리지 한계로 인한 추정 성능 저하 문제를 설명하였다.  

## Results  
4,961개 아레나 프롬프트와 5개 LLM 정책, GPT-5 기준 오라클 라벨을 활용한 13개 추정량 비교에서, CJE는 14배 적은 오라클 라벨(약 250개)로도 94~99% 쌍별 정책 순위 정확도와 95~96% 유효 신뢰구간 커버리지를 달성하였다.  

## Limitations  
본 연구는 평균 충분성 가정 및 로그 정책 커버리지가 낮은 경우 중요도 가중 기반 추정치가 실패하는 한계를 가지며, 일부 정책에 대해 정책별 추가 보정이나 오라클 평가가 필요하다.  

## Conclusion  
CJE는 LLM 평가의 세 가지 주요 실패 문제를 해결하는 통합적이고 효율적인 보정 기반 추정 프레임워크로서, 비용 효율적이고 신뢰할 수 있는 정책 평가를 가능하게 한다.

# 5. [Scaling Behavior of Discrete Diffusion Language Models](https://arxiv.org/abs/2512.10858)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2512.10858)

## Introduction
- 본 연구의 목표는 다양한 노이즈 유형에서 이산 확산 언어 모델(Discrete Diffusion Language Models, DLMs)의 스케일링 거동을 체계적으로 분석하는 것이다.  
- 기존의 자기회귀 언어 모델(Autoregressive Language Models, ALMs)에 비해 DLMs는 다중 토큰 병렬 생성과 이전 토큰 수정 가능성 등의 장점을 가지지만, 스케일링 거동에 대한 이해가 부족하였다.  
- 본 연구는 신호대잡음비(SNR)를 활용한 혼합 확산 프로세스 정의, 하이퍼파라미터 조정, 그리고 최대 10억 파라미터 규모의 모델 스케일링을 통한 DLMs의 확장성 평가를 주된 기여로 한다.  

## Method  
본 연구는 마스킹 확산(masked diffusion)과 균일 확산(uniform diffusion) 사이를 부드럽게 보간하는 하이브리드 확산 방식을 제안하며, 이를 SNR 기반의 보편적 혼합 분포로 표현하였다.  
학습 시 배치 크기와 학습률을 중요 변수로 다루어, 고정되지 않은 하이퍼파라미터 설정 하에서 토큰 및 컴퓨트 한계 조건의 스케일링 법칙을 추정하였다.  
또한 CompleteP 파라미터화와 학습률 무감소 스케줄을 적용하여 안정적이고 효율적인 모델 확장을 실험하였다.  

## Results  
균일 확산 기반 DLMs는 마스킹 확산 대비 컴퓨트 효율적 학습에서 더 적은 데이터와 더 많은 파라미터를 필요로 하며, 10억 파라미터 모델로 확대 시 기존 자기회귀 모델과 경쟁력 있는 성능을 보였다.  

## Limitations  
데이터셋 및 토크나이저 구성에 따라 스케일링 계수가 변동되므로, 본 연구 결과는 다른 환경에서 직접 비교하기 어려울 수 있다.  

## Conclusion  
이산 확산 언어 모델은 특히 균일 확산 방식이 대규모에서 자기회귀 모델과 경쟁 가능한 효과적인 스케일링 거동을 보이며, 토큰 한계 환경에서 유망한 대안임이 입증되었다.

# 6. [Particulate: Feed-Forward 3D Object Articulation](https://arxiv.org/abs/2512.11798)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2512.11798)

## Introduction
- Goal: 본 연구에서는 단일 정적 3D 메시로부터 객체의 관절 구조를 직접 추론하는 feed-forward 방식의 모델 PARTICULATE를 제안하였다.  
- Motivation: 기존의 관절 객체 모델링 방법들은 사전 최적화나 제한된 범주의 학습에 의존하며, 실제 다양한 객체에 확장하기 어려워 학습 기반의 범용적 접근법의 필요성이 제기되었다.  
- Contribution: PARTICULATE는 변환기 기반의 네트워크를 통해 관절 부위 분할, 운동학 구조, 운동 제약 등 모든 관절 속성을 한 번의 추론으로 예측하며, AI생성 3D 자산에도 높은 일반화 성능을 보이고 새로운 평가 벤치마크를 공개하였다.  

## Method  
PARTICULATE는 입력 메시로부터 샘플링한 포인트 클라우드를 입력으로 하여 변환기 기반의 Part Articulation Transformer를 통해 관절 부위, 운동학 트리, 운동 제약 파라미터를 예측한다. 네트워크는 각 관절 부위에 대응하는 쿼리 벡터와 포인트 특징을 주고받는 주의(attention) 블록으로 구성되며, 다중 디코더 헤드가 관절 속성을 생성한다. 학습은 공개된 다양한 관절 3D 자산 데이터셋을 활용하여 지도학습으로 이루어지며, 추론 시에는 포인트 예측을 메시로 투사해 완전한 관절 3D 모델을 빠르게 생성한다.  

## Results  
PARTICULATE는 PartNet-Mobility 테스트셋과 새로 제안된 Lightwheel 벤치마크에서 기존 최첨단 기법들에 비해 관절 부위 분할과 운동 예측 정확도에서 현저한 성능 향상을 달성하였다.  

## Limitations  
현재 연구에서는 최대 16개 부위로 제한된 객체만 처리하며, 더 복잡한 관절 구조나 대규모 부위 수에 대한 대응은 추가 연구가 필요하다.  

## Conclusion  
PARTICULATE는 단일 정적 3D 메시에서 관절 구조 전체를 신속하고 정확하게 복원하는 end-to-end feed-forward 모델로, AI 생성 3D 자산에도 강인한 일반화 능력을 가진다.
