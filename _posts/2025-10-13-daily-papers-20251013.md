---
layout: post
title: "Daily Papers — 2025-10-13"
date: 2025-10-13 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion   Sampling](https://arxiv.org/abs/2510.04533)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.04533)

## Introduction
- 본 논문은 확산 모델의 표상 오류(hallucination)를 줄이기 위한 새로운 추론 시간 안내 기법인 Tangential Amplifying Guidance(TAG)를 제안하는 것을 목표로 한다.  
- 확산 모델은 뛰어난 이미지 생성 성능에도 불구하고 의미적 불일치와 오류가 발생하는 문제가 있으며, 기존 안내 방법들은 외부 신호나 모델 구조 변형에 의존해 계산 비용이 증가하는 한계가 존재한다.  
- 이에 본 연구는 확산 모델을 변경하지 않고 경로상의 점들을 기하학적으로 분석하여 본질적으로 의미 구조를 담고 있는 접선 성분을 증폭시키는 효율적이며 직접적인 안내 방식을 개발하였다.  

## Method  
TAG는 확산 샘플링 과정에서 현재 상태의 단위 벡터를 기준으로 업데이트 벡터를 법선 방향과 접선 방향으로 분해하고, 접선 방향 성분만을 증폭해 샘플링 경로가 데이터의 확률 분포 내 고밀도 영역에 머무르도록 유도한다.  
이 과정은 튜드리 공식과 1차 테일러 전개를 이용해 정형화되었으며, 법선 성분의 변화는 최소화하면서 접선 성분 증폭으로 의미적 구조가 강화된 샘플을 생성한다.  
TAG는 기존의 조건부 및 무조건부 확산 모델 샘플러에 플러그 앤 플레이 방식으로 적용 가능하며 별도의 추가 평가나 재학습이 필요하지 않다.  

## Results  
평가 결과 TAG는 ImageNet과 MS-COCO 데이터셋에서 FID 및 IS, CLIPScore 등 품질 지표를 기반으로 기존 안내 기법 대비 시각적 품질을 일관되게 높였으며, 동일하거나 더 적은 함수 평가 횟수로도 성능 향상을 달성하였다.  

## Limitations  
적절한 접선 성분 증폭 비율(η) 선택이 매우 중요하며, 과도한 증폭은 샘플 품질 저하와 스케줄러의 반지름 보정 왜곡을 초래하였다.  

## Conclusion  
TAG는 확산 모델 샘플링에서 의미적 왜곡을 줄이고 샘플 품질을 크게 향상시키는 실용적이고 모델 아키텍처 비종속적인 안내 방법임을 보였다.

# 2. [KORMo: Korean Open Reasoning Model for Everyone](https://arxiv.org/abs/2510.09426)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.09426)

## Introduction
- Goal: 본 연구는 합성 데이터를 주로 활용하여 비영어권 언어인 한국어에 대해 완전 개방형 이중언어 대규모 언어 모델(KORMo-10B)을 구축하는 첫 대규모 연구를 수행하는 데 목적이 있다.  
- Motivation: 기존 공개형 대규모 언어 모델 연구는 주로 영어에 집중되어 있어 저자원 언어 환경에서 재현 가능하고 투명한 완전 개방형 모델 개발의 필요성이 대두되었다.  
- Contribution: 한국어-영어 병렬 코퍼스에 68.74% 합성 데이터를 포함시켜 안정적인 훈련과 동등한 성능을 보이는 10.8억 파라미터 모델을 완전 공개하고 관련 데이터, 코드, 학습 로그를 배포하였다.  

## Method  
합성 데이터 비율과 언어 혼합 비율에 따른 토크나이저 설계, 정규화 방법, 어텐션 마스킹, 다중 토큰 예측 기법 등을 단계적으로 실험하며 합성 데이터가 훈련 안정성에 미치는 영향을 분석하였다.  
1B 규모의 프록시 모델로 합성 데이터 전용 학습이 성능 저하 없이 가능함을 확인하고, 최종적으로 한글-영어 병렬 데이터를 활용한 10.8B 모델을 학습하였다.  
학습 커리큘럼은 사전학습부터 슈퍼바이즈드 파인튜닝 및 선호 학습까지 포괄하며 다양한 스타일과 주제를 반영한 합성 데이터를 결합하였다.  

## Results  
합성 데이터 기반 KORMo-10B 모델은 상용 다국어 공개 모델과 비등한 추론 능력과 지식, 명령 수행 능력을 보였으며, 합성 데이터가 훈련 안정성이나 성능 저하를 야기하지 않음을 체계적으로 입증하였다.  

## Limitations  
1B 프록시 모델 수준에서 실험을 진행함에 따라 10B 이상 대규모 모델에서 발생할 수 있는 잠재적 안정성 문제나 구조적 한계에 대해 추가 검증이 요구된다.  

## Conclusion  
본 연구는 비영어 저자원 환경에서 합성 데이터 중심 완전 개방형 다국어 LLM 개발을 가능하게 하는 투명한 학습 체계와 실험 결과를 최초로 제시하였으며, 관련 자원 모두 공개함으로써 후속 연구의 재현성과 접근성을 크게 향상시켰다.

# 3. [ARES: Multimodal Adaptive Reasoning via Difficulty-Aware Token-Level   Entropy Shaping](https://arxiv.org/abs/2510.08457)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.08457)

## Introduction
- Goal: 본 논문의 목표는 멀티모달 대형 추론 모델(MLRMs)의 문제 난이도에 따라 동적으로 탐색 노력을 조절하는 적응적 추론 프레임워크 ARES를 제안하는 것이다.  
- Motivation: 기존 MLRMs는 쉬운 문제에서 과도한 추론을 하여 불필요한 계산 비용이 발생하고 어려운 문제에서 탐색이 부족해 문제 해결에 실패하는 한계가 존재하였다.  
- Contribution: 본 연구는 창의적 토큰 수준 엔트로피 기반 난이도 인식 전략과 이에 기초한 두 단계의 훈련 파이프라인을 통해 효율성과 정확도를 동시에 향상시키는 방법론을 제안하였다.

## Method  
ARES는 첫째, 난이도에 따라 추론 길이를 조절하는 적응형 콜드스타트 단계에서 텍스트 및 멀티모달 데이터를 활용해 모델에 초기 난이도 인식을 습득시킨다.  
둘째, Adaptive Entropy Policy Optimization(AEPO)를 도입하여 높은 윈도우 엔트로피 토큰을 탐색 트리거로 활용하고, 난이도에 따라 탐색 깊이를 조절하는 계층적 보상과 동적 KL 컨트롤을 적용한다.  
이로써 쉬운 문제에서는 불필요한 추론을 줄이고 어려운 문제에서는 깊은 탐색을 촉진하여 효율적이고 정확한 추론을 가능하게 한다.

## Results  
ARES는 수학, 논리 및 멀티모달 벤치마크에서 기존 최첨단 공개 소스 및 상용 모델 대비 높은 정확도와 추론 효율성을 동시에 달성하였다.

## Limitations  
정보 부족

## Conclusion  
ARES는 토큰 수준 엔트로피 기반 난이도 인식을 통해 동적 추론 노력을 조절함으로써 멀티모달 대형 추론 모델의 성능과 효율성을 크게 향상시켰다.

# 4. [ReviewerToo: Should AI Join The Program Committee? A Look At The Future   of Peer Review](https://arxiv.org/abs/2510.08867)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.08867)

## Introduction
- Goal: 본 논문은 AI를 활용한 동료 평가 시스템의 가능성과 한계를 분석하고, AI 심사위원이 학술 심사 과정에 어떻게 통합될 수 있는지 연구하는 것을 목표로 한다.  
- Motivation: 기존 동료 평가는 평가자 주관성, 일관성 부족, 그리고 확장성 한계 문제로 어려움을 겪고 있으며, 대규모 학술대회에서 심사 부담이 급증하고 있다.  
- Contribution: 본 연구에서는 ReviewerToo라는 모듈형 AI 보조 동료 평가 프레임워크를 제안하고, 다양한 심사자 페르소나를 활용한 대규모 ICLR 2025 데이터셋 실험을 통해 AI 심사자의 성능과 한계, 그리고 심사 통합 가이드라인을 제시하였다.  

## Method  
ReviewerToo는 논문 입력부터 문헌 조사, 복수의 AI 심사자 그룹에 의한 평가, 저자 반박문 작성, 메타 리뷰어에 의한 최종 종합 평가까지의 단일-회차 워크플로우로 구성된다.  
서로 다른 심사 철학을 시뮬레이션하는 다수의 심사자 페르소나를 도입하여 심사 결정 및 편향을 분석하며, 공식 학회 가이드라인과 문헌 요약에 기반한 근거 평가를 수행한다.  
이를 바탕으로 다수 의견 합의, 편향 완화, 그리고 심사 품질 향상을 위해 메타 리뷰어를 통한 앙상블 및 검증 기법을 적용한다.  

## Results  
ICLR-2025 1,963편 논문 데이터셋으로 평가한 결과, ReviewerToo의 AI 심사자들은 평균 인간 심사자 대비 약 81.8%의 논문 수락·거절 분류 정확도를 기록하였으며, 메타 리뷰어 앙상블 시 83.9%인 인간 평균과 근접하는 성능을 보였다.  

## Limitations  
AI 심사자는 세밀한 등급 구분(예: 구두 발표 vs 강연)과 반박문 평가 단계에서 자기편향적 경향을 보이며, 인간 전문가의 미묘한 판단을 완전히 대체하지 못하였다.  

## Conclusion  
본 연구는 AI 심사자가 인간 심사자를 보완하는 하이브리드 동료 평가 체계 구성을 위한 체계적 근거와 실용적 가이드라인을 제공하며, AI의 일관성·공정성 증진 기여와 인간 전문가의 심층 평가 유지 필요성을 동시에 강조한다.

# 5. [Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive   Text-to-image Generation](https://arxiv.org/abs/2510.08994)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.08994)

## Introduction
- Goal: 본 논문은 자율회귀 방식의 텍스트-이미지 생성 모델의 추론 속도를 가속화하는 기법을 제안하는 데 목적이 있다.  
- Motivation: 기존 자율회귀 모델은 순차적 토큰 디코딩 과정으로 인해 수천 회의 모델 순전파가 필요하여 추론 속도가 매우 느리다.  
- Contribution: 본 연구는 노이즈가 추가된 토큰 임베딩을 입력받아 다음 깨끗한 토큰을 예측하는 방식으로 잡오비(Jacobi) 반복과 디노이징 과정을 통합한 Speculative Jacobi-Denoising Decoding (SJD2) 프레임워크를 제안하였다.  

## Method  
SJD2는 잡오비 반복 내에서 디노이징 과정을 포함하여 병렬적으로 다중 토큰을 동시에 생성하는 전략이다. 사전 학습된 자율회귀 모델을 노이즈가 포함된 임베딩에 적응시키기 위해 낮은 비용의 파인튜닝을 수행하며, 추론 시에는 가우시안 노이즈로 초기화된 토큰 시퀀스를 점진적으로 정제한다. 확률적 기준을 통해 다수의 토큰을 병렬로 검증하고, 미검증 토큰은 디노이징 궤적에 따라 반복적으로 정제한다.  

## Results  
실험 결과 Lumina-mGPT와 Emu3 모델에서 각각 4배 이상, 5배 이상 순전파 횟수를 줄여 2배 이상의 실질적인 지연 시간 단축과 함께 생성 이미지의 시각적 품질을 유지하는 성과를 보였다.  

## Limitations  
본 방법은 병렬 디코딩을 위한 추가 메모리 사용량이 증가하여 GPU 메모리 부담이 커지는 단점이 존재한다.  

## Conclusion  
SJD2는 자율회귀 텍스트-이미지 생성에서 디노이징 과정을 잡오비 디코딩에 성공적으로 융합하여 추론 속도를 대폭 개선하면서도 결과 이미지 품질을 유지하는 새로운 알고리즘임을 증명하였다.

# 6. [ARMOR: High-Performance Semi-Structured Pruning via Adaptive Matrix   Factorization](https://arxiv.org/abs/2510.05528)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.05528)

## Introduction
- Goal: 본 연구는 LLM의 하드웨어 가속을 가능하게 하는 2:4 반구조적 가지치기에서 발생하는 성능 저하 문제를 해결하는 새로운 후처리 가지치기 알고리즘 ARMOR를 제안하는 것이다.  
- Motivation: 기존 2:4 가지치기 기법은 이론적 연산 속도 향상에도 불구하고 모델 정확도가 크게 떨어지는 문제를 내포하고 있다.  
- Contribution: ARMOR는 가중치 행렬을 2:4 희소 핵심과 저오버헤드 블록 대각 행렬로 분해하는 기법을 개발하였으며, 이 기법은 이론적 수렴 보장과 뛰어난 성능 유지 능력을 갖는다.  

## Method
ARMOR는 각 계층의 가중치 행렬을 2:4 희소 마스크가 적용된 핵심 행렬과 이를 감싸는 두 개의 블록 대각 행렬로 분해한다. 분해된 행렬을 최적화하기 위해 블록 좌표 하강법 기반의 최적화 알고리즘을 제안하며, 이 과정에서 NoWag 근사 손실 함수를 최소화한다. 이 방법은 기존 2:4 가지치기 대비 더 유연하게 모델 품질을 보존하며, 하드웨어 가속 요구 조건을 만족한다.  

## Results
Qwen 및 Llama 모델군을 대상으로 한 벤치마크 평가에서 ARMOR는 모든 다운스트림 작업과 퍼플렉서티 평가에서 기존 2:4 가지치기 방법을 일관되게 뛰어넘는 성능을 보였다.  

## Limitations
ARMOR는 블록 크기와 최적화 반복 수 등 하이퍼파라미터 조정이 필요하며, 이러한 설정에 따른 성능 편차 가능성이 존재한다.  

## Conclusion
ARMOR는 하드웨어 지원 2:4 희소성의 연산 효율성과 모델 정확도 사이에서 균형을 효과적으로 달성하는 새로운 반구조적 가지치기 접근법임을 증명하였다.

# 7. [ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual   Recall](https://arxiv.org/abs/2510.07896)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.07896)

## Introduction
- Goal: 본 연구의 목표는 다중 홉 다중 사실 추론에서 발생하는 지식 편집 문제를 신경망 수준의 활성화 메커니즘을 기반으로 효과적으로 해결하는 것이다.  
- Motivation: 기존 지식 편집 기법들은 다중 홉 추론 시 중간에 존재하는 암묵적 주제를 포함한 추론 체인에서의 편집 실패와 성능 저하 문제가 존재하였다.  
- Contribution: 신경원 수준의 쿼리-값 경로 활성화 메커니즘 분석을 통해 쿼리 및 값 뉴런을 조작하는 ACE(Attribution-Controlled Knowledge Editing) 프레임워크를 제안하여 다중 홉 사실 추론 편집 정확도를 크게 향상시켰다.  

## Method  
ACE는 다중 홉 추론에서 중간 암묵적 주제가 쿼리 뉴런으로 기능하며, 이들이 연쇄적으로 값 뉴런을 활성화하는 특성을 활용하여 중요한 쿼리 및 값 뉴런을 신경원 수준에서 식별하고 편집한다.  
이 과정에서 쿼리 뉴런은 중간 단계 정보를 조정하며, 값 뉴런은 최종 답변 정보를 누적하는 역할을 하므로 이들을 동시에 편집함으로써 정확하고 일관된 지식 갱신이 가능하다.  
기존의 locate-then-edit 접근법을 확장하여, ACE는 신경 수준 개입을 통해 다중 홉 체인에서 지식 편집 실패 문제를 극복한다.  

## Results  
ACE는 GPT-J와 Qwen3-8B 모델에서 각각 기존 최첨단 방법 대비 다중 홉 정확도를 9.44%와 37.46% 향상시키며 우수한 성능을 입증하였다.  

## Limitations  
제안 방법은 쿼리 및 값 뉴런의 활성화 위치가 도메인에 따라 동적으로 변하는 점 등에서 특정 모델 구조 및 도메인 일반화에 한계가 있을 수 있다.  

## Conclusion  
본 연구는 다중 홉 사실 추론에서 쿼리-값 뉴런 활성화 메커니즘을 밝히고, 이를 근거로 한 ACE 프레임워크로 효과적인 신경망 수준의 지식 편집을 구현함으로써 다중 홉 지식 편집 연구에 새로운 방향을 제시하였다.
