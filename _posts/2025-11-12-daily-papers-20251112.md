---
layout: post
title: "Daily Papers — 2025-11-12"
date: 2025-11-12 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [Adaptive Multi-Agent Response Refinement in Conversational Systems](https://arxiv.org/abs/2511.08319)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.08319)

## Introduction
- Goal: 본 연구의 목표는 맞춤형 대화 시스템에서 응답의 정확성, 개인화, 일관성을 다중 에이전트 협업을 통해 적응적으로 개선하는 방법을 제안하는 것이다.  
- Motivation: 기존 대화 시스템에서 대형 언어 모델(LLM)은 개인화하거나 특정 지식을 반영하는 데 한계가 있어, 사용자가 직접 오류를 지적하고 재요청하는 방식은 비현실적이므로 응답을 사전적으로 정제할 필요가 있다.  
- Contribution: 본 논문에서는 사실성, 개인화, 일관성 각각을 담당하는 전문화된 다중 에이전트를 도입하고, 각 쿼리별로 최적의 에이전트 조합과 순서를 동적으로 선택하는 계획자 에이전트를 포함한 MARA 프레임워크를 제안하였다.  

## Method  
제안하는 MARA는 초기 LLM 응답에 대해 사실(factuality), 개인화(personalization), 일관성(coherence)을 전담하는 세 개의 전문 에이전트가 협업하여 순차적으로 정제하는 다중 에이전트 구조이다.  
계획자 에이전트는 쿼리별 요구사항에 따라 동적으로 필요한 에이전트 집합과 실행 순서를 결정하며, 각 정제 에이전트는 계획자의 설명을 참고하여 역할에 맞게 응답을 개선한다.  
이 과정은 동시적 혹은 고정 순서와 달리 쿼리마다 최적화된 순차적 커뮤니케이션 전략을 적용하여 응답 품질을 극대화한다.  

## Results  
MARA는 PersonaChat, INSCIT, FoCus 등 사용자 개인 정보 반영과 사실성 요구가 모두 포함된 대표 대화 데이터셋에서 기존 단일 및 다중 에이전트 기법들 대비 전 영역에서 유의미하게 우수한 성능을 보였다.  

## Limitations  
현재 계획자 에이전트는 비지도 학습 방식으로 구현되어 최적의 에이전트 조합 탐색에서 이상적인 계획자 대비 성능 차이가 존재한다는 한계가 있다.  

## Conclusion  
맞춤형 대화에서 개인화, 사실성, 일관성 등 다양한 품질 측면을 전문 에이전트들이 협력하여 적응적으로 정제하는 MARA 프레임워크는 기존 연구 대비 응답 품질을 크게 향상시키는 효과적인 접근법임을 입증하였다.

# 2. [Beyond English: Toward Inclusive and Scalable Multilingual Machine Translation with LLMs](https://arxiv.org/abs/2511.07003)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.07003)

## Introduction
- Goal: 본 연구는 대규모 언어 모델을 활용하여 중국어와 영어를 중심으로 60개 언어, 234개 번역 방향을 포함하는 포괄적이고 확장 가능한 다국어 기계 번역 시스템을 개발하는 데 목적이 있다.  
- Motivation: 기존의 다국어 기계 번역 시스템은 영어 중심 편향과 언어별 품질 불균등, 그리고 다국어 훈련 데이터의 방향성 문제 등 여러 한계를 지니고 있어 이를 극복할 필요가 있다.  
- Contribution: 본 논문에서는 다국어 대규모 기계 번역 모델인 LMT를 제안하며, 방향별 성능 저하 문제를 완화하는 전략적 다운샘플링과 교차언어 전이를 강화하는 병렬 다국어 프롬프팅 기법을 도입하였다.  

## Method  
LMT는 지속 사전 학습(Continued Pre-training)과 지도 미세 조정(Supervised Fine-tuning)이라는 2단계 적응 과정을 통해 구축되었으며, 다언어 및 다자료원 데이터를 엄격하게 수집, 구성하였다.  
지도 미세 조정 과정에서는 양방향 대칭 데이터의 과도한 역방향(다수→영어/중국어) 중복으로 인한 방향성 악화를 발견하고, 이를 완화하기 위해 전략적 다운샘플링 기법을 적용하였다.  
또한, 병렬 다국어 프롬프팅(Parallel Multilingual Prompting)을 통해 유사 언어 또는 영어를 보조 언어로 활용하여 번역 품질과 교차 언어 전이 성능을 향상시켰다.  

## Results  
제안한 LMT-60-4B 모델은 언어 수 60개 내외 모델 중에서 Aya-101-13B, NLLB-54B 등 훨씬 큰 모델들을 뛰어넘는 SOTA 성능을 달성하였다.  

## Limitations  
평가가 주로 학술 벤치마크와 COMET 지표에 국한되어 있으며, 실제 현장 환경 및 문화적 적합성 평가로 확장이 필요하다.  

## Conclusion  
LMT는 영어 중심 편향을 극복하고 다국어 포괄성과 일관된 번역 품질을 실현한 중국어-영어 중심의 대규모 다국어 기계 번역 모델로서, 향후 다국어 번역 연구를 위한 강력한 기준점을 제공한다.
