---
layout: post
title: "Daily Papers — 2025-10-21"
date: 2025-10-21 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented   Generation](https://arxiv.org/abs/2510.17354)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.17354)

## Introduction
- 본 연구의 목표는 쿼리와 문서가 혼합 모달리티(텍스트와 이미지)를 포함하는 현실 세계의 환경에서 보편적 검색 증강 생성(URAG)을 위한 통합 혼합 모달 검색기를 개발하는 것이다.  
- 기존의 검색 증강 생성(RAG) 시스템은 주로 단일 텍스트 모달리티에 집중하여 복잡한 혼합 모달리티 문서와 쿼리에 효과적으로 대응하지 못한다는 점에서 연구의 필요성이 대두되었다.  
- 본 논문은 Nyx라는 혼합 모달-대-혼합 모달 검색기와 웹 기반 자동 데이터 생성 파이프라인을 제안하여 현실적인 URAG 시나리오에 맞춘 고품질 다중 모달 질문응답 데이터셋 NyxQA를 구축하였다.  

## Method  
- NyxQA는 웹에서 수집한 혼합 모달 문서를 세분화하고, 비전-언어 모델(VLM)을 이용해 질문응답 쌍을 자동 생성 및 필터링하는 4단계 파이프라인을 통해 구축되었다.  
- Nyx는 Qwen-2.5-VL-3B-Instruct 기반으로 사전 학습과 VLM 피드백을 활용한 감독 미세 조정의 2단계 훈련 프로세스를 거쳐 개발되었으며, Matryoshka Representation Learning(MRL)을 적용해 임베딩의 표현력과 효율성을 균형 있게 확보하였다.  
- 학습 시 contrastive learning 손실함수를 활용하여 쿼리와 문서 간 의미적 유사성을 학습하고, 혼합 모달 입력을 통합 임베딩 공간에 효과적으로 매핑하도록 설계되었다.  

## Results  
- Nyx는 텍스트 단일 모달 및 혼합 모달 RAG 벤치마크에서 기존 최첨단 모델 대비 우수한 검색 정확도와 시각-언어 생성 성능을 보였으며, NyxQA에서는 81.83%의 정확도를 달성해 mmE5 대비 유의미한 성능 개선을 이루었다.  

## Limitations  
- 제안된 방법은 대규모 혼합 모달 학습 데이터 확보와 VLM 피드백 기반 미세 조정에 의존하므로, 데이터 품질과 피드백 체계의 한계가 최종 검색기의 성능에 영향을 미칠 수 있다.  

## Conclusion  
- 본 연구는 현실 세계 웹 문서의 복잡한 혼합 모달리티를 효과적으로 처리하는 보편적 검색 증강 생성 시스템 구현에 기여하며 혼합 모달 검색 분야의 새로운 기준을 제시하였다.

# 2. [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM   Ensembling](https://arxiv.org/abs/2510.15346)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.15346)

## Introduction
- Goal: 본 논문은 대형 언어 모델(LLM)의 다음 토큰 확률 분포를 활용하는 앙상블 기법에서 언제 토큰 단위로 앙상블을 수행할지 결정하는 방안을 제시하는 데 목적이 있다.  
- Motivation: 기존의 모든 토큰에서 앙상블을 수행하는 방식은 긴 문장 생성 시 성능 저하와 비효율성을 초래하는 문제점이 발견되었기 때문이다.  
- Contribution: 토크나이저 불일치와 모델 간 합의 정도를 고려하여 선택적으로 앙상블 지점을 결정하는 SAFE(Stable And Fast LLM Ensembling) 프레임워크와 확률 샤프닝 기법을 제안하였다.  

## Method  
SAFE는 주요 모델인 드래프터가 미리 토큰 시퀀스를 생성하고, 검증자 모델들이 이를 평가하여 안정성과 필요성이 확인된 토큰 위치에서만 앙상블을 수행한다.  
토크나이저 간 미스매치로 발생하는 OOV-like 토큰을 방지하고, 모델 간 충분한 합의가 있을 때는 앙상블을 생략하여 효율성을 확보한다.  
또한, 확률 분포가 지나치게 평탄할 경우 확률 샤프닝을 통해 같은 단어에 분산된 확률을 집중시켜 정확도를 높인다.  

## Results  
MATH500, BBH 등 다양한 벤치마크에서 SAFE는 기존 최첨단 앙상블 기법 대비 CoT(reasoning) 환경에서 평균 5.72% 이상의 정확도 향상과 최대 99% 미만의 토큰 앙상블 비율로 효율적 결과를 보여주었다.  

## Limitations  
SAFE는 주로 토크나이저 간 이질성이 큰 다중 모델 조합에 적합하며, 유사한 토크나이저를 지닌 모델 조합에 대해서는 상대적으로 성능 향상 폭이 제한적이다.  

## Conclusion  
본 연구는 토큰 단위로 언제 앙상블할지 결정하는 SAFE 기법을 통해 안정성과 속도 모두 개선된 LLM 앙상블을 구현하여 실제 응용에서의 활용 가능성을 높였다.

# 3. [Annotation-Efficient Universal Honesty Alignment](https://arxiv.org/abs/2510.17509)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.17509)

## Introduction
- Goal: 대형 언어 모델(LLM)이 자신의 지식 경계를 인식하고 신뢰도 높은 확신을 표현하는 정직성 정렬 능력을 달성하는 것이다.  
- Motivation: 기존의 정직성 정렬 방법은 주석 비용이 매우 높아 보편적인 정직성 정렬을 위한 효율적인 주석 활용이 요구된다.  
- Contribution: 저자는 저비용 자기일관성 신호를 통해 내재적 확신을 유도하고, 소량의 정답 주석으로 이를 보정하는 EliCal 프레임워크와 10개 QA 데이터셋을 포함한 대규모 HonestyBench 벤치마크를 제안하였다.

## Method  
EliCal은 두 단계로 구성되며, 첫 단계에서는 자기일관성 기반 신호로 모델이 내부 확신을 표현하도록 학습한다. 두 번째 단계에서는 소량의 정답 주석을 활용해 모델의 확신과 실제 정확도를 정밀 보정한다. 모델 파라미터는 고정하고 LoRA 모듈과 선형 헤드를 도입하여 효율적으로 확신을 예측한다.

## Results  
EliCal은 전체 주석 데이터의 약 0.18%에 해당하는 1,000개의 정답 주석만으로도 최적에 근접한 정직성 정렬을 달성하였고, 미지의 MMLU 과제에서는 보정 전용 방식 대비 우수한 일반화 성능을 보였다.  

## Limitations  
자기일관성 신호에 의존하는 과정에서 다중 샘플링이 요구되어 계산 비용이 상대적으로 증가할 수 있다.

## Conclusion  
EliCal과 HonestyBench는 최소 주석으로도 대규모 범용 정직성 정렬을 가능케 하여 실제 AI 배포에서의 신뢰성 향상에 기여한다.

# 4. [ConsistEdit: Highly Consistent and Precise Training-free Visual Editing](https://arxiv.org/abs/2510.17803)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.17803)

## Introduction
- Goal: 본 연구는 Multi-Modal Diffusion Transformer (MM-DiT) 아키텍처 기반에서 훈련 없이 텍스트 지시를 활용한 시각적 편집을 일관되고 정밀하게 수행하는 방법을 제안하는 것이다.  
- Motivation: 기존의 텍스트 기반 편집 기법들은 편집 강도와 원본 일관성 유지라는 두 가지 요구를 동시에 만족하지 못하고, 특히 다중 라운드 및 영상 편집에서 시각적 오류가 누적되는 문제점이 존재하였다.  
- Contribution: MM-DiT의 주의 메커니즘에서 도출한 세 가지 핵심 통찰에 기반하여, 비전 토큰만 제어하는 새로운 주의 통제 기법 ConsistEdit을 개발하여 고성능의 구조 일관성과 세밀한 편집 제어가 가능함을 보였다.  

## Method  
ConsistEdit는 MM-DiT의 모든 층과 단계에서 비전 부분에만 주의 통제를 적용하며, 편집 영역과 비편집 영역에 대해 사전 주의 마스크 융합과 쿼리, 키, 값 토큰 별 차별화된 조작을 수행한다. 이를 통해 편집 영역 내 구조적 일관성을 보장하면서도 텍스트 기반의 외관 변화를 정밀하게 제어한다. 또한, 편집 강도를 조절할 수 있어 구조적 일관성과 변형의 정도를 미세 조정할 수 있다.

## Results  
일련의 실험에서 ConsistEdit는 구조 변경이 필요한 편집 및 비구조 일관 편집 모두에서 기존 최신 기법 대비 원본 구조 유지 및 편집 정확성 측면에서 우수한 성능을 달성하였으며, 이미지와 영상 편집 모두에 효과적으로 적용됨을 입증하였다.

## Limitations  
현재 논문에서는 구체적인 계산 비용이나 실시간 편집 적용 가능성에 대한 제한점 및 상세 논의는 제공되지 않았다.

## Conclusion  
ConsistEdit는 MM-DiT 기반 생성 모델의 편집 잠재력을 극대화하는 최초의 전 층 단계 훈련 없는 주의 제어 방식으로, 고품질의 반복적 다중 영역 편집과 세밀한 일관성 조절을 가능하게 하는 획기적인 발전이다.

# 5. [Chronos-2: From Univariate to Universal Forecasting](https://arxiv.org/abs/2510.15821)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.15821)

## Introduction
- Goal: Chronos-2는 단변량, 다변량 및 공변량 예측을 제로샷 방식으로 수행할 수 있는 범용 시계열 예측 모델을 제안하는 것이다.  
- Motivation: 기존의 사전학습 시계열 모델은 주로 단변량 데이터에만 초점을 맞춰 실제 환경에서 중요한 다변량 및 공변량 정보를 효과적으로 활용하지 못한다는 한계가 존재하였다.  
- Contribution: Chronos-2는 그룹 어텐션 메커니즘과 합성 데이터 기반의 사전학습을 통해 다양한 다변량 구조와 공변량 의존성을 학습하며, 이를 통해 여러 벤치마크에서 최첨단 성능을 달성하였다.  

## Method  
Chronos-2는 시계열 내 시간 축 주의(attention)와 시계열 간의 그룹 주의를 교차 적용하는 인코더-기반 트랜스포머 구조이다.  
그룹 어텐션은 서로 관련 있는 시계열 대상, 공변량, 다변량 변수를 하나의 그룹으로 묶어 정보를 효과적으로 공유케 하여 맥락 내 학습능력을 향상한다.   
합성 시계열 데이터를 활용하여 다양한 다변량 의존성과 공변량 구조를 인위적으로 생성, 사전학습에 활용하여 모델의 일반화력을 끌어올렸다.  

## Results  
Chronos-2는 fev-bench, GIFT-Eval, Chronos Benchmark II 등 세 가지 주요 벤치마크에서 기존 최고 사전학습 모델 대비 평균 승률 80% 이상과 높은 스킬 점수를 기록하며, 특히 공변량이 포함된 작업에서 큰 폭의 성능 개선을 보였다.  

## Limitations  
다양한 실제 데이터 분포에 완전히 일치하는 고품질 다변량 및 공변량 시계열 데이터 확보가 어려워 주로 합성 데이터를 활용한 점이 제한 사항이다.  

## Conclusion  
Chronos-2는 그룹 어텐션과 합성 데이터 사전학습을 통한 제로샷 범용 시계열 예측 모델로서, 실무 예측 파이프라인에 즉시 활용 가능한 강력한 기반 모델임을 입증하였다.

# 6. [Constantly Improving Image Models Need Constantly Improving Benchmarks](https://arxiv.org/abs/2510.15021)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.15021)

## Introduction
- Goal: 본 연구의 목표는 최신 이미지 생성 모델의 실제 사용 사례를 반영하는 동적인 벤치마크를 개발하는 것이다.  
- Motivation: 기존 벤치마크들은 빠르게 발전하는 이미지 모델의 새로운 기능과 사용자 경험을 적시에 반영하지 못하는 한계가 존재한다.  
- Contribution: 이에 따라 본 논문은 소셜 미디어 사용자 피드백을 수집·분석하여 실시간으로 벤치마크를 구성하는 ECHO 프레임워크를 제안하였다.  

## Method  
ECHO는 대상 모델과 관련된 소셜 미디어 게시물을 대량 수집하고, LLM을 이용해 영상 생성 프롬프트와 커뮤니티 피드백을 필터링 및 구조화한다.  
이후 멀티모달 처리 기법을 통해 프롬프트와 입출력 이미지 관계를 복원하며 완전한 샘플을 구축한다.  
이 과정은 소셜 미디어의 다양한 게시물 형식과 분산된 문맥을 통합해 실제 사용자의 생생한 평가를 벤치마크에 반영한다.  

## Results  
ECHO로 생성된 31,000개 이상의 사용자 프롬프트 데이터셋은 기존 벤치마크 대비 더 창의적이고 복합적인 과제를 포함하며, 최신 모델 간 성능 차이를 명확히 구분하였다.  

## Limitations  
자동 평가 지표와 인간 평가 간 상관관계가 제한적이며, 더 정교한 판정 모델 개발 연구가 필요한 상황이다.  

## Conclusion  
ECHO는 모델과 사용자 요구 변화에 능동적으로 대응하는 벤치마크 설계의 새로운 방향을 제시하며, 실용적이고 신뢰도 높은 이미지 생성 평가 체계를 가능하게 한다.

# 7. [Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset](https://arxiv.org/abs/2510.16258)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.16258)

## Introduction  
- Goal: 본 연구는 인간의 다양한 3D 움직임과 행동을 포괄적으로 다룰 수 있는 대규모 멀티모달 모션 데이터셋을 구축하는 것이다.  
- Motivation: 기존 2D 및 3D 모션 데이터셋은 크기, 품질, 다양성, 완성도 면에서 상호 보완적인 한계가 존재하여 인간 모션 및 행동 연구에 병목 현상을 초래하였다.  
- Contribution: Embody 3D는 439명의 참가자로부터 500인시(person-hours) 이상의 고품질 3D 모션 데이터를 수집하였으며, 전신 및 손 추적, 체형, 음성, 텍스트 주석 등 다양한 모달리티를 포함하는 최초의 종합적인 대규모 3D 인간 모션 데이터셋이다.  

## Method  
본 데이터셋은 다중 카메라 시스템(80대 고해상도 카메라)과 640채널 마이크로폰 어레이를 사용하여 3D 모션과 음성을 동기화하여 수집하였다.  
참가자별 신체형상 추정과 다중 인물 동작 추정에는 선행된 보정 및 딥러닝 기반 키포인트 탐지, 삼각측량 및 포즈 인코더 기법을 적용하였다.  
또한, 음성 분리에는 빔포밍 알고리즘을 개발하여 각 참가자의 음성을 분리하였으며, 엄격한 수작업 품질 검수를 통해 오차를 최소화하였다.  

## Results  
Embody 3D는 500인시 54백만 프레임 이상의 3D 움직임과, 단일 인물에서 다인물 대화, 협력 활동, 공존 시나리오 등 다양한 행동 유형을 모두 포함하는 데이터를 제공한다.  

## Limitations  
정보 부족으로 인해 구체적인 한계점에 대한 서술은 불가능하다.  

## Conclusion  
Embody 3D는 기존 3D 인간 모션 데이터셋의 품질과 규모, 모달리티 통합 문제를 극복하며 인간 움직임과 행동 연구 및 가상 인간 생성 분야 발전에 중요한 자원을 제공한다.

# 8. [On Non-interactive Evaluation of Animal Communication Translators](https://arxiv.org/abs/2510.15768)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2510.15768)

## Introduction
- Goal: 본 논문은 동물 의사소통 번역기의 정확성을 상호작용 없이 검증하는 방법을 제안하는 데 목적이 있다.  
- Motivation: 동물 번역기의 검증 시 동물과의 직접 상호작용이나 관찰이 필수라는 기존 통념에 도전하며, 안전성 및 윤리적 문제를 줄이기 위한 대안을 모색하고자 하였다.  
- Contribution: 복잡한 언어일수록 영어 출력만으로 평가가 가능하다는 이론적·실험적 증거를 제시하고, 이를 위해 세그먼트 단위 변환과 셔플 테스트(ShufflEval)를 활용한 비상호작용 평가 방법을 개발하였다.  

## Method  
입력된 동물 의사소통을 화자의 발화 단위로 세분화하여 각 세그먼트를 영어로 번역하고, 번역 결과가 원래 순서대로 이어질 때보다 무작위 순서로 배치될 경우 일관성이 낮아지는지를 판별하는 셔플 테스트 방식을 적용하였다. 이 평가 방법은 참조 번역문 없이 기계 번역 품질을 가늠하는 레퍼런스 프리 품질 평가(RFQE)의 일종이며, GPT-5 등 최신 언어 모델을 평가자 및 번역기로 활용하였다.  

## Results  
저자들은 저자원이거나 인위적으로 생성된 언어 집합을 대상으로 셔플 테스트 기반 평가가 기존의 참조 번역 기반 평가와 높은 상관관계를 보임을 발견하여, 본 방법의 유효성을 입증하였다.  

## Limitations  
셔플 테스트는 발화 단위별 세분화와 개별 번역이 가능해야 하며, 단순하거나 의미 독립적인 세그먼트가 있는 경우 완벽한 번역자에게도 낮은 평가를 줄 수 있다는 한계가 존재한다.  

## Conclusion  
본 연구는 동물 의사소통 번역기 평가에서 물리적 상호작용 없이도 신뢰할 수 있는 검증이 가능함을 이론 및 실험으로 증명하며, 향후 더 적은 윤리적 부담과 비용으로 동물 번역 연구가 진전될 수 있는 길을 제시하였다.
