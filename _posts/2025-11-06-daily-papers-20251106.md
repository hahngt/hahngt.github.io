---
layout: post
title: "Daily Papers — 2025-11-06"
date: 2025-11-06 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal   Interactions](https://arxiv.org/abs/2511.03334)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.03334)

## Introduction
- Goal: 본 논문은 오디오와 비디오를 통합하여 고품질의 동시 생성이 가능한 UniAVGen 프레임워크를 제안하는데 목적이 있다.  
- Motivation: 기존 공개 오픈소스 오디오-비디오 생성 방법들은 크로스 모달 모델링의 한계로 인해 입술 동기화 및 의미적 일관성에서 성능 저하가 발생하였다.  
- Contribution: UniAVGen은 대칭적 이중 확산 트랜스포머 구조와 비대칭적 크로스 모달 상호작용, 얼굴 인식 조절 모듈 및 모달리티 인식 무분류 안내를 도입하여 효율적인 통합 생성과 다양한 관련 작업 지원을 실현하였다.  

## Method  
UniAVGen은 음성과 영상 각각에 대해 대칭적인 두 갈래 확산 트랜스포머를 사용하며, 비대칭적 크로스 모달 상호작용 메커니즘으로 시간적 정렬된 쌍방향 주의를 수행한다. 얼굴 인식 조절 모듈은 상호작용에서 중요한 얼굴 영역을 동적으로 강조하고, 모달리티 인식 무분류 안내는 추론 시 크로스 모달 상관 신호를 증폭하여 생성 품질을 향상시킨다. 또한 다양한 조건 입력을 조합하여 공동 생성, 더빙, 오디오 기반 비디오 생성 등 다중 작업에 대응 가능하다.  

## Results  
약 130만 개의 훈련 샘플로 기존 3070만 개 대비 훨씬 적은 데이터로도 음성-영상 동기화, 음색 및 감정의 일관성에서 기존 최첨단 모델들을 능가하는 성능을 입증하였다.  

## Limitations  
제안 방식의 한계점에 대한 구체적인 논의는 본문에 명확히 제시되어 있지 않아 정보 부족하다.  

## Conclusion  
본 연구에서는 비대칭적 크로스 모달 상호작용과 얼굴 인식 조절을 결합한 UniAVGen을 통해 효과적이며 확장성 있는 통합 오디오-비디오 생성 체계를 구축하여 실용적인 멀티모달 생성의 새로운 기준을 제시하였다.

# 2. [Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist   Annotation Scheme for MapTask](https://arxiv.org/abs/2511.03718)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.03718)

## Introduction
- Goal: 본 연구는 비대칭적 대화 상황에서 화자와 청자의 관점 차이를 반영하여 참조 표현의 이해 상태를 정밀하게 주석하는 스킴을 제안하는 것이다.  
- Motivation: 협력적 대화에서 공통 기반(common ground)을 구축하는 과정에서 명시적 일치가 이루어진 듯 보이더라도, 정보 접근의 비대칭성으로 인해 서로 다른 대상에 대해 언급하는 오해가 발생할 수 있기 때문이다.  
- Contribution: 화자와 청자의 개인적 해석을 구분하는 5단계 속성 기반 주석 스킴과 통합 된 랜드마크 ID 체계를 제시하며, 대규모 대화 말뭉치에 GPT-5로 주석을 달아 약 1.3만 건 참조 표현의 신뢰도 높은 데이터셋을 구축하였다.  

## Method  
비대칭 지도를 사용하는 HCRC MapTask 대화 코퍼스를 대상으로, 화자의 의도 및 청자의 해석을 별도 랜드마크 ID로 표기하고 5개 이진 속성(양화성, 명시성, 수용성, 접지, 상상성) 위계적 판단 절차에 따라 주석을 수행하였다.  
멀티턴 대화 맥락을 포함한 대규모 주석을 위해 스킴 제약 조건을 갖춘 JSON 스키마 기반 프롬프트를 활용한 GPT-5 LLM 주석 파이프라인을 개발하였다.  
주석 품질 평가는 전문 인간 주석자와 비교를 통해 95.5% 이상의 정확도와 99.5% 미세-조화평균(F1)을 달성하여 신뢰도를 검증하였다.  

## Results  
전체 참조 표현 중 오해(misunderstanding)는 약 1.8%로 드물었으며, 특히 복수성(multiplicity) 불일치에서 오해 발생률이 전체 평균보다 6배 이상 높아 실질적 오해 유발 요인임을 밝혀냈다.  

## Limitations  
주석 신뢰도는 높으나 다양한 주석자 간의 일관성 검증과 세밀한 공간 추론, 비언어적 신호를 포함하지 못한 점은 한계로 남는다.  

## Conclusion  
본 연구는 협력 대화에서 화자와 청자의 관점을 모두 반영하는 정교한 참조 표현 주석 스킴과 대규모 데이터셋을 제공함으로써, 향후 (비전)대형언어모델의 관점 의존적 접지 능력 평가 및 협력적 대화 이해 연구에 중요한 분석 도구를 마련하였다.
