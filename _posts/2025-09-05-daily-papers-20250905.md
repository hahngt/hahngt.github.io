---
layout: post
title: Daily Papers — 2025-09-05"
date: 2025-09-05 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth](https://arxiv.org/abs/2509.03867)

## Introduction  
- Goal: 본 연구는 ‘Drivelology’라 명명한 문법적으로는 일관되나 의미적으로는 다층적, 모순적, 또는 감정적으로 내포된 언어 현상을 탐구하며 대형 언어 모델(LLM)의 해석 능력을 평가하는 것이다.  
- Motivation: 기존 LLM은 자연어 처리 다수 작업에서는 우수한 성능을 보이나, 다층적 의미와 심층 해석이 요구되는 언어 현상에 대한 진정한 이해 능력은 불명확하기 때문이다.  
- Contribution: 고유하고 다국어를 포함한 1,200여 개 예시로 구성된 DRIVELHUB 벤치마크 데이터셋을 구축하고, 다중 태스크 평가지표로 다양한 LLM의 Drivelology 이해도를 체계적으로 분석하였다.  

## Method  
Drivelology 텍스트 수집에는 다국적 소셜미디어에서 선별한 다층적, 역설적, 언어유희적 표현이 포함되며, 엄격한 전문가 다중 검토 과정을 거쳐 주석을 완성하였다.  
평가를 위해 Drivelology 판별, 다중 레이블 태깅, 암시적 서사 생성, 그리고 다항 선택 문제를 설계하여 언어 모델의 인지적 깊이를 다각도로 점검하였다.  
여러 상용 및 오픈소스 LLM에 대해 0샷 설정으로 다국어 및 다양한 난이도에서 성능을 시험하였다.  

## Results  
Deepseek-v3 모델이 다수 평가지표에서 최고 성적을 기록했으며, 고난이도 서사 선택 문제에서는 모델 크기에 따라 성능이 현저히 향상되는 스케일링 효과가 관찰되었다.  

## Limitations  
DRIVELHUB 데이터셋은 만다린어 샘플이 절반에 달하여 언어별 불균형 문제와 제한된 컴퓨팅 자원으로 인해 대규모 모델 평가에 제약이 존재한다.  

## Conclusion  
본 연구는 LLM이 표면적 언어 유창성을 넘어서 깊이 있는 사회적·문화적 의미를 이해하는 데 한계가 있음을 입증하며, Drivelology 같은 복합적 언어 현상을 통한 심층적 언어 모델 개발의 필요성을 제기한다.

# 2. [From Editor to Dense Geometry Estimator](https://arxiv.org/abs/2509.04338)

## Introduction
- Goal: 본 논문은 이미지 편집 모델을 기반으로 한 단안 밀집 기하 예측 모델 FE2E를 제안하는 것을 목표로 한다.  
- Motivation: 기존 텍스트-이미지 생성 모델은 밀집 기하 예측에 적합하지 않으며, 이미지 편집 모델이 더 안정적이고 효과적인 기하학적 구조 표현 능력을 지님을 발견하였다.  
- Contribution: 편집 모델을 밀집 기하 추정기로 전환하기 위한 새로운 일관 속도 학습 목표, 로그 양자화 기법, 비용 부담 없는 깊이와 법선의 공동 추정 전략을 제안하였다.  

## Method  
FE2E는 Step1X-Edit 편집 모델을 Diffusion Transformer(DiT) 구조 위에 재구성하고, 기존 흐름 매칭 손실을 일관 속도(flow matching with consistent velocity) 손실로 재설계하였다. 또한, BFloat16 정밀도 문제를 로그 양자화를 통해 해결하며, 단일 순전파에서 깊이와 법선을 동시에 추정하도록 DiT의 전역 주의를 활용하였다.  

## Results  
FE2E는 제한된 7만여 개 학습 데이터만 사용하면서도 ETH3D, KITTI 등 다수 벤치마크에서 기존 최첨단 모델 대비 최대 35% 이상의 절대 상대 오차(AbsRel) 개선을 달성하였다.  

## Limitations  
정보 부족.  

## Conclusion  
편집 모델의 내재된 구조적 특성을 활용하여 FE2E는 학습 데이터 규모를 확장하지 않고도 단안 밀집 기하 예측에서 우수한 성능과 효율성을 동시에 확보하였다.

# 3. [Towards a Unified View of Large Language Model Post-Training](https://arxiv.org/abs/2509.04419)

## Introduction
- Goal: 본 연구는 대형 언어 모델의 후속 학습 과정에서 강화학습과 지도 미세조정 기법을 통합하는 통합 정책 그래디언트 추정기를 제시하는 데 목적이 있다.  
- Motivation: 기존 강화학습과 지도 미세조정이 서로 대립되는 것이 아니라 단일 최적화 과정의 다양한 형태임을 이론적으로 규명하고, 이를 바탕으로 효율적인 하이브리드 후속 학습 알고리즘을 개발할 필요가 있었다.  
- Contribution: 통합 정책 그래디언트 추정기(UPGE)를 도출하고, 이를 기반으로 실시간 성능에 따라 동적으로 학습 신호를 선택하는 하이브리드 후속 학습(HPT)을 제안하였다.  

## Method  
본 연구는 온라인 롤아웃 데이터와 오프라인 데모 데이터를 단일 목표 함수 하에서 통합하며, 네 가지 구성요소(안정화 마스크, 참조 정책, 이점 추정, 가능도 그래디언트)로 통합 정책 그래디언트를 분석하였다.  
이론적 분석에 따라 HPT 알고리즘은 모델 성능에 따라 RL과 SFT 손실의 가중치를 스위칭하는 동적 혼합 손실을 사용한다.  
이를 통해 모델의 탐색과 활용 능력을 균형 있게 개선하면서 안정적인 학습을 달성하였다.  

## Results  
HPT는 6개 수학 추론 벤치마크와 2개 분포 외 테스트에서 Qwen과 LLaMA 모델군 전반에 걸쳐 기존 SFT, GRPO, LUFFY 등 강력한 베이스라인을 일관되게 능가하였다.  

## Limitations  
실험은 일부 모델과 벤치마크에 한정되었으며, 다른 유형의 작업 및 더 광범위한 데이터셋에 대한 일반화 가능성에 대한 검증은 부족하였다.  

## Conclusion  
본 연구는 대형 언어 모델 후속 학습을 위한 이론적 통합 관점과 성능 기반 동적 하이브리드 학습 방법을 제안함으로써 일관된 성능 향상과 안정적인 학습 과정을 입증하였다.

# 4. [DeepResearch Arena: The First Exam of LLMs' Research Abilities via   Seminar-Grounded Tasks](https://arxiv.org/abs/2509.01396)

## Introduction  
- Goal: 대규모 언어 모델(LLM)의 심층 연구 능력을 학술 세미나 기반의 실제 연구 환경에서 평가하기 위한 벤치마크인 DeepResearch Arena를 제안하는 것이다.  
- Motivation: 기존의 연구 능력 평가 방법은 정적 데이터나 전문가 수작업에 의존하여 확장성과 연구 현실성에서 한계를 보이며, 진정한 연구 문제의 동적 생성 과정을 반영하지 못한다는 문제점이 있다.  
- Contribution: 12개 학문 분야, 200개 이상의 학술 세미나에서 1만여 개 이상의 고품질 연구 과제를 자동 생성하는 다중 에이전트 계층적 작업 생성(MAHTG) 시스템과, 사실 근거 평가 및 개방형 추론 평가를 결합한 하이브리드 평가 프레임워크를 개발하였다.  

## Method  
MAHTG 시스템은 세미나 녹취록에서 연구 가치가 높은 영감을 추출하고 이를 명확하고 실행 가능한 연구 과제로 변환한다.  
추출된 영감은 한계, 방법론, 학제간 연구, 가설 네 가지 유형으로 분류되며, 연구 합성, 설계, 평가라는 세 가지 핵심 연구 단계에 맞추어 구조화된다.  
평가에는 사실 기반 평가인 Keypoint-Aligned Evaluation(KAE)과 개방형 결과를 평가하는 Adaptively-generated Checklist Evaluation(ACE)를 병행하여 심층 연구 능력을 다각도로 측정한다.  

## Results  
DeepResearch Arena 벤치마크 평가에서 GPT-4 mini-deepresearch와 Gemini-2.5-flash 모델이 높은 평가점수를 기록하며, 모델 간 연구 역량과 과제 유형별 수행 능력에 현저한 차이가 확인되었다.  

## Limitations  
본 벤치마크는 세미나 기반이기에 오디오 인식 오류 및 일부 연구 분야의 대표성 한계가 존재하며, 실제 연구 맥락의 모든 복잡성을 완벽히 포착하지는 못한다.  

## Conclusion  
DeepResearch Arena는 실제 연구 토론의 맥락을 반영하여 LLM 기반 연구 에이전트의 심층 연구 능력을 체계적이고 신뢰성 있게 평가할 수 있는 이론적 및 실용적 기반을 제공한다.

# 5. [Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow   Real Instructions?](https://arxiv.org/abs/2509.04292)

## Introduction
- 본 연구의 목표는 대형 언어 모델(LLM)이 학습 중에 형성된 고정된 훈련 규칙을 벗어나 실제 역설적 지시(inverse instructions)를 효과적으로 수행할 수 있는 능력인 '역인지 능력(Counter-intuitive Ability)'을 평가하는 것이다.  
- 기존 LLM은 지도학습 단계에서 습득한 표준화된 패턴에 의존하여 비전형적이거나 역설적인 명령에 취약한 인지 관성(cognitive inertia)을 보이는 문제점이 존재한다.  
- 본 연구는 이러한 한계를 극복하기 위해 8가지 유형의 역설적 지시를 포함하는 Inverse IFEval 벤치마크를 제안하고, 이를 통한 다국어·다분야 1012개 고품질 문항 데이터셋과 자동 평가 프레임워크를 구축하였다.  

## Method  
역설적 지시 8가지 유형(예: 질문 수정, 의도적 텍스트 결함, 주석 없는 코드 등)을 체계적으로 설계하여 SFT 데이터의 이상적 패러다임을 역전시켰다.  
인간-기계 협력 파이프라인을 통해 도메인별 전문가가 시드 문항을 제작하고, LLM을 이용한 대규모 생성과 자동 필터링, 엄격한 인간 검증 과정을 거쳐 데이터셋을 완성하였다.  
평가에는 적응형 LLM-심판(LLM-as-a-Judge) 방식을 도입하여 전문가 검증 기반 정확도 98%의 자동 점수 산출을 수행하였다.  

## Results  
실험 결과 최상위 LLM들이 전통적 명령 수행에는 우수하나 역인지 능력 평가에서는 성능에 큰 편차가 나타났으며, 사고 메커니즘(Thinking mechanism) 활성화가 성능 향상에 중요한 역할을 함을 확인하였다.  

## Limitations  
본 연구에서 제시하는 역설적 지시들은 실용적 의미보다는 LLM의 일반화·적응력 평가를 위한 인위적 테스트셋임을 명시하였다.  

## Conclusion  
Inverse IFEval 벤치마크는 LLM의 인지 관성 문제와 과적합 경향을 밝혀내고, 앞으로 현실의 예기치 않은 지시를 수행할 수 있는 모델 적응력 향상을 위한 기초를 제공한다.

# 6. [Transition Models: Rethinking the Generative Learning Objective](https://arxiv.org/abs/2509.04394)

## Introduction
- 본 논문의 목표는 생성 모델의 학습 목표를 재고하여 임의의 시간 간격 ∆t에 대한 상태 전이를 정확히 정의하는 새로운 생성 패러다임을 제안하는 것이다.  
- 동기 부여는 기존 확산 모델이 높은 품질을 구현하지만 많은 계산 비용을 요구하고, 소수 단계 모델은 효율적이나 품질 한계에 부딪히는 근본적인 상충관계에 기인한다.  
- 본 연구의 주요 기여는 임의 단계(state-to-state) 전이를 학습하는 Transition Models(TiM)를 제안하여 적은 파라미터 수로도 다단계와 소단계 모두에서 현존 최고 성능을 달성하고, 샘플링 단계가 증가할수록 품질이 지속적으로 향상됨을 증명한 것이다.  

## Method  
Transition Models(TiM)은 확산 경로 상의 두 임의 시점 상태 간 전이 동역학을 수식으로 엄밀히 규명하고, 이를 학습 목표로 설정하였다. TiM은 기존 PF-ODE 기반 국소 미분 방정식 근사와 고정 엔드포인트 맵 학습의 한계를 극복하여 경로 일관성과 시간-기울기 매칭 조건을 만족하는 모델을 구현하였다. 효율적 학습을 위해 자동미분 비호환 문제를 해결한 차분 근사법(DDE)과 인터벌 인지 셀프어텐션, 분리된 시간 및 간격 임베딩을 도입하였다.  

## Results  
865M 파라미터 규모의 TiM은 GenEval, MJHQ30K, DPGBench 등 다수 벤치마크에서 최첨단의 성능을 보이며, 1단계부터 128단계까지 단계별 추가 샘플링이 품질 향상으로 이어지는 점을 보여 기존 수십억 파라미터 모델들을 능가하였다.  

## Limitations  
TiM은 고해상도에서 일부 아티팩트 발생 및 텍스트, 손 등 세밀한 디테일 표현이 제한적이며, 콘텐츠 안전성과 제어 가능성 문제는 여전히 해결해야 할 과제로 남아있다.  

## Conclusion  
본 연구는 임의 단계 상태 전이를 학습하는 Transition Models를 통해 효율성과 품질의 근본적 상충을 해소하고, 고성능·다단계 세밀 보정이 가능한 차세대 생성 모델 학습 지평을 제시하였다.

# 7. [Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding](https://arxiv.org/abs/2508.20478)

## Introduction
- Goal: 본 논문은 긴 동영상에서 발생하는 다중 이벤트와 장기간 시공간 의존성을 효과적으로 이해하기 위한 강화된 다중 회차 추론 프레임워크인 Video-MTR을 제안하는 데 목적이 있다.  
- Motivation: 기존 방법들은 단일 회차의 정적 추론이나 외부 시각-언어 모델 의존으로 인해 복잡성과 최적화 제약을 겪으며, 긴 동영상 내 핵심 정보 손실 문제를 해결하지 못한다는 문제점이 존재한다.  
- Contribution: Video-MTR은 다중 회차에 걸친 반복적 핵심 영상 분할 선택과 질문 이해를 통해 점진적으로 문맥을 반영하는 추론을 수행하며, 새로운 게이트드 이중 보상 체계로 중간 단계의 선택과 최종 답변 정확도를 통합적으로 최적화하고 외부 모델 없이 종단 간 학습을 가능하게 한다.  

## Method  
Video-MTR은 MLLM(Qwen2.5-VL-7B)을 기반으로 강화학습을 적용하여 다중 회차 내 핵심 프레임을 점진적으로 선택하고 질문에 대한 이해를 향상시키는 의사결정 정책을 학습한다.  
이를 위해 답변 정확도를 평가하는 궤적 수준 보상과 프레임-질문 연관성에 중점을 둔 회차 수준 보상을 결합한 게이트드 이중 보상 메커니즘을 도입하여 중간 행동에 대한 세밀한 피드백을 제공한다.  
또한, 제한적 QA 데이터와 시간적 영상 주석 데이터를 정제하여 활용하고, 탐색 보너스 전략으로 다중 회차 탐색 행동을 촉진한다.  

## Results  
Video-MTR은 VideoMME, MLVU, EgoSchema와 같은 대표적 긴 동영상 벤치마크에서 기존 최첨단 모델 대비 적은 프레임 수임에도 불구하고 경쟁력 있는 정확도(MLVU 48.4%, VideoMME 롱샛 51.0%, EgoSchema 62.4%)를 기록하며 탁월한 일반화 능력과 효율성을 입증하였다.  

## Limitations  
정보 부족  

## Conclusion  
Video-MTR은 최초로 종단 간 강화학습과 명시적 다중 회차 추론을 결합해 긴 동영상 이해에서 뛰어난 성능과 확장성을 보여주었으며, 추후 더욱 긴 영상과 복잡한 추론 과제에의 확장이 기대된다.

# 8. [NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware   Embeddings](https://arxiv.org/abs/2509.04011)

## Introduction
- Goal: 본 연구의 목표는 사전 정의된 유형 없이 사용자 정의 타입 설명을 활용해 명명된 개체를 제로샷으로 효과적으로 검색하는 NER Retriever 프레임워크를 제안하는 것이다.  
- Motivation: 기존 NER 시스템은 고정된 엔티티 유형과 대량의 라벨 데이터에 의존하여 실제 다양한 도메인과 상황에 적용하기 어렵다는 문제점이 존재한다.  
- Contribution: 대형 언어 모델(LLM)의 중간계층 값 벡터를 활용해 유형 인식 임베딩을 생성하고, 경량 대비 대조 학습 기반 투영기를 도입해 세밀한 개체 유형 구별과 무스키마 기반 엔티티 검색을 가능하게 하였다.  

## Method  
엔티티 멘션과 유형 설명을 동일 의미 공간에 임베딩하는 방식이며, LLaMA 3.1 8B 모델의 17번째 변환기 블록의 self-attention 값 벡터를 기반으로 중간 표현을 추출한다.  
추출된 고차원 표현은 대조 학습을 통해 학습된 2층 MLP 투영망을 거쳐 저차원 유형 인식 임베딩으로 변환되어 효율적 근접 이웃 탐색에 활용된다.  
키워드 기반 기존 방법과 문장 수준 밀집 임베딩 대비 NER Retriever는 개별 개체 임베딩 중심 설계로 정밀도와 확장성을 확보하였다.  

## Results  
Three개의 벤치마크(Few-NERD, MultiCoNER 2, NERetrieve)에서 NER Retriever는 대부분의 경우 BM25, E5-Mistral, NV-Embed v2 대비 최대 4배 이상의 R-Precision 성능 향상을 보였다.  

## Limitations  
LLM에 내재된 모수형 지식에 의존하므로 법률, 의료, 금융 등 특수 도메인에서는 제로샷 성능 저하가 나타날 수 있다는 한계가 존재한다.  

## Conclusion  
본 연구는 LLM 중간 계층 표현과 대조 학습 투영을 통한 유형 인식 개체 임베딩으로 제로샷 적응형 명명된 개체 검색을 실현하여, 다양한 미지의 개체 유형에 대해 확장 가능하고 정확한 검색을 가능하게 하였다.

# 9. [Few-step Flow for 3D Generation via Marginal-Data Transport Distillation](https://arxiv.org/abs/2509.04406)

## Introduction
- 본 연구의 목표는 사전학습된 3D 플로우 모델을 기반으로 하는 소수 단계 3D 생성 플로우 증류(few-step 3D flow distillation) 프레임워크인 MDT-dist를 제안하는 것이다.  
- 기존 2D 확산 모델 가속화 기술은 발전하였으나 복잡한 3D 생성 작업에 적용된 사례가 부족하며, 3D 생성은 고차원 및 희소한 구조 특성상 더 어려운 문제임을 동기로 삼았다.  
- 논문에서는 마지널 데이터 운송(Marginal-Data Transport)을 학습하는 새로운 목적함수를 제안하고, 이를 해결하기 위해 속도장 일치(Velocity Matching)와 속도 증류(Velocity Distillation)라는 두 가지 최적화 목표를 도입하였다.  

## Method  
MDT-dist는 마지널 확률 분포에서 데이터 분포로의 직접 운송을 학습하는 주요 목적함수를 기반으로 하며, 직접적인 적분이 불가능한 문제를 속도장과 분포 수준으로 변환하여 해결한다.  
속도장 일치는 학생 모델과 교사 모델 간 속도장을 안정적으로 매칭하도록 학습하나 편향된 그래디언트 문제를 가진 반면, 속도 증류는 확률 밀도 추정을 통해 간접적인 분포 정합을 수행하여 학습을 보완한다.  
두 손실 함수를 결합하여 학습하며, TRELLIS 3D 생성 모델의 플로우 변환기 샘플링 단계를 대폭 감소시키면서도 고품질 생성을 유지한다.  

## Results  
본 방법은 TRELLIS 모델에서 플로우 변환기의 샘플링 단계를 기존 25단계에서 1~2단계로 축소하여 GPU A800 기준 최대 9배 이상 가속화하면서도 시각적 및 기하학적 품질을 유지하여 기존 CM 및 FlashVDM 대비 우수한 성능을 보였다.  

## Limitations  
본 연구 방법은 다량의 조건 이미지와 고품질 3D 기하학 데이터에 의존하며, 3D 기하 데이터 수집 비용과 희소성으로 인해 증류 학습 비용이 높다는 한계가 존재한다.  

## Conclusion  
본 연구는 마지널 데이터 운송 학습을 통해 3D 플로우 기반 생성 모델의 소수 단계 가속화를 효과적으로 달성하는 MDT-dist 프레임워크를 제시하여, 기존 일관성 모델 대비 뛰어난 품질과 속도를 동시에 확보하였다.

# 10. [Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers](https://arxiv.org/abs/2509.03059)

## Introduction
- Goal: 본 연구의 목적은 다양한 추론 집약 분야에서 검증 가능한 보상을 통해 대규모 연쇄 사고 과정을 합성할 수 있는 오픈소스 프레임워크 Loong을 제안하는 것이다.  
- Motivation: 기존의 수학과 프로그래밍 분야에서 강화학습과 검증 가능한 보상을 통한 모델 성능 향상은 성공적이었으나, 고품질 검증 데이터셋 부족과 인간 감독 비용 문제로 인해 타 분야 확장은 어려웠다.  
- Contribution: Loong 프로젝트는 12개 도메인의 8,729개 검증된 시드 데이터를 포함한 LOONGBENCH와 다양한 자동화 전략을 활용한 합성 데이터 생성 환경 LOONGENV를 개발하였다.  

## Method  
Loong은 LOONGBENCH 시드 데이터를 기반으로 LOONGENV를 통해 자연어 질문과 코드 생성으로 구성된 문제-답-코드 3중쌍을 자동 합성한다.  
코드 실행 결과와 LLM의 연쇄 사고(Chain-of-Thought, CoT) 기반 해답을 상호 검증하여 정답 여부를 판단하고, 이를 강화학습의 보상 신호로 활용하는 에이전트-환경 루프를 구축하였다.  
여러 합성 전략인 Few-shot, Self-instruct, Evol-instruct를 도입해 문제 다변화 및 난이도 조정을 시도하였다.  

## Results  
LOONGBENCH를 이용한 벤치마크에서 추론 최적화 모델(o3-mini, DeepSeek-r1 등)이 대부분 분야에서 우수한 성능을 보였으며, LOONGENV의 합성 데이터는 실행 가능성과 의미적 정합성 측면에서 다양한 생성 전략 간 품질 차이를 확인하였다.  

## Limitations  
다양한 도메인에서 충분한 합성 데이터 확보는 가능하지만 Evol-instruct 방식에서 실행 불가 코드 증가와 의미 불일치 문제 등 생성 신뢰도 향상 필요성이 남아있다.  

## Conclusion  
Loong 프레임워크는 대규모 연쇄 사고 합성 및 자동 검증을 통해 다중 도메인에서 추론 능력 향상을 위한 실용적인 데이터 생성 및 평가 체계를 제공한다.

# 11. [Durian: Dual Reference-guided Portrait Animation with Attribute Transfer](https://arxiv.org/abs/2509.04434)

## Introduction
- 본 연구의 목표는 얼굴 속성(reference image) 정보를 활용하여 단일 초상 사진으로부터 속성 변환이 가능한 고품질 2D 초상 애니메이션 비디오를 제로샷 방식으로 생성하는 방법을 제안하는 것이다.  
- 기존의 정적 이미지 편집 도구들이 현실감과 표현력에 한계가 있고, 동적 얼굴 속성 변환 및 일관된 영상 애니메이션 생성이 어려워 이를 해결할 필요가 존재한다.  
- 본 논문에서는 듀얼 레퍼런스 네트워크와 속성-초상 마스크 확장 및 증강 전략을 결합한 자기재구성 학습 방식을 통해 다양한 얼굴 속성을 통합하여 애니메이션까지 생성하는 최초의 프레임워크를 제시한다.  

## Method  
Durian은 속성 이미지와 초상 이미지를 마스킹하여 각각 Attribute ReferenceNet과 Portrait ReferenceNet에 입력하고, 두 네트워크에서 추출한 다중 해상도 공간 특징을 공간 및 교차 주의(attention) 메커니즘으로 통합하여 확산모델의 디노이징 과정에 주입한다.  
이를 통해 동일 아이덴티티 내 두 프레임의 자기재구성 훈련을 수행하며, 마스크 확장과 공간-외형 변형 증강을 적용하여 포즈 및 정렬 변화에 강건한 속성 변환을 학습한다.  
추가로 3D 아바타 기반 정렬된 속성 마스크를 추론 시 활용하여 공간적 불일치를 완화하고, 다중 속성 조합 및 속성 간 보간도 단일 생성 과정에서 지원한다.  

## Results  
CelebV-Text, VFHQ 등 실제 영상 데이터를 활용한 평가에서 Durian은 다양한 정량 지표(L1, PSNR, SSIM, LPIPS, FID) 기준으로 기존 두 단계 기반 속성 전이 및 애니메이션 결합 방법들을 모두 능가하였다.  

## Limitations  
복잡한 속성의 공간적 상호작용 처리, 조명 차이에 따른 품질 저하, 극단적 아구먼트 전이, 키포인트 추출 실패에 따른 시간적 진동 등 일부 한계점이 존재한다.  

## Conclusion  
Durian은 명시적 삼중 데이터 없이 제로샷으로 얼굴 속성을 다중 조합 및 보간하며 자연스러운 포즈 변화가 반영된 고품질 초상 애니메이션을 생성하는 혁신적 확산 기반 프레임워크임을 입증하였다.

# 12. [Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from   Vector Drawings](https://arxiv.org/abs/2508.18733)

## Introduction
- Goal: 본 연구의 목표는 2D 벡터 엔지니어링 도면으로부터 파라메트릭 CAD 모델을 자동으로 생성하는 프레임워크를 제안하는 것이다.  
- Motivation: 기존 CAD 생성 연구들은 점군, 메시, 텍스트 등에서 3D 모델을 생성하지만, 산업 디자인의 2D 공학 도면 시작 단계와 부합하지 않는 한계가 존재한다.  
- Contribution: 본 논문은 CAD 생성 문제를 시퀀스-투-시퀀스 학습 문제로 재정의하고, SVG 벡터 도면 기반의 정밀한 기하학 정보를 보존하는 새로운 학습 구조와 대규모 대응 데이터셋 CAD-VGDrawing을 제안한다.  

## Method  
벡터 도면을 위한 네트워크 친화적 표현 방식을 설계하고, 명령어 유형과 파라미터 생성을 분리하는 듀얼 디코더 트랜스포머 구조를 도입하였다. 명령 가이드를 통한 파라미터 생성 방식과 부드러운 대상 분포 손실함수를 통해 파라미터 허용 범위를 확장하였다. 또한 FreeCAD 스크립트로 생성한 공학 도면과 CAD 모델 쌍으로 구성된 CAD-VGDrawing 데이터셋을 구축하였다.  

## Results  
벡터 도면 입력은 래스터 이미지 대비 명령어 정확도, 파라미터 정확도, 생성 CAD 모델의 유효성 측면에서 일관되게 우수한 성능을 보였으며, 제안한 Drawing2CAD는 기존 벡터 기반 모델 대비 모든 평가 지표에서 향상된 결과를 나타냈다.  

## Limitations  
복잡 모델 처리 시 FreeCAD의 도면 생성 한계로 일부 데이터셋 필터링이 필요하며, 더 복잡한 설계에 대한 일반화 능력은 추가 연구가 필요하다.  

## Conclusion  
본 연구는 벡터 기반 2D 엔지니어링 도면에서 정밀한 파라메트릭 CAD 모델을 생성하는 혁신적이고 실용적인 딥러닝 프레임워크를 성공적으로 제안하였다.

# 13. [Delta Activations: A Representation for Finetuned Large Language Models](https://arxiv.org/abs/2509.04442)

## Introduction
- Goal: 본 연구는 파인튜닝된 대형 언어 모델들을 내부 활성화 변화량을 측정하여 벡터 임베딩 방식으로 표현하는 것을 목표로 한다.  
- Motivation: 다양한 도메인과 작업에 특화된 다수의 파인튜닝 모델들이 존재하지만, 비일관적 메타데이터와 구조화되지 않은 저장소로 인해 이들 모델의 탐색과 이해가 어렵다는 문제의식에서 출발한다.  
- Contribution: 내부 상태의 차이를 이용한 Delta Activations 기법을 제안하여, 모델 간 유사성과 특성을 효과적으로 군집화하고, 퓨샷 작업 임베딩 및 모델 선택, 병합 등에 활용 가능함을 보였다.  

## Method  
Delta Activations는 동일 입력에 대해 기본 모델과 파인튜닝된 모델의 최종 레이어 마지막 토큰 활성화 값의 차이를 계산해 모델 임베딩 벡터를 생성한다. 이를 위해 완전히 일반적인 프롬프트 집합을 사용하여 모델 내 활성화 변화만을 반영하며, 이 임베딩은 퓨샷 학습된 과제 표상으로도 확장 가능하다.  

## Results  
Delta Activations는 LLAMA, GEMMA, QWEN의 파인튜닝 모델들에서 도메인별 군집화에 뛰어난 성능을 보였으며, 다양한 학습 세팅에도 견고하고, 여러 도메인 복합 학습 모델의 임베딩이 개별 임베딩의 덧셈으로 근사되는 속성을 확인하였다.  

## Limitations  
Delta Activations는 내부 히든 스테이트 접근이 필요하기 때문에, 폐쇄형 모델이나 내부 정보 비공개 모델에는 적용이 어렵다는 제한이 존재한다.  

## Conclusion  
본 연구는 파인튜닝된 대형 언어 모델들의 행동 변화를 효과적으로 정량화하여 모델 탐색과 활용을 촉진하는 범용적이고 확장 가능한 임베딩 기법을 제시하였다.

# 14. [False Sense of Security: Why Probing-based Malicious Input Detection   Fails to Generalize](https://arxiv.org/abs/2509.03888)

## Introduction
- Goal: 본 논문은 대형 언어 모델(LLM) 내부 표현을 이용한 probing 기반 악의적 입력 탐지 기법의 일반화 실패 원인을 체계적으로 재검토하는 데 목적이 있다.  
- Motivation: 기존 연구에서는 probing 분류기가 도메인 내에서 높은 정확도를 보이나, 도메인 밖(out-of-distribution)에서는 성능이 급격히 저하되는 문제점이 관찰되어, 분류기가 실제 의미적 유해성을 학습하는지 의문이 제기되었다.  
- Contribution: 세 가지 연구를 통해 probing 분류기가 유해성의 의미적 이해보다는 표면적 패턴(교수형 패턴 및 트리거 단어)에 의존함을 규명하고, 이로 인해 현 기법들이 잘못된 안정성 신뢰를 제공함을 증명하였다.  

## Method  
LLM의 마지막 층 은닉 상태를 추출하여 SVM 등 간단한 분류기를 학습하는 probing 기법을 적용하였다.  
비교를 위해 n-그램 기반 Naive Bayes 모델과 의미적 클린징(cleaned)된 데이터셋을 활용한 통제 실험, 가짜 트리거 단어 삽입 테스트를 수행하였다.  
또한 다양한 층, 분류기 구조, 기본 모델과 instruction-tuned 모델 간의 성능 차이를 분석하였다.  

## Results  
proving 분류기는 도메인 내에서 98% 이상의 높은 정확도를 보이나, 도메인 밖에서는 최대 99%까지 급락하며, 단순 n-그램 기법과 비슷한 성능을 보이고 의미적 클린징 시에도 정확도가 대폭 하락함을 확인하였다.  

## Limitations  
본 연구는 영어 데이터셋과 디코더형 Transformer 모델에 한정되어 있어 다국어 및 기타 LLM 아키텍처에 대한 일반화는 추가 연구가 필요하다.  

## Conclusion  
proving 기반 악의적 입력 탐지 방식은 표면적 패턴 학습에 의존하여 의미적 유해성을 제대로 반영하지 못하며, 이는 잘못된 안정성 인식을 조장하므로 강건하고 의미론적 기반의 새로운 검출 방법 개발이 요구된다.
