---
layout: post
title: "Daily Papers — 2025-11-27"
date: 2025-11-27 08:15:00
tags: [papers, hugginface]
categories: []
---


# 1. [Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation](https://arxiv.org/abs/2511.20714)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.20714)

## Introduction
- Goal: 본 논문은 차세대 세미-오토리그레시브(블록-디퓨전) 디코딩 방식을 이용한 세계 시뮬레이션용 추론 엔진 Inferix를 제안하는 데 목적이 있다.  
- Motivation: 기존 비디오 디퓨전 모델들은 고품질 장기 영상 생성 시 메모리 및 계산 병목 현상이 존재하며, 확장성과 효율성에 한계가 있었다.  
- Contribution: Inferix는 효율적인 KV 캐시 관리, 병렬 처리, 실시간 영상 스트리밍 및 장시간 영상 평가를 위한 LV-Bench 벤치마크 통합 등 혁신적 기능을 제공한다.  

## Method  
Inferix는 노이즈로부터 반복적 디노이징을 수행하여 블록 단위로 비디오를 생성하며, 이전 블록의 문맥 정보를 포함하는 KV 캐시를 지속적으로 갱신한다.  
병렬화 기법과 적응형 병렬 전략을 적용해 장시간 영상 생성 시 메모리 부담과 처리 시간을 최소화한다.  
또한 KV 캐시 압축과 오프로딩을 지원하여 GPU 메모리 사용을 최적화하며, 다양한 블록-디퓨전 모델에 범용적으로 대응한다.  

## Results  
Inferix는 LV-Bench를 활용한 평가에서 장시간 영상 생성의 공간적 선명도 및 시간적 안정성에서 우수한 성능을 입증하였다.  

## Limitations  
Inferix는 블록-디퓨전 특화 기법이 지속 개발 중이며, 높은 계산 비용과 복잡한 KV 캐시 관리는 여전히 해결해야 할 과제이다.  

## Conclusion  
Inferix는 블록-디퓨전 기반의 차세대 추론 엔진으로서 장시간, 고품질 세계 시뮬레이션 영상 생성 연구에 중요한 도구가 될 것으로 기대된다.

# 2. [Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy](https://arxiv.org/abs/2511.21579)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.21579)

## Introduction
- 본 연구의 목표는 교차 태스크 시너지 학습을 통해 오디오와 비디오 생성 간의 정밀한 동기화를 이루는 통합 생성 모델인 Harmony를 제안하는 것이다.  
- 기존 오픈소스 모델들이 직면한 오디오-비디오 정합성 문제의 근본 원인이 잡음 있는 잠재 공간에서의 대응 관계 변동, 비효율적인 전역 주의 메커니즘, 그리고 내재적 모달 편향을 가진 기존의 분류기 자유 안내법(CFG)에 있음을 규명하였다.  
- 본 논문은 교차 태스크 시너지 훈련, 전역-국소 분리 상호작용 모듈, 그리고 동기화 강화 CFG(SyncCFG)를 통해 기존 한계를 극복하는 새로운 오디오-비디오 생성 프레임워크를 제안하였다.  

## Method  
Harmony는 (1) 오디오 주도 비디오 생성과 비디오 주도 오디오 생성이라는 단방향 감독 신호를 활용해 대응 관계 변동 문제를 완화하는 교차 태스크 시너지 훈련 전략, (2) 전역 스타일 일관성과 세밀한 시간적 정합을 동시에 달성하기 위한 전역-국소 분리 상호작용 모듈, (3) 추론 단계에서 음성-영상 동기화 신호를 명시적으로 증폭하는 SyncCFG 기법을 핵심 설계로 포함한다.  

## Results  
Harmony는 인간 음성 및 환경음이 혼재된 복잡한 장면에서도 기존 최첨단 모델 대비 우수한 오디오-비디오 동기화 성능을 보이며 Harmony-Bench 벤치마크에서 Sync-C 및 Sync-D 지표에서 최고 성적을 기록하였다.  

## Limitations  
정보 부족.  

## Conclusion  
Harmony는 근본적인 대응 관계 변동과 구조적 충돌 문제를 해결하고 동기화 강화 안내를 도입함으로써 오디오-비디오 생성의 새로운 표준을 확립하였으며, 차세대 통합 오디오-비주얼 생성 모델 개발의 중요한 토대를 제공한다.

# 3. [Revisiting Generalization Across Difficulty Levels: It's Not So Easy](https://arxiv.org/abs/2511.21692)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.21692)

## Introduction
- Goal: 본 연구의 목표는 대형 언어 모델(LLM)이 서로 다른 난이도 수준의 과제에서 얼마나 잘 일반화되는지 체계적으로 평가하는 것이다.  
- Motivation: 난이도별 일반화 성능에 대한 기존 연구 결과가 상반되고 인간 기준 난이도 평가의 한계로 인해 데이터 큐레이션 및 평가가 어려우므로, 모델 기반 난이도 측정을 통한 객관적 분석이 필요하다.  
- Contribution: 본 논문은 아이템 반응 이론(Item Response Theory, IRT)과 수천 개 LLM의 평가 결과를 활용해 여섯 개 데이터셋 내 문제들의 난이도를 세분화하여, 난이도 간 일반화가 제한적임을 체계적으로 입증하였다.  

## Method  
LLM들의 응답 결과를 수집하여 IRT의 Rasch 모델을 통해 각 문제의 난이도와 모델 능력을 추정하였다. 수집된 난이도 점수를 기준으로 문제들을 열 개의 동일 크기 난이도 구간(bin)으로 나누어 구간별 fine-tuning 후 다른 난이도 구간에서 평가했다. 다양한 모델 및 데이터셋에 걸쳐 이 과정을 반복하여 난이도 간 일반화 능력을 비교 분석하였다.  

## Results  
일반적으로 LLM은 훈련된 난이도 구간과 가까운 난이도 문제들에서만 성능 향상이 나타나며, 쉬운 문제만 훈련하거나 어려운 문제만 훈련해도 전 범위 난이도에 걸친 안정적인 일반화는 불가능함을 확인하였다.  

## Limitations  
본 연구는 대규모 모델 추론 비용 제한으로 인해 기존 공개된 평가 기록을 활용해 난이도를 추정하였으며, 추후 직접 실험 기반 확장 연구가 필요하다.  

## Conclusion  
난이도에 따른 일반화는 제한적이며, 난이도가 다양한 훈련 및 평가 데이터를 활용한 난이도 인지 기반 접근법만이 실용적 언어 모델 개발에 필수적임을 제시한다.

# 4. [NVIDIA Nemotron Parse 1.1](https://arxiv.org/abs/2511.20478)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.20478)

## Introduction
- Goal: 본 연구는 Nemoretriever-Parse 1.0의 성능을 향상시킨 경량 문서 파싱 및 OCR 모델 Nemotron-Parse 1.1을 제안하는 것이다.  
- Motivation: 현대 문서 레벨 OCR은 단순한 문자 추출을 넘어 레이아웃, 의미 범주, 수식, 표 및 다단 구성 인식 등 복합적인 정보를 요구한다.  
- Contribution: Nemotron-Parse 1.1은 일반 OCR, 마크다운 포맷팅, 구조화된 표 파싱, 그림 및 도표 내 텍스트 추출 능력을 개선하고, 긴 시퀀스 처리와 토큰 압축을 통한 속도 개선을 동시에 달성하였다.  

## Method  
Nemotron-Parse 1.1은 885M 매개변수의 인코더-디코더 트랜스포머 아키텍처를 기반으로 하며, RADIO 비전 인코더와 mBART 디코더를 통합하였다.  
디코더에서는 위치 임베딩 없이 대규모 문서에서 긴 문맥을 효율적으로 처리하며, 다수 토큰 동시 예측 방식을 채택하여 추론 속도를 높였다.  
또한 서로 다른 주석 특성을 갖는 이질적 데이터셋을 단일 조건부 프롬프트 인터페이스로 통합해 다양한 출력(텍스트, 바운딩 박스, 클래스 라벨)을 학습하였다.  

## Results  
Nemotron-Parse 1.1은 내부 및 공개 벤치마크(OmniDocBench, GOT, RD-TableBench 등)에서 동급모델 대비 우수한 OCR 정확도, 표 추출, 읽기 순서 인식 성능을 보였으며, 토큰 압축 모델은 약 20% 향상된 속도와 함께 성능 저하를 최소화하였다.  

## Limitations  
모델은 주로 과학 문서 및 표준 PDF 문서에 최적화되어 있으며, 중국어, 일본어, 한국어 등 비유럽권 언어의 야생 이미지 인식에는 제한적으로 지원된다.  

## Conclusion  
Nemotron-Parse 1.1은 경량화와 고성능을 동시에 달성하는 엔드투엔드 문서 OCR 및 파싱 모델로서, 공개 배포되어 다양한 문서 이해 애플리케이션에 활용 가능하다.

# 5. [Terminal Velocity Matching](https://arxiv.org/abs/2511.19797)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.19797)

## Introduction
- 목표는 단일 학습 단계에서 고품질의 한두 단계 생성 모델을 구현하는 것이다.  
- 기존 확산 모델과 유동 매칭 기법은 고품질 샘플을 위해 다단계 샘플링이 필요해 연산 비용이 크다.  
- 본 논문에서는 경로의 시작이 아닌 끝 시점에서 속도를 매칭하는 Terminal Velocity Matching (TVM)을 제안한다.  

## Method  
Terminal Velocity Matching은 임의 두 시간 점 간의 변화를 모델링하며 경로의 종단 시점에서 속도를 정규화한다.  
Lipschitz 연속성을 갖는 경우 TVM 손실은 데이터와 모델 분포 간 2-Wasserstein 거리의 상한을 제공한다.  
효율적 구현을 위해 JVP가 가능한 Flash Attention 커널과 최소한의 아키텍처 변경으로 학습 안정성을 확보한다.  

## Results  
ImageNet-256×256 및 512×512 데이터셋에서 TVM은 1단계 샘플링 시 각각 3.29, 4.32 FID를 달성하며 기존 단일/소수 단계 모델 대비 우수한 성능을 나타낸다.  

## Limitations  
Diffusion Transformer는 Lipschitz 연속성을 갖지 않아 안정적 학습을 위해 아키텍처 수정을 필요로 한다.  

## Conclusion  
TVM은 경로 종료시점의 속도 매칭을 통해 이론적 분포적 보장을 가지면서 단일/소수 단계 생성 모델 학습 안정성과 성능 향상을 동시에 달성한다.

# 6. [Image-Free Timestep Distillation via Continuous-Time Consistency with Trajectory-Sampled Pairs](https://arxiv.org/abs/2511.20410)

> [Alphaxiv](https://www.alphaxiv.org/ko/overview/2511.20410)

## Introduction
- Goal: 본 논문은 확산 모델의 생성 효율성을 높이기 위해 이미지 데이터 없이 연속 시간 일관성(distillation)을 활용한 궤적 샘플링 기반의 새 시점 단축 증류(Timestep Distillation) 방법을 제안하는 것이다.  
- Motivation: 기존 연속 시간 일관성 증류 방법은 대규모 학습 데이터와 고성능 연산 자원에 의존하여 자원 제한적인 환경에서의 적용과 다양한 도메인 확장에 제약이 존재한다.  
- Contribution: 이미지 데이터 및 VAE 인코딩에 의존하지 않고 사전 학습된 교사 모델의 생성 궤적에서 직접 잠재 표현을 추출하는 새로운 무이미지(image-free) 증류 방식인 궤적-역방향 일관성 모델(TBCM)을 개발하였다.  

## Method  
제안하는 TBCM은 교사 모델의 생성 궤적을 따라 다중 샘플을 잠재 공간에서 직접 획득하며, 이를 통해 훈련과 추론 간의 분포 차이를 줄여 일관성 증류 품질을 향상시킨다. VAE 인코더 생략으로 GPU 메모리 사용량과 훈련 시간을 크게 절감하며, 텍스트 인코딩 오버헤드를 여러 샘플에 분산하여 효율을 증대하였다. 또한, 궤적 샘플링 전략과 손실 함수 내 불안정 항목의 가중치를 조정하여 증류 안정성과 결과 품질을 개선하였다.  

## Results  
MJHQ-30k 벤치마크에서 TBCM은 단일 스텝 생성 시 FID 6.52, CLIP 28.08의 우수한 성능을 기록했으며, 기존 Sana-Sprint 대비 약 40% 훈련 시간 단축 및 60% 이상의 GPU 메모리 절감을 달성하였다.  

## Limitations  
실제 이미지 감독 없이 교사 모델 궤적에만 의존하기 때문에 교사 모델의 한계와 편향이 학생 모델에 전이되어 샘플 다양성 감소나 모드 붕괴 문제가 발생할 수 있다.  

## Conclusion  
TBCM은 이미지-프리 잠재 공간 증류를 통해 연속 시간 일관성 증류의 효율성과 확장성을 크게 향상시켰으며, 향후 샘플 공간 설계와 보완적 생성 기법 결합이 발전 가능성이 큰 연구 방향임을 시사한다.
