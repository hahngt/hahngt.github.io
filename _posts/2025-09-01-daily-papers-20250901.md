---
layout: post
title: Daily Papers — 2025-09-01"
date: 2025-09-01 08:15:00
tags: [papers, arxiv, ai]
categories: []
---


# 1. [R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs   via Bi-Mode Annealing and Reinforce Learning](https://arxiv.org/abs/2508.21113)

## Introduction  
- Goal: 본 연구는 다목적 자동사고(auto-thinking) 능력을 갖춘 멀티모달 대형 언어 모델(MLLM) R-4B를 제안하는 것이다.  
- Motivation: 기존 MLLM은 복잡한 문제에 대해 단계적 사고를 수행하지만 단순 문제에서 불필요한 연산 낭비가 발생하는 비효율성이 존재한다.  
- Contribution: R-4B는 문제 복잡도에 따라 사고 수행 여부를 자동으로 판단하는 이중 모드 어닐링과 강화학습 기반의 Bi-mode Policy Optimization(BPO) 기법을 통합하여 효율적인 사고 능력을 제공한다.  

## Method  
R-4B는 사고와 비사고 두 가지 모드를 동시에 학습하는 이중 모드 어닐링을 도입하고, 이를 위한 추론 집중 및 직답 데이터셋을 자동 분할하여 구성한다. 이후 강화학습 단계에서는 BPO를 활용해 사고 모드와 비사고 모드의 출력을 균형 있게 생성하고 평가하여 최적의 모드 선택 정책을 학습시킨다. 이를 통해 복잡한 문제에 대해서는 사고 모드를, 단순한 문제에는 직답 모드를 선택할 수 있게 한다.  

## Results  
R-4B 강화학습 모델(R-4B-RL)은 25개 다중 도전 벤치마크에서 Qwen2.5-VL-7B를 능가하고, 16B 파라미터급 대형모델인 Kimi-VL-A3B-Thinking-2506과 유사하거나 우수한 성능을 보이며 높은 효율성을 달성하였다.  

## Limitations  
복잡한 보상 설계 없이 수학 문제에 기반한 단순 규칙형 보상을 적용했으나, 일반 도메인 내 일부 복잡성 판단의 세밀함은 개선이 필요하다.  

## Conclusion  
R-4B는 이중 모드 어닐링과 BPO 강화학습을 결합하여 효율적이며 적응적인 자동사고 기능을 실현, 고성능과 자원 효율성을 동시에 달성하는 멀티모달 대형 언어 모델 개발의 실용적 방향을 제시하였다.

# 2. [EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for   General Robot Control](https://arxiv.org/abs/2508.21112)

## Introduction
- Goal: 본 연구는 인간과 유사한 수준의 유연한 비전, 텍스트, 로봇 행동 간 상호작용 능력을 갖춘 범용 로봇 제어를 위해 통합된 다중모달 행동-이해 기초 모델을 제안하는 것이다.  
- Motivation: 기존의 비전-언어-행동(VLA) 모델들은 제한된 로봇 환경에서만 유의미한 성능을 보이나, 인간 수준의 상호억제적 사고와 행동의 융합적 수행에는 미흡하였다.  
- Contribution: EO-1 모델과 EO-Data1.5M 데이터셋을 기반으로 하는 인터리브드 비전-텍스트-행동 사전학습 방법과 이를 위한 대규모 고품질 다중모달 행동 추론 데이터셋 및 모델 아키텍처를 제시하였다.  

## Method  
EO-1은 이미지, 텍스트, 비디오, 행동 데이터를 동일한 통합 구조에서 다루는 단일 디코더형 트랜스포머로 설계되었으며, 언어를 위한 자기회귀 방식 디코딩과 행동 생성을 위한 연속형 흐름 매칭 노이즈 제거 방식을 통합하였다.  
로봇 행동과 시각 및 언어적 추론을 시계열상 상호 얽히도록 인터리브된 형식으로 구성한 EO-Data1.5M 데이터셋으로 사전학습하였으며, 행동 토큰의 노이즈 제거를 위한 교정 샘플링 전략을 도입하였다.  
학습은 다음 토큰 예측과 행동 벡터 필드 예측의 두 가지 손실 함수를 함께 최적화하는 방식으로 이루어졌다.  

## Results  
EO-1 모델은 ERQA, LIBERO, SimplerEnv 및 자체 구축 EO-Bench 등 다양한 벤치마크에서 기존 공개 모델들을 능가하는 다중모달 추론 능력과 실 로봇 제어 성능을 획득하였다.  

## Limitations  
정보 부족  

## Conclusion  
EO-Robotics는 범용 자율 로봇을 위한 고급 통합 다중모달 행동-이해 기초 모델 개발에 있어 새로운 방향성과 공개된 데이터 및 모델 리소스를 제공하였다.
